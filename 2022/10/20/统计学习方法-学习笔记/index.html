<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>统计学习方法 - Bruce Han&#039;s Blog</title><link rel="manifest" href="../../../../manifest.json"><meta name="application-name" content="Bruce Han&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Bruce Han&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="统计学习方法——学习笔记"><meta property="og:type" content="blog"><meta property="og:title" content="统计学习方法"><meta property="og:url" content="https://brucehan98@github.io/2022/10/20/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><meta property="og:site_name" content="Bruce Han&#039;s Blog"><meta property="og:description" content="统计学习方法——学习笔记"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/Roccurves.png/220px-Roccurves.png"><meta property="og:image" content="https://s2.loli.net/2022/09/23/WkHaxuNDbmpGeiL.png"><meta property="og:image" content="https://s2.loli.net/2022/09/24/Ex9t6ASncizOvXp.png"><meta property="og:image" content="https://s2.loli.net/2022/09/24/5HuajAdDTqlJMzZ.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/5w4NzR7dnOWLDVZ.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/1VML4dHECJAqfoD.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/dZxFqlPSgmUHQc8.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/HGZUOiY6gkjKVJ7.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/Y4q2rm1KPF5Xb8R.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/2klwHvGsK1juxJO.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/MfoSPvOaC147qVA.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/ilb6eOtmJAPGNyK.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/R6kC2y78jlar4DI.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/hfCEjva58bDFeHy.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/BQMYjOPD7ZzAdW5.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/FvIUCKOoMiPs2bx.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/6KpZDUvVwNYazyd.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/TcnE2MRYzpbgkjK.png"><meta property="og:image" content="https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009122440303.png"><meta property="og:image" content="https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009194041235.png"><meta property="og:image" content="https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009194113943.png"><meta property="og:image" content="https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009194449118.png"><meta property="og:image" content="https://s2.loli.net/2022/10/08/IoyYP36vxpnijGc.png"><meta property="og:image" content="https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009203908759.png"><meta property="og:image" content="https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009203934547.png"><meta property="og:image" content="https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009204035263.png"><meta property="og:image" content="https://pic4.zhimg.com/80/v2-5ee98f8f3426b845bc1c5038ecd29593_1440w.webp"><meta property="og:image" content="https://pic3.zhimg.com/80/v2-eab35f0f8896ebe2dbf64d3c0b2bb1da_1440w.webp"><meta property="og:image" content="https://pic1.zhimg.com/80/v2-51a61b4e3b977ade92b970f486a4aef4_1440w.webp"><meta property="og:image" content="https://pic3.zhimg.com/80/v2-6a5a4da69ea5c7450d016fd2a8c7c436_1440w.webp"><meta property="og:image" content="https://images2015.cnblogs.com/blog/1042406/201701/1042406-20170103121629034-435985945.png"><meta property="article:published_time" content="2022-10-20T10:45:48.000Z"><meta property="article:modified_time" content="2022-10-25T09:37:23.124Z"><meta property="article:author" content="Bruce Han"><meta property="article:tag" content="机器学习"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/Roccurves.png/220px-Roccurves.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://brucehan98@github.io/2022/10/20/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},"headline":"统计学习方法","image":["https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/Roccurves.png/220px-Roccurves.png","https://s2.loli.net/2022/09/23/WkHaxuNDbmpGeiL.png","https://s2.loli.net/2022/09/24/Ex9t6ASncizOvXp.png","https://s2.loli.net/2022/09/24/5HuajAdDTqlJMzZ.png","https://s2.loli.net/2022/10/08/5w4NzR7dnOWLDVZ.png","https://s2.loli.net/2022/10/08/1VML4dHECJAqfoD.png","https://s2.loli.net/2022/10/08/dZxFqlPSgmUHQc8.png","https://s2.loli.net/2022/10/08/HGZUOiY6gkjKVJ7.png","https://s2.loli.net/2022/10/08/Y4q2rm1KPF5Xb8R.png","https://s2.loli.net/2022/10/08/2klwHvGsK1juxJO.png","https://s2.loli.net/2022/10/08/MfoSPvOaC147qVA.png","https://s2.loli.net/2022/10/08/ilb6eOtmJAPGNyK.png","https://s2.loli.net/2022/10/08/R6kC2y78jlar4DI.png","https://s2.loli.net/2022/10/08/hfCEjva58bDFeHy.png","https://s2.loli.net/2022/10/08/BQMYjOPD7ZzAdW5.png","https://s2.loli.net/2022/10/08/FvIUCKOoMiPs2bx.png","https://s2.loli.net/2022/10/08/6KpZDUvVwNYazyd.png","https://s2.loli.net/2022/10/08/TcnE2MRYzpbgkjK.png","https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009122440303.png","https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009194041235.png","https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009194113943.png","https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009194449118.png","https://s2.loli.net/2022/10/08/IoyYP36vxpnijGc.png","https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009203908759.png","https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009203934547.png","https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009204035263.png","https://pic4.zhimg.com/80/v2-5ee98f8f3426b845bc1c5038ecd29593_1440w.webp","https://pic3.zhimg.com/80/v2-eab35f0f8896ebe2dbf64d3c0b2bb1da_1440w.webp","https://pic1.zhimg.com/80/v2-51a61b4e3b977ade92b970f486a4aef4_1440w.webp","https://pic3.zhimg.com/80/v2-6a5a4da69ea5c7450d016fd2a8c7c436_1440w.webp","https://images2015.cnblogs.com/blog/1042406/201701/1042406-20170103121629034-435985945.png"],"datePublished":"2022-10-20T10:45:48.000Z","dateModified":"2022-10-25T09:37:23.124Z","author":{"@type":"Person","name":"Bruce Han"},"publisher":{"@type":"Organization","name":"Bruce Han's Blog","logo":{"@type":"ImageObject","url":"https://brucehan98@github.io/img/logo.svg"}},"description":"统计学习方法——学习笔记"}</script><link rel="canonical" href="https://brucehan98@github.io/2022/10/20/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><link rel="icon" href="../../../../img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/github.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="../../../../css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?8ff5bda969cd5128662b3fbc6a899b16";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="../../../../index.html"><img src="../../../../img/logo.svg" alt="Bruce Han&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="../../../../index.html">首页</a><a class="navbar-item" href="../../../../archives">归档</a><a class="navbar-item" href="../../../../categories">分类</a><a class="navbar-item" href="../../../../tags">标签</a><a class="navbar-item" href="../../../../about">关于</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="../../../../https:/github.com/BruceHan98"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-4 is-size-4-mobile" style="font-weight: 600; margin-bottom: 0.8rem;">统计学习方法</h1><div class="article-meta is-size-6 is-uppercase level is-mobile" style="margin-top: 0.5rem;"><div class="level-left"><span class="level-item"><time dateTime="2022-10-20T10:45:48.000Z" title="2022-10-20T10:45:48.000Z">2022-10-20</time>发表</span><span class="level-item"><time dateTime="2022-10-25T09:37:23.124Z" title="2022-10-25T09:37:23.124Z">2022-10-25</time>更新</span><span class="level-item"><a class="link-muted" href="../../../../categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a></span><span class="level-item">2 小时读完</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><div class="content" style="margin-top: 1rem; margin-bottom: 0.5rem;"><h2 id="一、统计学习与监督学习概论"><a href="#一、统计学习与监督学习概论" class="headerlink" title="一、统计学习与监督学习概论"></a>一、统计学习与监督学习概论</h2><h3 id="1-1-统计学习"><a href="#1-1-统计学习" class="headerlink" title="1.1 统计学习"></a>1.1 统计学习</h3><p><strong>什么是学习？</strong></p>
<p>如果一个系统能够通过执行某个过程改进它的性能，这就是学习。——赫尔伯特 · 西蒙</p>
<p><strong>统计机器学习</strong></p>
<p>统计学习就是计算机系统通过运用数据及统计方法提高系统性能的及其学习。机器学习往往指统计机器学习。</p>
<p><strong>统计学习的前提</strong></p>
<p>统计学习关于数据的基本假设是同类数据具有一定的统计规律性。</p>
<p><strong>统计学习的目的</strong></p>
<p>统计学习用于对数据的预测与分析，特别是对未知新数据的预测与分析。</p>
<p><strong>统计学习的方法</strong></p>
<p>统计学习的方法是基于数据构建概率统计模型，从而对数据进行预测与分析，由监督学习、无监督学习和强化学习等组成。</p>
<p><strong>定义</strong></p>
<p>统计学习方法可以概括如下：从给定的、有限的、用于学习的训练数据集合出发，假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数的集合，称为假设空间；应用某个评价准则，从假设空间中选取一个最优模型，使它对已知的训练数据及未知的测试数据在给定的评价准则下有最优的预测；最优模型的选取由算法实现。</p>
<p>这样，统计学习方法方法包括模型的假设空间、模型选择的准则以及模型学习的算法，简称为模型（model）、策略（strategy）和算法（algorithm），称为统计学习方法的三要素。</p>
<h3 id="1-2-统计学习的分类"><a href="#1-2-统计学习的分类" class="headerlink" title="1.2 统计学习的分类"></a>1.2 统计学习的分类</h3><h4 id="基本分类"><a href="#基本分类" class="headerlink" title="基本分类"></a>基本分类</h4><p><strong>监督学习</strong></p>
<p>监督学习（supervised learning）是从标注数据中学习预测模型的机器学习问题。其本质是学习输入到输出的映射的统计规律。</p>
<p>监督学习假设输入与输出的随机变量 X 和 Y 遵循联合概率分布 P(X, Y)。训练数据与测试数据被看作是依联合概率分布 P(X, Y) 独立同分布产生的。这是监督学习关于数据的基本假设。</p>
<p><strong>无监督学习</strong></p>
<p>无监督学习（unsupervised learning）是指从无标注数据中学习预测模型的机器学习问题。其本质是学习数据中的统计规律或潜在结构。</p>
<p><strong>强化学习</strong></p>
<p>强化学习（reinforcement learning）是指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题。其本质是学习最优的序贯决策。</p>
<p><strong>半监督学习与主动学习</strong></p>
<p>半监督学习（semi-supervised learning）是指利用标注数据和未标注数据学习预测模型的机器学习问题。利用未标注数据中的信息，辅助标注数据进行监督学习，以较低的成本达到较好的学习效果。</p>
<p>主动学习（active learning）是指机器不断主动给出实例让教师进行标注，然后利用标注数据学习预测模型的机器学习问题。主动学习的目标是找出对学习最有帮助的实例让老师标注，以较小的标注代价达到较好的学习效果。</p>
<p>半监督学习和主动学习更接近监督学习。</p>
<h4 id="按模型分类"><a href="#按模型分类" class="headerlink" title="按模型分类"></a>按模型分类</h4><p><strong>概率模型与非概率模型</strong></p>
<p>统计学习方法可以分为概率模型（probabilistic model）和非概率模型（non-probabilistic model）或确定性模型（deterministic model）。</p>
<p>在监督学习中，概率模型取条件概率分布形式 P(y|x)，非概率模型取函数形式 y = f(x)，其中 x 是输入，y 是输出。在无监督学习中，概率模型取条件概率形式 P(z|x) 或 P(x|z)，非概率模型取函数形式 z = g(x)，其中 x 是输入，z 是输出。</p>
<p>概率模型包括：</p>
<ul>
<li>决策树</li>
<li>朴素贝叶斯</li>
<li>隐马尔可夫模型</li>
<li>条件随机场</li>
<li>概率潜在语义分析</li>
<li>潜在狄利克雷分配</li>
<li>高斯混合模型</li>
</ul>
<p>非概率模型包括：</p>
<ul>
<li>感知机</li>
<li>支持向量机</li>
<li>k 近邻</li>
<li>AdaBoost</li>
<li>k 均值</li>
<li>潜在语义分析（LSA）</li>
<li>神经网络</li>
</ul>
<p>逻辑回归既可以看作是概率模型，也可以看作是非概率模型。</p>
<blockquote>
<p> 注意：条件概率分布 P(y|x) 与函数 y = f(x) 可以相互转化。因此，概率模型和非概率模型的区别不在于输入与输出之间的映射关系，而在于模型的内在结构：概率模型一定可以表示为联合概率分布的形式。</p>
</blockquote>
<h3 id="1-3-统计学习方法的三要素"><a href="#1-3-统计学习方法的三要素" class="headerlink" title="1.3 统计学习方法的三要素"></a>1.3 统计学习方法的三要素</h3><p>方法 = 模型 + 策略 + 算法</p>
<h4 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h4><p>在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。模型对假设空间包含所有可能的条件概率分布或决策函数。</p>
<p>假设空间可以定义为决策函数的集合：$\mathcal F=\{f|Y=f(X)\}$，其中，X 和 Y 是定义在输入空间 $\mathcal X$ 和输出空间 $\mathcal Y$ 上的变量。</p>
<p>假设空间也可以定义为条件概率的集合：$\mathcal F=\{P|P(Y|X)\}$</p>
<h4 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h4><p>有了模型的假设空间，接着需要考虑的是按照什么样的准则学习或选择最优模型。统计学习的目标在于从假设空间中选取最优模型。</p>
<p><strong>损失函数与风险函数</strong></p>
<p>损失函数度量模型一次预测的好坏；风险函数度量平均意义下模型预测的好坏。</p>
<p><strong>损失函数</strong>是 f(X) 和 Y 的非负实值函数，记作 L(Y, f(X))。</p>
<ul>
<li><p>0-1 损失函数：</p>
<p>$L(Y,f(X))=\begin{cases}1,&amp;Y\ne f(X)\\0,&amp;Y=f(X) \end{cases}$</p>
</li>
<li><p>平方损失函数：</p>
<p>$L(Y,f(X))=(Y-f(X))^2$</p>
</li>
<li><p>绝对损失函数：</p>
<p>$L(Y,f(X))=|Y-f(X)|$</p>
</li>
<li><p>对数（似然）损失函数：</p>
<p>$L(Y,P(Y|X))=-logP(Y|X)$</p>
</li>
</ul>
<p>损失函数值越小，模型就越好。</p>
<p><strong>风险函数</strong>或<strong>期望损失</strong>就是平均意义下的损失：</p>
<p>​        $R_{exp}(f)=E_P[L(Y,f(X))]=\int_{\mathcal X \times \mathcal Y}L(y,f(x))P(x,y)dxdy$</p>
<p>学习的目标就是选择期望风险最小的模型。由于联合分布 P(X, Y) 是未知的（如果知道联合分布 P(X, Y)，就可以直接求出条件概率分布 P(Y|X)，就不需要学习了），所以 $R_{exp}(f)$ 不能直接计算。因此，监督学习需要用经验风险估计期望风险。</p>
<p>模型关于训练数据的平均损失称为<strong>经验风险</strong>或经验损失：</p>
<p>​        $R_{emp}(f)=\frac{1}{N}\sum\limits_{i=1}^NL(y_i,f(x_i))$</p>
<p>期望风险是模型关于联合分布的期望损失；经验风险是模型关于训练样本集的平均损失。根据大数定律，当样本容量 N 趋于无穷大时，经验风险趋于期望风险。但是现实中训练样本数有限，甚至很小，因此用经验风险估计期望风险常常并不理想，要对经验风险进行一定的矫正。有两个基本策略：经验风险最小化和结构风险最小化。</p>
<p><strong>经验风险最小化和结构风险最小化</strong></p>
<p><strong>经验风险最小化</strong>（empirical risk minimization，ERM）的策略认为，经验风险最小的模型就是最优的模型。最优模型就是求解以下最优化问题：</p>
<p>​        $\min\limits_{f \in \mathcal F}R_{emp}(f)$</p>
<p>当样本容量足够大时，经验风险最小化能保证有很好的学习效果。比如，极大似然估计就是经验风险最小化的一个例子。</p>
<p>但是，当样本容量很小时，经验风险最小化学习的效果会产生“过拟合”现象。</p>
<p><strong>结构风险最小化</strong>（structural risk minimization，SRM）是为了<strong>防止过拟合</strong>而提出的策略。结构风险最小化<strong>等价于正则化</strong>（regularization），是在经验风险上加上表示模型复杂度的正则化项或罚项。<strong>结构风险</strong>的定义是：</p>
<p>​        $R_{srm}(f)=R_{emp}(f) + \lambda J(f)$</p>
<p>其中 J(f) 为模型的复杂度，是定义在假设空间上的泛函。模型越复杂，复杂度 J(f) 越大；反义，模型越简单，复杂度 J(f) 就越小。也就是说，复杂度表示了对复杂模型的惩罚。$\lambda \ge 0$ 是系数，用来权衡经验风险和模型复杂度。</p>
<p>这样，监督学习问题就变成了经验风险最优化或结构风险最优化问题。</p>
<h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><p>算法是指学习模型的具体计算方法。统计学习的算法归结为求解最优化问题的算法。如果最优化问题有显示的解析解，这个优化问题就比较简单。但通常解析解不存在，这就需要用数值计算的方法求解。</p>
<h3 id="1-5-正则化与交叉验证"><a href="#1-5-正则化与交叉验证" class="headerlink" title="1.5 正则化与交叉验证"></a>1.5 正则化与交叉验证</h3><h4 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h4><p>模型选择的典型方法是正则化（regularization）。正则化是结构风险最小化策略的实现，一般具有如下形式：</p>
<p>​        $\min\limits_{f\in\mathcal F}\frac{1}{N}\sum\limits_{i=1}^NL(y_i,f(x_i))+\lambda J(f)$</p>
<p>其中，第 1 项是经验风险，第 2 项是正则化项。</p>
<p>比如，损失函数是平方损失，正则化项可以是参数向量的 L2 范数：</p>
<p>​        $L(\omega)=R_{emp} + \frac{\lambda}{2}||\omega||^2$</p>
<p>这里，$||\omega||$ 表示参数向量 $\omega$ 的 L2 范数。</p>
<h4 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h4><p>另一种模型选择方法是交叉验证（cross validation）。如果给定的样本数据充足，进行模型选择的一种简单方法是随机地将数据集切分为三部分：训练集、验证集和测试集。训练集用来训练模型，验证集用来选择模型，而测试集用于最终对学习方法的评估。选择对验证集有最小预测误差的模型。</p>
<p>如果数据不充足，可以采用交叉验证方法。交叉验证的基本想法是重复地使用数据：把给定的数据切分，将切分的数据集组合为训练集于测试集，在此基础上反复地进行训练、测试以及模型选择。</p>
<p><strong>简单交叉验证</strong></p>
<p>随机地将数据分为两部分：训练集和测试集（例如，70% 作为训练集，30% 作为测试集），在测试集上评价模型的测试误差，选择测试误差最小的模型。</p>
<p><strong>S 折交叉验证</strong></p>
<p>首先随机地将数据切分为 S 个互不相交、大小相同的子集；然后利用 S - 1 个子集的数据训练模型，剩下的子集用于测试模型；将这一过程对可能的 S 种选择重复进行，最后选择平均测试误差最小的模型。</p>
<p><strong>留一交叉验证</strong></p>
<p>当 S = N 时，称为留一交叉验证。</p>
<h3 id="1-7-生成模型与判别模型"><a href="#1-7-生成模型与判别模型" class="headerlink" title="1.7 生成模型与判别模型"></a>1.7 生成模型与判别模型</h3><p>监督学习方法又可以分为生成方法和判别方法，所学到的模型分别称为生成模型和判别模型。</p>
<p><strong>生成方法</strong></p>
<p>生成方法由数据学习联合概率分布 P(X, Y)，然后求出条件概率分布 P(Y|X) 作为预测的模型：</p>
<p>​        $P(Y|X)=\frac{P(X,Y)}{P(X)}$</p>
<p><strong>生成模型包括：</strong></p>
<ul>
<li>朴素贝叶斯</li>
<li>隐马尔可夫模型</li>
</ul>
<p><strong>生成方法的特点：</strong></p>
<ul>
<li>可以还原出连个概率分布 P(X, Y)</li>
<li>学习收敛速度更快</li>
<li>当存在隐变量时，仍可以用生成方法学习，而不能用判别方法</li>
</ul>
<p><strong>判别方法</strong></p>
<p>判别方法由数据直接学习决策函数 f(X) 或者条件概率分布 P(Y|X)。</p>
<p><strong>判别模型包括：</strong></p>
<ul>
<li>k 近邻</li>
<li>感知机</li>
<li>决策树</li>
<li>逻辑回归</li>
<li>最大熵模型</li>
<li>支持向量机</li>
<li>提升方法</li>
<li>条件随机场</li>
</ul>
<p><strong>判别方法的特点：</strong></p>
<ul>
<li>直接学习条件概率或决策函数，直接面对预测，往往准确率更高</li>
<li>可以对数据进行各种程度上的抽象、定义和使用特征，可以简化学习问题</li>
</ul>
<h3 id="1-8-监督学习的应用"><a href="#1-8-监督学习的应用" class="headerlink" title="1.8 监督学习的应用"></a>1.8 监督学习的应用</h3><h4 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h4><p>监督学习从数据中学习一个分类模型或分类决策函数，称为分类器。评价分类器性能的指标一般是分类的准确率（accuracy）：分类器正确分类的样本数与总样本数之比。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">真实类别 \ 分类结果</th>
<th style="text-align:center">正类</th>
<th style="text-align:center">负类</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>正类</strong></td>
<td style="text-align:center">TP</td>
<td style="text-align:center">FN</td>
</tr>
<tr>
<td style="text-align:center"><strong>负类</strong></td>
<td style="text-align:center">FP</td>
<td style="text-align:center">TN</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><p>精确率：$P=\frac{TP}{TP+FP}$    (所有预测的正类中，预测正确的占比)</p>
</li>
<li><p>召回率：$R=\frac{TP}{TP+FN}$    (所有正类样本中，预测正确的占比) </p>
</li>
<li><p>$F_1$ 值：$F_1=\frac{2PR}{P+R}$</p>
</li>
<li>准确率：$ACC=\frac{TP+TN}{TP+FP+TN+FN}$    (所有样本中，预测正确的占比)</li>
<li>灵敏度：$TPR=R$    (所有正类样本中，预测正确的占比) </li>
<li>特异度：$TNR=\frac{TN}{FP+TN}$    (所有负类样本中，预测正确的占比)</li>
</ul>
<p><strong>ROC 曲线与 AUC 值</strong></p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/Roccurves.png/220px-Roccurves.png" alt="img"></p>
<p>横轴：$FPR=\frac{FP}{FP+TN}$    (假正率，预测错误的正类在所有负类样本中的占比)</p>
<p>纵轴：$TPR=\frac{TP}{TP+FN}$    (真正率，预测正确的正类在所有正类样本中的占比)</p>
<p>AUC（Area under Curve）：ROC 曲线下的面积，介于 0 和 1 之间。其数值可以评价分类器的好坏，值越大（曲线却靠近 (0, 1) 点），代表分类器的效果越好。</p>
<p>ROC 曲线一定是需要在 y = x 之上的，否则就是一个不理想的分类器</p>
<h4 id="标注问题"><a href="#标注问题" class="headerlink" title="标注问题"></a>标注问题</h4><p>标注（tagging）问题是分类问题的一个推广，又是更复杂的结构预测（structure prediction）问题的简单形式。标注问题的输入是一个观测序列，输出是一个标记序列或状态序列。目标在于学习一个模型，能够对观测序列给出标记序列作为预测。</p>
<p>标注常用的统计学习方法有：隐马尔可夫模型、条件随机场。</p>
<h4 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h4><p>回归用于预测输入变量（自变量）和输出变量（因变量）之间的关系，学习从输入变量到输出变量之间映射的函数。按照输入变量的个数，分为一元回归和多元回归；按照输入变量和输出变量之间的关系类型，分为线性回归和非线性回归。</p>
<h2 id="二、感知机"><a href="#二、感知机" class="headerlink" title="二、感知机"></a>二、感知机</h2><p>感知机（perceptron）是二分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别，属于<strong>判别模型</strong>。感知机学习旨在求出将训练数据线性化分的分离超平面，是神经网络与支持向量机的基础。</p>
<h3 id="2-1-感知机模型"><a href="#2-1-感知机模型" class="headerlink" title="2.1 感知机模型"></a>2.1 感知机模型</h3><p>感知机函数：$f(x)=sign(\omega \cdot x + b)$</p>
<p>其中，$\omega$ 和 $b$ 为感知机模型参数，$\omega \in R^n$ 叫权值（向量），$b\in R$ 叫偏置（bias），$\cdot$ 表示内积。输入空间是 $\mathcal X \subseteqq R^n$，输出空间是 $\mathcal Y=\{+1,-1\}$。sign 是符号函数，即</p>
<p>​        $sign(x)=\begin{cases}+1,&amp;x\ge0\-1,&amp;x&lt;0\end{cases}$</p>
<p>感知机是一种线性分类模型，线性方程的几何解释如下：</p>
<p>对应于特征空间 $R^n$ 中的一个超平面 S，ω 是超平面的法向量，b 是超平面的截距。这个超平面将特征空间划分为两个部分，对应正负两类。</p>
<p><img src="https://s2.loli.net/2022/09/23/WkHaxuNDbmpGeiL.png" alt="image-20220923012906506" style="zoom: 67%;" /></p>
<h3 id="2-2-学习策略"><a href="#2-2-学习策略" class="headerlink" title="2.2 学习策略"></a>2.2 学习策略</h3><p>假设训练数据集是线性可分的（能够通过线性方程 $\omega \cdot x + b$ 分为两类），感知机学习的目标是求得一个能够将正负点完全正确分开的超平面。</p>
<p><strong>损失函数</strong></p>
<p>如果选择误分类点的总数作为损失函数，该损失函数不是参数 ω 和 b 的连续可导函数，不易优化。另一个选择是误分类点到超平面 S 的总距离。输入空间中任一点 $x_0$ 到超平面 S 的距离定义为</p>
<p>​        $\frac{1}{||\omega||}|\omega \cdot x_0+b|$ </p>
<p>其中，$||\omega||$ 表示 $\omega$ 的 L2 范数。</p>
<p>对于误分类的数据 $(x_i,y_i)$，有 $-y_i(\omega \cdot x_i+b)&gt;0$。因此，误分类点到超平面的距离是</p>
<p>​        $-\frac{1}{||\omega||}y_i|\omega \cdot x_0+b|$ </p>
<p>这样，所有误分类点到超平面的总距离为</p>
<p>​        $-\frac{1}{||\omega||}\sum\limits_{x_i\in M}y_i|\omega \cdot x_0+b|$ </p>
<p>不考虑 $\frac{1}{||\omega||}$，得到感知机的损失函数</p>
<p>​        $L(w,b)=-\sum\limits_{x_i \in M}y_i(\omega \cdot x_i + b)$</p>
<p>这就是感知机学习的经验风险函数。显然，损失函数是非负的，如果没有误分类点，损失函数为 0。而且，误分类点越少，损失函数值越小。</p>
<h3 id="2-3-算法"><a href="#2-3-算法" class="headerlink" title="2.3 算法"></a>2.3 算法</h3><p>算法为求解损失函数极小化问题：</p>
<p>​        $\min\limits_{w,b}L(w,b)=-\sum\limits_{x_i\in M}y_i(\omega \cdot x_i+b)$</p>
<p>感知机学习算法是误分类驱动的，采用<strong>随机梯度下降法</strong>不断地极小化目标函数。极小化过程不是一次使素有误分类点的梯度下降，而是一次随机选取一个误分类点使其梯度下降。具体梯度为</p>
<p>​        $\nabla_\omega L(w,b)=-\sum\limits_{x_i\in M}y_ix_i$</p>
<p>​        $\nabla_bL(w,b)=-\sum\limits_{x_i\in M}y_i$</p>
<p>随机选取一个误分类点，对参数 ω 和 b 进行更新：</p>
<p>​        $\omega \leftarrow \omega+\eta y_ix_i$</p>
<p>​        $b \leftarrow b+\eta y_i$</p>
<p>其中，η 是步长，又称学习率。这样，通过迭代降低损失函数，直到为 0。</p>
<ul>
<li><p>可证明，线性可分的数据集可经过有限次迭代，得到完全正确划分的分离超平面及感知机模型。</p>
</li>
<li><p>感知机学习算法存在多解，这些解依赖于参数初值的选择，也依赖于选择误分类点进行参数更新的次序。</p>
</li>
<li>为了得到唯一的超平面，需要对分离超平面添加约束（参考线性支持向量机）。</li>
<li>当训练集线性不可分时，感知机学习算法不收敛，迭代结果会发生震荡。</li>
</ul>
<h2 id="三、k-近邻法"><a href="#三、k-近邻法" class="headerlink" title="三、k 近邻法"></a>三、k 近邻法</h2><p>k 近邻法（KNN）是一种基本的分类与回归方法。在分类任务中，k 近邻法的输入为实例的特征向量，输出为实例的类别，可以取多类。在预测时，根据其 k 个最近邻的类别，通过多数表决等方法进行预测。因此，k 近邻法不具有显式的学习过程。</p>
<p>k 近邻法的三个基本要素：<strong>k 值的选择</strong>、<strong>距离度量</strong>以及<strong>分类决策规则</strong>。</p>
<h3 id="3-2-模型"><a href="#3-2-模型" class="headerlink" title="3.2 模型"></a>3.2 模型</h3><p>当距离度量、k 值及分类决策规则确定后，对于任一新的输入实例，模型输出的类别唯一确定。</p>
<h4 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h4><p>特征空间中两个实例点的距离是两点<strong>相似程度</strong>的反映。可以使用欧氏距离度量，也可以使用更一般的 $L_p$ 距离：</p>
<p>​        $L_p(x_i,x_j)=(\sum\limits_{l=1}^n|x_i^{(l)}-x_j^{(l)}|^p)^{\frac{1}{p}}$</p>
<p>当 p = 1 时，称为曼哈顿距离；当 p = 2 时，称为欧式距离；当 p = ∞ 时，它是各个坐标距离的最大值。</p>
<h4 id="k-值的选择"><a href="#k-值的选择" class="headerlink" title="k 值的选择"></a>k 值的选择</h4><p>k 值的选择会对 k 近邻法的结果产生重大影响。</p>
<p>k 值较小时，学习的近似误差减小，只有与输入实例较近的实例才会对预测结果起作用。学习的估计误差会增大，预测结果对近邻的实例点非常敏感，容易受噪声影响。换句话说，k 值的减小意味着整个模型变得复杂，容易发生过拟合。</p>
<p>k 值较大时，可以减小学习的估计误差，但是近似误差会增大。这时输入实例较远的实例也会对预测起作用，使预测发生错误。k 值的增大意味着整个模型变得简单。</p>
<p>通常采用交叉验证法来选取最优的 k 值。</p>
<h4 id="分类决策规则"><a href="#分类决策规则" class="headerlink" title="分类决策规则"></a>分类决策规则</h4><p>通常采用多数表决，即由输入实例的 k 个近邻的实例中多数类决定输出实例的类。</p>
<p>多数表决等价于经验风险最小化。</p>
<h2 id="四、朴素贝叶斯法"><a href="#四、朴素贝叶斯法" class="headerlink" title="四、朴素贝叶斯法"></a>四、朴素贝叶斯法</h2><p>朴素贝叶斯法是基于<strong>贝叶斯定理</strong>与<strong>特征条件独立假设</strong>的分类方法。</p>
<p>对于给定的训练数据集，首先基于特征条件独立假设学习输入输出的联合概率分布；然后基于此模型，对给定的输入 x，利用贝叶斯定理求出后验概率最大的输出 y。</p>
<h3 id="4-1-朴素贝叶斯法的学习与分类"><a href="#4-1-朴素贝叶斯法的学习与分类" class="headerlink" title="4.1 朴素贝叶斯法的学习与分类"></a>4.1 朴素贝叶斯法的学习与分类</h3><p>朴素贝叶斯法通过徐连数据集学习联合概率分布 P(X, Y)。具体地，学习先验概率分布：</p>
<p>​        $P(Y=c_k), k=1,2,…,K$</p>
<p>以及条件概率分布：</p>
<p>​        $P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},…,X^{(n)}=x^{(n)}|Y=c_k), k=1,2,…,K$</p>
<p>于是学习到连个概率分布 P(X, Y)。</p>
<p>朴素贝叶斯法对条件概率分布作了<strong>条件独立性</strong>的假设：</p>
<p>​        $\begin{aligned}P(X=x|Y=c_k) &amp;=P(X^{(1)}=x^{(1)},…,X^{(n)}=x^{(n)}|Y=c_k) \\ &amp; = \prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)\end{aligned}$</p>
<p>朴素贝叶斯法分类时，对给定的输入 x，通过学习到的模型计算后验概率分布 $P(Y=c_k|X=x)$，将后验概率最大的类作为 x 的类输出。后验概率计算根据贝叶斯定理进行：</p>
<p>​        $P(Y=c_k|X=x)=\frac{P(X=x|Y=c_k)P(Y=c_k)}{\sum\limits_kP(X=x|Y=c_k)P(Y=c_k)}$</p>
<p>带入条件独立性假设，有</p>
<p>​        $P(Y=c_k|X=x)=\frac{P(Y=c_k)\prod\limits_jP(X^{(j)}=x^{(j)}|Y=c_k)}{\sum\limits_kP(Y=c_k)\prod\limits_jP(X^{(j)}=x^{(j)}|Y=c_k)}, k=1,2,…,K$</p>
<p>于是，<strong>朴素贝叶斯分类器</strong>可以表示为</p>
<p>​        $y=f(x)=arg\max\limits_{c_k} \frac{P(Y=c_k)\prod\limits_jP(X^{(j)}=x^{(j)}|Y=c_k)}{\sum\limits_kP(Y=c_k)\prod\limits_jP(X^{(j)}=x^{(j)}|Y=c_k)}, k=1,2,…,K$</p>
<p>注意到，上式中分母对所有 $c_k$ 都是相同的，所以</p>
<p>​        $y=arg\max\limits_{c_k}P(Y=c_k)\prod\limits_jP(X^{(j)}=x^{(j)}|Y=c_k)$</p>
<p>朴素贝叶斯法将实例分到<strong>后验概率最大</strong>的类中，这等价于期望风险最小化。</p>
<h3 id="4-2-朴素贝叶斯法的参数估计"><a href="#4-2-朴素贝叶斯法的参数估计" class="headerlink" title="4.2 朴素贝叶斯法的参数估计"></a>4.2 朴素贝叶斯法的参数估计</h3><h4 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h4><p>在朴素贝叶斯法中，学习意味着估计 $P(Y=c_k)$ 和 $P(X^{(j)}=x^{(j)}|Y=c_k)$。</p>
<p>先验概率 $P(Y=c_k)$ 的极大似然估计是</p>
<p>​        $P(Y=c_k)=\frac{\sum\limits_{i=1}^NI(y_i=c_k)}{N}, k=1,2,…,K$</p>
<p>条件概率 $P(X^{(j)}=x^{(j)}|Y=c_k)$ 的极大似然估计是</p>
<p>​        $P(X^{(j)}=a_{jl}|Y=c_k)=\frac{\sum\limits_{i=1}^NI(x_i^{(j)}=a_{jl},y=c_k)}{\sum\limits_{i=1}^NI(y_i=c_k)}$</p>
<p>​        $j=1,2,…,n; l=1,2,…,S_j; k=1,2,…,K$</p>
<p>其中，x 的第 j 个特征 $x^{(j)}$ 的取值范围集合为 $\{a_{j1},…,a_{jS_j}\}$，$x_i^{(j)}$ 是第 i 个岩本的第 j 个特征；$I$ 为指示函数。</p>
<h4 id="算法-1"><a href="#算法-1" class="headerlink" title="算法"></a>算法</h4><ol>
<li>计算先验概率及条件概率</li>
<li>对于给定的实例，计算后验概率</li>
<li>确定实例 x 的类：分到后验概率最大的类</li>
</ol>
<h4 id="贝叶斯估计"><a href="#贝叶斯估计" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h4><p>用极大似然估计可能会出现要估计的概率值为 0 的情况。这回影响到后验概率的计算结果，产生分类偏差。解决这一问题的方法是使用贝叶斯估计。具体地，条件概率的贝叶斯估计是</p>
<p><img src="https://s2.loli.net/2022/09/24/Ex9t6ASncizOvXp.png" alt="image-20220924193326950" style="zoom:67%;" /></p>
<p>式中 $\lambda\ge0$，当 λ = 0 时就是极大似然估计。</p>
<p>同样，先验概率的贝叶斯估计是</p>
<p><img src="https://s2.loli.net/2022/09/24/5HuajAdDTqlJMzZ.png" alt="image-20220924193510136" style="zoom:67%;" /></p>
<p>常取 λ = 1，这时称为拉普拉斯平滑。</p>
<h4 id="频率学派与贝叶斯学派"><a href="#频率学派与贝叶斯学派" class="headerlink" title="频率学派与贝叶斯学派"></a>频率学派与贝叶斯学派</h4><p><strong>频率学派</strong>认为世界是确定的，事件在多次重复实验中趋于一个稳定的值 p，这个值就是该事件的概率。</p>
<p>频率学派直接对事件本身建模，认为模型参数是定值，希望通过类似解方程组的方式从数据中求得该未知数。这就是<strong>频率学派使用的参数估计方法</strong>——<strong>极大似然估计（MLE）</strong>，这种方法往往在大数据量的情况下可以很好的还原模型的真实情况。</p>
<p><strong>贝叶斯学派</strong>则认为世界是不确定的，因获取的信息不同而不同。贝叶斯学派对世界有一个预先的估计，然后通过获取的信息来不断调整之前的估计。</p>
<p>贝叶斯学派不试图对事件本身进行建模，认为模型参数源自某种潜在分布，希望从数据中推知该分布。这就是<strong>贝叶斯学派用来估计参数的常用方法</strong>——<strong>最大后验概率估计（MAP）</strong>。这种方法在先验假设比较靠谱的情况下效果显著，随着数据量的增加，先验假设对于模型参数的主导作用会逐渐削弱，相反真实的数据样例会大大占据有利地位。如果把先验假设去掉，或者假设先验满足均匀分布的话，那它和极大似然估计就如出一辙了。</p>
<h4 id="极大似然估计与最大后验概率估计"><a href="#极大似然估计与最大后验概率估计" class="headerlink" title="极大似然估计与最大后验概率估计"></a>极大似然估计与最大后验概率估计</h4><p>根据已知的一些数据样本，来推测产生该数据的模型的参数，即<strong>已知数据，推测模型和参数</strong>。根据两大派别的不同，对于模型的参数估计方法也有两类：极大似然估计与最大后验概率估计。</p>
<p><strong>极大似然估计（MLE）</strong></p>
<p>极大似然就是最大化该事件发生的可能性。根据已知样本，希望通过调整模型参数来使得模型能够最大程度地符合样本情况出现的概率。</p>
<p>例如，一个盒子里面有红黑共10个球，每次有放回的取出，取了10次，结果为7次黑球，3次红球。问拿出黑球的概率 p 是多少？</p>
<p>假设7次黑球，3次红球的结果为事件 A，事件 A 发生的概率为 $P(A)=p^7*(1-p)^3$，极大似然估计就是让这个概率最大化，计算得 p = 0.7。</p>
<p><strong>最大后验概率（MAP）</strong></p>
<p>最大化在给定数据样本的情况下模型参数的后验概率。依然是根据已知样本，来通过调整模型参数使得模型能够产生该数据样本的概率最大，只不过<strong>对于模型参数有了一个先验假设</strong>，即<strong>模型参数可能满足某种分布</strong>，不再一味地依赖数据样例（万一数据量少或者数据不靠谱呢）。</p>
<p>例如，抛一枚硬币10次，有10次正面朝上，0次反面朝上。问正面朝上的概率 θ 。</p>
<p>在频率学派看来，用极大似然估计可以得到 θ = 1.0，但具有先验知识的我们直到，这显然是有很大偏差的。</p>
<p>如果利用最大后验概率来估计，先验认为符合概率分布 $P(\theta|X)$，最大值介于 0.5~1之间。</p>
<p>显然，随着数据量的增加，参数分布会更倾向于向数据靠拢，先验假设的影响会越来越小。</p>
<h2 id="五、决策树"><a href="#五、决策树" class="headerlink" title="五、决策树"></a>五、决策树</h2><p>决策树是一种基本的分类与回归方法。主要优点是模型具有可读性，分类速度快。</p>
<h3 id="5-1-决策树模型与学习"><a href="#5-1-决策树模型与学习" class="headerlink" title="5.1 决策树模型与学习"></a>5.1 决策树模型与学习</h3><p>分类决策树模型是一种描述对实例进行分类的树形结构。</p>
<p>可以将决策树看呈一个 if-then 规则的集合。由决策树的根结点到叶结点的每一条路径构建一条规则；路径上内部结点的特征对应着规则的条件，而叶结点的类对应着规则的结论。决策树的路径或其对应的 if-then 规则集合具有一个重要的性质：<strong>互斥并且完备</strong>。决策树还表示给定特征条件下类的条件概率分布。</p>
<p>决策树学习本质上是从训练数据集中归纳出一组分类规则。能正确分类的决策树可能有多个，也可能一个都没有。我们需要的是一个与训练数据矛盾较小的决策树，同时具有很好的泛化能力。</p>
<p>决策树学习的损失函数通常是<strong>正则化的极大似然函数</strong>。决策树学习的策略是最小化目标函数。因为从所有可能的决策树种选取最优决策树是 NP 完全问题，所以现实中决策树学习算法通常采用启发式方法，近似求解这一最优化问题。这样得到的决策树是次最优的。</p>
<p>决策树学习的算法通常是一个<strong>递归</strong>地选择最优特征，并根据该特征对训练数据进行分割，使得对各个子数据集有一个最好的分类的过程：</p>
<ul>
<li><p>开始，构建根结点，将所有训练数据都放在根结点。</p>
</li>
<li><p>选择一个最优特征，按照这一特征将训练数据集分割成子集，使得各个子集有一个在当前条件下最好的分类。如果这些子集已经能够被基本正确分类，那么构建叶结点，并将这些子集分到所对应的叶结点中去；如果还有子集不能被基本正确分类，那么就对这些自己选择新的最优特征，继续对其进行分割，构建相应的结点。</p>
</li>
<li>如此递归下去，直到所有训练数据子集被基本正确分类，或者没有合适的特征为止。</li>
<li>最后每个子集都被分类到叶结点上，即都有了明确的类，这就生成了一颗决策树。</li>
</ul>
<p>以上方法能对训练数据较好地分类，但可能发生过拟合现象。我们需要对已生成的树自下而上进行剪枝，使树变得更简单，从而提高泛化能力。具体地，就是去掉过于细分的叶结点，使其回退到父结点甚至更高的结点，然后将父结点或更高的结点改为新的叶结点。</p>
<p>可以看出，决策树学习算法包含<strong>特征选择</strong>、<strong>决策树的生成</strong>与<strong>决策树的剪枝</strong>过程。决策树的生成只考虑局部最优，相对地，决策树的剪枝则考虑全局最优。</p>
<h3 id="5-2-特征选择"><a href="#5-2-特征选择" class="headerlink" title="5.2 特征选择"></a>5.2 特征选择</h3><p>特征选择在于选取对训练数据具有分类能力的特征。如果利用一个特征进行分类的结果与随机分类的结果没有很大差别，则称这个特征是没有分类能力的，可以扔掉。通常特征选择的准则是<strong>信息增益</strong>或<strong>信息增益比</strong>。</p>
<p><strong>熵</strong></p>
<p>在信息论与概率统计中，熵（entropy）是表示随机变量<strong>不确定性</strong>的度量。设 X 是一个取有限个值的李赛随机变量，其概率分布为 $P(X=x_i)=p_i, i=1,2,…,n$，则随机变量 X 的熵定义为</p>
<p>​        $H(X)=-\sum\limits_{i=1}^np_ilogp_i$</p>
<p>由定义可知：</p>
<ul>
<li>熵只依赖于 X 的分布，与 X 的取值无关，所以也可将 X 的熵记作 H(p)</li>
<li>熵越大，随机变量的不确定性就越大</li>
<li>$0\le H(p)\le logn$</li>
</ul>
<p><strong>条件熵</strong></p>
<p>设有随机变量的联合概率分布</p>
<p>​        $P(X=x_i,Y=y_i)=p_{ij}$</p>
<p>条件熵 H(Y|X) 表示在已知随机变量 X 的条件下随机变量 Y 的不确定性，定义为 X 给定条件下 Y 的条件概率分布的熵对 X 的数学期望</p>
<p>​        $H(Y|X)=\sum\limits_{i=1}^np_iH(Y|X=x_i)$</p>
<p><strong>信息增益</strong></p>
<p>信息增益表示得知特征 X 的信息而使得类 Y 的信息的不确定性减少的程度。当熵和条件熵的概率由数据估计（特别是极大似然估计）得到时，所对应的熵与条件熵分别称为<strong>经验熵</strong>和<strong>经验条件熵</strong>。</p>
<p>特征 A 对训练数据集 D 的信息增益 g(D, A)，定义为集合 D 的经验熵 H(D) 与特征 A 给定条件下 D 的经验条件熵 H(D|A) 之差，即</p>
<p>​        $g(D,A)=H(D)-H(D|A)$</p>
<p>一般地，熵 H(Y) 与条件熵 H(Y|X) 之差称为<strong>互信息</strong>，决策树学习中的信息增益等价于训练数据集中类与特征的互信息。信息增益依赖于特征，不同的特征往往具有不同的信息增益，信息增益大的特征具有更强的分类能力。</p>
<p>根据信息增益准则的特征选择方法是：计算每个特征的信息增益，并比较它们的大小，选择信息增益最大的特征。</p>
<blockquote>
<p>设训练数据集为 D，|D|表示其样本容量。设有 K 个类 $C_k$，k=1, 2, …, K，$|C_k|$ 为属于类 $C_k$ 的样本个数。设特征 A 有 n 个不同的取值 $\{a_1,a_2,…,a_n\}$，根据特征 A 的取值将 D 划分为 n 个子集 $D_1,D_2,…,D_n$，$|D_i|$ 为 $D_i$ 的样本个数。设子集 $D_i$ 中属于类 $C_k$ 的样本的集合为 $D_{ik}$。</p>
</blockquote>
<p><strong>信息增益的算法</strong></p>
<ol>
<li>计算数据集 D 的经验熵 H(D)</li>
</ol>
<p>​        $H(D)=-\sum\limits_{k=1}^K\frac{|C_k|}{|D|}log_2\frac{|C_k|}{|D|}$</p>
<ol>
<li>计算特征 A 对数据集 D 的经验条件熵 H(D|A)</li>
</ol>
<p>​        $H(D|A)=\sum\limits_{i=1}^n\frac{|D_i|}{|D|}H(D_i)=-\sum\limits_{i=1}^n\frac{|D_i|}{|D|}\sum\limits_{k=1}^K\frac{|D_{ik}|}{|D_i|}log_2\frac{|D_{ik}|}{|D_i|}$</p>
<ol>
<li>计算信息增益</li>
</ol>
<p>​        $g(D,A)=H(D)-H(D|A)$</p>
<p><strong>信息增益比的算法</strong></p>
<p>以信息增益作为划分训练数据集的特征，存在偏向于选择取值较多的特征的问题。使用信息增益比可以对这一问题进行矫正。</p>
<p>信息增益比 $g_R(D,A)$ 定义为其信息增益 $g(D,A)$ 与训练数据集 D 关于特征 A 的值的熵 $H_A(D)$ 之比，即</p>
<p>​        $g_R(D,A)=\frac{g(D,A)}{H_A(D)}$</p>
<p>其中，$H_A(D)=-\sum\limits_{i=1}^n\frac{|D_i|}{|D|}log_2\frac{|D_i|}{|D|}$，n 是特征 A 取值的个数。</p>
<h3 id="5-3-决策树的生成"><a href="#5-3-决策树的生成" class="headerlink" title="5.3 决策树的生成"></a>5.3 决策树的生成</h3><h4 id="ID3-算法"><a href="#ID3-算法" class="headerlink" title="ID3 算法"></a>ID3 算法</h4><p>ID3 算法的核心是在决策树各个结点上应用<strong>信息增益</strong>准则选择特征，递归地构建决策树。ID3 相当于用极大似然法进行概率模型的选择。</p>
<p>ID3 算法只有树的生成，所以该算法生成的树容易产生过拟合。</p>
<h4 id="C4-5-算法"><a href="#C4-5-算法" class="headerlink" title="C4.5 算法"></a>C4.5 算法</h4><p>C4.5 在生成的过程中，用信息增益比来选择特征。</p>
<h3 id="5-4-决策树的剪枝"><a href="#5-4-决策树的剪枝" class="headerlink" title="5.4 决策树的剪枝"></a>5.4 决策树的剪枝</h3><p>递归生成决策树往往对训练数据分类的很准确，但对位置的测试数据的分类却没有那么准确，即出现过你和现象。对决策树进行简化的过程称为<strong>剪枝</strong>，有助于提高模型的泛化能力。</p>
<p>决策树的剪枝往往通过极小化决策树整体的损失函数来实现。</p>
<blockquote>
<p>设树 T 的结点个数为 |T|，t 是树 T 的叶节点，该叶节点有 $N_t$ 个样本点，其中 k 类的样本点有 $N_{tk}$ 个，k = 1, 2, …, K，$H_t(T)$ 为叶节点 t 上的经验熵，$\alpha\ge0$ 为参数。</p>
</blockquote>
<p>决策树学习的损失函数定义为</p>
<p>​        $C_\alpha(T)=\sum\limits_{t=1}^{|T|}N_tH_t(T)+\alpha|T|$</p>
<p>将损失函数右端的第 1 项记作</p>
<p>​        $C(T)=\sum\limits_{t=1}^{|T|}N_tH_t(T)$</p>
<p>这时有</p>
<p>​        $C_\alpha(T)=C(T)+\alpha|T|$</p>
<p>式中，C(T) 表示模型对训练数据的预测误差，即模型与训练数据的拟合程度，|T|表示模型复杂度，参数 α 控制两者之间的影响。较大的 α 促使选择较简单的模型，较小的 α 促使选择较复杂的模型。α = 0 意味着只考虑模型与训练数据的拟合程度，不考虑模型对复杂度。</p>
<p>剪枝，就是当 α 确定时，选择损失函数最小的模型。当 α 确定时，子树越大，往往训练数据的拟合越好，但是模型的复杂度就越高；设一组叶节点回缩到其父节点之前与之后的整体树分别为 TB 与 TA，其对应的损失函数值分别是 $C_\alpha(T_B)$ 与 $C_\alpha(T_A)$，如果 $C_\alpha(T_A) \le C_\alpha(T_B)$，则进行剪枝，即将父节点变为新的叶节点。重复剪枝过程，直至不能继续，得到损失函数最小的子树 $T_\alpha$。</p>
<h3 id="5-5-CART-算法"><a href="#5-5-CART-算法" class="headerlink" title="5.5 CART 算法"></a>5.5 CART 算法</h3><p>分类与回归树（classification and regression tree，CART）模型<strong>既可以用于分类也可以用于回归</strong>。</p>
<p>CART 事在给定输入随机变量 X 条件下输出随机变量 Y 的条件概率分布的学习方法。CART 假设决策树是二叉树，内部节点特征的取值是“是”和“否”，左分支取值为“是”，右分支取值为“否”。这样的决策树等价于递归地二分每个特征，将输入空间划分为有限个单元，并在这写单元上确定预测的概率分布，也就是在输入给定的条件下输出条件概率分布。</p>
<p>CART 算法包括决策树生成与决策树剪枝两个步骤。</p>
<h4 id="CART-生成"><a href="#CART-生成" class="headerlink" title="CART 生成"></a>CART 生成</h4><p>递归地构建二叉树的过程，对回归树用<strong>平方误差最小化</strong>准则，对分类树用<strong>基尼指数</strong>最小化准则，进行特征选择，生成二叉树。</p>
<ol>
<li>回归树的生成</li>
</ol>
<p>在训练数据集所在的输入空间中，递归地将每个区域划分为两个子区域并决定每个子区域上的输出值，构建二叉决策树：</p>
<p>（1）选择最优切分变量 j 与切分点 s，求解</p>
<p><img src="https://s2.loli.net/2022/10/08/5w4NzR7dnOWLDVZ.png" alt="image-20221008094355125" style="zoom: 67%;" /></p>
<p>遍历变量 j，对固定的切分变量 j 扫描切分点 s，选择使上式达到最小值的对 (j, s)。</p>
<p>（2）用选定的对 (j, s) 划分区域并决定相应的输出值：</p>
<p><img src="https://s2.loli.net/2022/10/08/1VML4dHECJAqfoD.png" alt="image-20221008094903245" style="zoom:67%;" /></p>
<p>（3）继续对两个子区域调用步骤（1），（2）直至满足停止条件。</p>
<p>（4）将输入空间划分为 M 个区域 R1, R2, …, RM，生成决策树：</p>
<p>​        $f(x)=\sum\limits_{m=1}^M \hat{c}_mI(x\in R_m)$</p>
<p>当输入空间的划分确定时，用平方误差 $\sum\limits_{x_i\in R_m}(y_i-f(x_i))^2$ 来表示回归树对于训练数据的预测误差，用平方误差最小的准则求解每个单元上的最优输出值。</p>
<ol>
<li>分类树的生成</li>
</ol>
<p>分类树用基尼指数选择最优特征，同时决定该特征的最优二值切分点。</p>
<p><strong>基尼指数</strong></p>
<p>分类问题中，假设有 K 个类，样本点属于第 k 类的概率为 $p_k$，则概率分布的基尼指数定义为</p>
<p>​        $Gini(p)=\sum\limits_{k=1}^Kp_k(1-p_k)=1-\sum\limits_{k=1}^Kp_k^2$</p>
<p>对于二分类问题，$Gini(p)=2p(1-p)$</p>
<p>对于给定样本集合 D，基尼指数为</p>
<p>​        $Gini(D)=1-\sum\limits_{k=1}^K(\frac{|C_k|}{|D|})^2$</p>
<p>这里，$C_k$ 是 D 中属于第 k 类的样本子集，K 是类的个数。</p>
<p>如果样本集合 D 根据特征 A 被划分为 D1 和 D2 两个部分，则在特征 A 的条件下，集合 D 的基尼指数定义为</p>
<p>​        $Gini(D, A)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)$</p>
<p>基尼指数 Gini(D) 表述集合 D 的不确定性，基尼指数值越大，表示样本集合的不确定性就越大。</p>
<p>在选择特征的切分点时，选择基尼指数最小的特征及其对应的切分点作为最优特征于最优切分点。算法停止计算的条件是结点中的样本个数小于预定阈值或样本集的基尼指数小于预定阈值，或者没有更多特征。</p>
<h4 id="CART-剪枝算法"><a href="#CART-剪枝算法" class="headerlink" title="CART 剪枝算法"></a>CART 剪枝算法</h4><p>（1）设 k = 0，T = T0</p>
<p>（2）设 α = +∞</p>
<p>（3）自下而上地对各内部节点 t 计算 $C(T_t), |T_t|$ 以及</p>
<p>​        $g(t)=\frac{C(t)-C(T_t)}{|T_t|-1}$</p>
<p>​        $\alpha=min(\alpha,g(t))$</p>
<p>这里，Tt 表示以 t 为根节点的子树，$C(T_t)$ 是对训练数据的预测误差，$|T_t|$ 是 Tt 的叶节点个数。</p>
<p>（4）对 $g(t)=\alpha$ 的内部节点 t 进行剪枝，并对叶节点 t 以多数表决法决定其类，得到树 T</p>
<p>（5）设 k = k + 1，$\alpha_k=\alpha, T_K=T$</p>
<p>（6）如果 Tk 不是由根节点及两个叶节点构成的树，则回到步骤（2）；否则令 $T_k=T_n$</p>
<p>（7）采用交叉验证法在子树序列 T0, T1, …, Tn 中选取最优子树 $T_\alpha$。</p>
<h2 id="六、逻辑回归与最大熵模型"><a href="#六、逻辑回归与最大熵模型" class="headerlink" title="六、逻辑回归与最大熵模型"></a>六、逻辑回归与最大熵模型</h2><p>逻辑回归（logistic regression）是经典分类算法。最大熵是概率模型学习的一个准则。逻辑回归模型与最大熵模型都属于<strong>对数线性模型</strong>。</p>
<h3 id="6-1-逻辑回归模型"><a href="#6-1-逻辑回归模型" class="headerlink" title="6.1 逻辑回归模型"></a>6.1 逻辑回归模型</h3><h4 id="逻辑分布"><a href="#逻辑分布" class="headerlink" title="逻辑分布"></a>逻辑分布</h4><p>设 X 是连续随机变量，X 服从逻辑分布是指 X 具有以下分布函数和密度函数：</p>
<p><img src="https://s2.loli.net/2022/10/08/dZxFqlPSgmUHQc8.png" alt="image-20221008101521888" style="zoom:67%;" /></p>
<p><img src="https://s2.loli.net/2022/10/08/HGZUOiY6gkjKVJ7.png" alt="image-20221008102842870" style="zoom:67%;" /></p>
<h4 id="二项逻辑回归模型"><a href="#二项逻辑回归模型" class="headerlink" title="二项逻辑回归模型"></a>二项逻辑回归模型</h4><p>二项逻辑回归随机变量 Y 取值为 1 或 0，条件规律分布如下：</p>
<p><img src="https://s2.loli.net/2022/10/08/Y4q2rm1KPF5Xb8R.png" alt="image-20221008104905689" style="zoom:67%;" /></p>
<p>逻辑回归比较两个条件概率值的大小，将实例 x 分到概率值较大的那一类。其中，w, b 是学习参数。</p>
<p>一个事件的<strong>几率</strong>（odds）是指该事件发生的概率与不发生的概率的比值。如果事件发生的概率是 p，那么该事件的几率是 $\frac{p}{1-p}$，该事件的<strong>对数几率</strong>或 <strong>logit 函数</strong>是</p>
<p>​        $logit(p)=log\frac{p}{1-p}$</p>
<p>则 $log\frac{P(Y=1|x)}{1-P(Y=1|x)}=w\cdot x$</p>
<p>这就是说，逻辑回归模型中，输出 Y = 1 的对数几率是输入 x 的线性函数。</p>
<h4 id="模型参数估计"><a href="#模型参数估计" class="headerlink" title="模型参数估计"></a>模型参数估计</h4><p>可以用用极大似然估计法估计模型参数，从而得到逻辑回归模型。</p>
<p>设 $P(Y=1|x)=\pi(x), P(Y=0|x)=1-\pi(x)$</p>
<p>似然函数为 $\prod\limits_{i=1}^N[\pi(x_i)]^{y_i}[1-\pi(x_i)]^{1-y_i}$</p>
<p>对数似然函数为</p>
<p><img src="https://s2.loli.net/2022/10/08/2klwHvGsK1juxJO.png" alt="image-20221008105833323" style="zoom:67%;" /></p>
<p>对 L(w) 求极大值，得到 w 的估计值。</p>
<p>这样，问题就变成了以<strong>对数似然函数</strong>为目标函数的最优化问题。通常采用<strong>梯度下降法</strong>及<strong>拟牛顿法</strong>。</p>
<h3 id="6-2-最大熵模型"><a href="#6-2-最大熵模型" class="headerlink" title="6.2 最大熵模型"></a>6.2 最大熵模型</h3><h4 id="最大熵原理"><a href="#最大熵原理" class="headerlink" title="最大熵原理"></a>最大熵原理</h4><p>最大熵原理认为，学习概率模型时，在所有可能的概率模型（分布）中，<strong>熵最大的模型是最好的模型</strong>。最大熵原理也可以表述为在满足约束条件的模型集合中选取熵最大的模型。</p>
<p>假设离散随机变量 X 的概率分布是 P(X)，则其熵是 $H(P)=-\sum\limits_xP(x)logP(x)$</p>
<p>熵满足下列不等式：$0\le H(P)\le log|X|$，其中 |X| 是 X 的取值个数，当 X 服从<strong>均匀分布</strong>时，熵最大。</p>
<h4 id="最大熵模型"><a href="#最大熵模型" class="headerlink" title="最大熵模型"></a>最大熵模型</h4><p>将最大熵原理应用到分类得到最大熵模型。</p>
<p>给定训练数据集，可以确定联合分布 P(X, Y) 的经验分布和边缘分布 P(X) 的经验分布：</p>
<p><img src="https://s2.loli.net/2022/10/08/MfoSPvOaC147qVA.png" alt="image-20221008111656541" style="zoom:67%;" /></p>
<p>其中，$\nu(X=x,Y=y)$ 表示训练数据中样本 (x, y) 出现的频数，N 表示训练样本容量。</p>
<p>用特征函数 f(x, y) 描述输入 x 和输入 y 之间的某一个事实，其定义是：</p>
<p>​        $f(x, y)=\begin{cases}1,&amp;x与y满足某一事实\\0,&amp;否则\end{cases}$</p>
<p>特征函数 f(x, y) 关于经验分布 $\tilde P(X,Y)$ 的期望值：</p>
<p>​        $E_{\tilde P}(f)=\sum\limits_{x,y}\tilde P(x,y)f(x,y)$</p>
<p>特征函数 f(x, y) 关于模型 P(Y|X) 与经验分布 $\tilde P(X)$ 的期望值：</p>
<p>​        $E_P(f)=\sum\limits_{x,y}\tilde P(x)P(y|x)f(x,y)$</p>
<p>如果模型能够获取训练数据中的信息，那么就可以假设这连个期望值相等，即 $E_P(f)=E_\tilde P(f)$</p>
<p>将 $E_P(f)=E_\tilde P(f)$ 作为模型学习的约束条件。</p>
<p>假设满足所有约束条件的模型集合为</p>
<p><img src="https://s2.loli.net/2022/10/08/ilb6eOtmJAPGNyK.png" alt="image-20221008114621806" style="zoom:67%;" /></p>
<p>定义在条件概率分布 P(Y|X) 上的条件熵为</p>
<p>​        $H(P)=-\sum\limits_{x,y}\tilde P(x)P(y|x)logP(y|x)$</p>
<p>则模型集合 C 中条件熵 H(P) 最大的模型称为最大熵模型。</p>
<h4 id="最大熵模型的学习"><a href="#最大熵模型的学习" class="headerlink" title="最大熵模型的学习"></a>最大熵模型的学习</h4><p>最大熵模型的学习过程就是求解最大熵模型的过程，可以形式化为约束最优化问题：</p>
<p><img src="https://s2.loli.net/2022/10/08/R6kC2y78jlar4DI.png" alt="image-20221008135722149" style="zoom:67%;" /></p>
<p>等价的最小值问题：</p>
<p><img src="https://s2.loli.net/2022/10/08/hfCEjva58bDFeHy.png" alt="image-20221008135747620" style="zoom:67%;" /></p>
<p>求解最优化问题的解就是最大熵模型学习的解。</p>
<h2 id="七、支持向量机"><a href="#七、支持向量机" class="headerlink" title="七、支持向量机"></a>七、支持向量机</h2><p>支持向量机（support vector machines，SVM）的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大是它有别于感知机；支持向量机还包括核技巧，这使它称为实质上的非线性分类器。支持向量机的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。支持向量机的学习算法时求解凸二次规划的最优化算法。</p>
<ul>
<li>线性可分支持向量机</li>
<li>线性支持向量机</li>
<li>非线性支持向量机</li>
</ul>
<h3 id="7-1-线性可分支持向量机"><a href="#7-1-线性可分支持向量机" class="headerlink" title="7.1 线性可分支持向量机"></a>7.1 线性可分支持向量机</h3><p>考虑一个二分类问题。假设输入空间与特征空间为两个不同的空间，输入空间为欧氏空间或离散集合，特征空间为欧氏空间或希尔伯特空间。假设这两个空间的元素一一对应，并将输入空间中的输入映射为特征空间中的特征向量。</p>
<p>学习的目标是在特征空间中找到一个分离超平面，能将实例分到不同的类。当训练数据集线性可分时，存在无穷个分离超平面可将两类数据正确分开。感知机利用误分类最小的策略求得分离超平面，不过这时的解有无穷多个。线性可分支持向量机利用间隔最大化求最优分离超平面，这时，解是唯一的。</p>
<p>定义学习得到的分离超平面为</p>
<p>​        $w\cdot x+b=0$</p>
<p>相应的分类决策函数</p>
<p>​        $f(x)=sign(w\cdot x+b)$</p>
<p>称为<strong>线性可分支持向量机</strong>。</p>
<p><strong>函数间隔</strong>为 $\tilde \gamma_i=y_i(w\cdot x_i+b)$</p>
<p><strong>超平面</strong>为函数间隔最小值 $\tilde \gamma=\min\limits_{i=1,…,N}\tilde\gamma_i$</p>
<p>函数间隔可以表示分类预测的正确性及确信度，但是选择分离超平面时，只有函数间隔还不够，因为成比例地改变 w 和 b，超平面并没有改变，但是函数间隔却变化了。因此，可以对分离超平面的法向量 w 加某些约束，如规范化，||w|| = 1，使得间隔是确定的。这时函数间隔成为几何间隔。</p>
<p>​        $\gamma_i=\frac{w}{||w||}\cdot x_i+\frac{b}{||w||}$</p>
<p>其中，||w||为 w 的 L2 范数。这是点 A 在超平面正的一侧的情形。如果在负的一侧，即 $y_i=-1$，那么点与超平面的距离为</p>
<p>​        $\gamma_i=-(\frac{w}{||w||}\cdot x_i+\frac{b}{||w||})$</p>
<p>一般地，当样本点 $(x_i,y_i)$ 被超平面 (w, b) 正确分类时，点 $x_i$ 与超平面 (w, b) 的距离是</p>
<p>​        $\gamma_i=y_i(\frac{w}{||w||}\cdot x_i+\frac{b}{||w||})$</p>
<p>也就是超平面的<strong>几何间隔</strong>。</p>
<h4 id="间隔最大化"><a href="#间隔最大化" class="headerlink" title="间隔最大化"></a>间隔最大化</h4><p>对线性可分的训练数据集而言，线性可分分离超平面有无穷多个（等价于感知机），但是几何间隔最大的分离超平面是唯一的。间隔最大化是找到几何间隔最大的超平面，可以表示为约束最优化问题：</p>
<p><img src="https://s2.loli.net/2022/10/08/BQMYjOPD7ZzAdW5.png" alt="image-20221008152501239" style="zoom:67%;" /></p>
<p>函数间隔的取值并不影响最优化问题的解，可以取 $\gamma=1$。注意到，最大化 $\frac{1}{||w||}$ 和最小化 $\frac{1}{2}||w||^2$ 是等价的，于是得到下面的最优化问题：</p>
<p><img src="https://s2.loli.net/2022/10/08/FvIUCKOoMiPs2bx.png" alt="image-20221008182838868" style="zoom:67%;" /></p>
<p>这是一个凸二次规划问题。求解该约束最优化问题，用到了<strong>最大间隔法</strong>。</p>
<p><img src="https://s2.loli.net/2022/10/08/6KpZDUvVwNYazyd.png" alt="image-20221008183301219" style="zoom:67%;" /></p>
<p>H1、H2是两个超平面，在 H1、H2 上的点就是<strong>支持向量</strong>。H1 与 H2 平行，并且没有点落在它们中间。H1 与 H2 之间的距离称为<strong>间隔</strong>，间隔等于 $\frac{2}{||w||}$。H1、H2 称为<strong>间隔边界</strong>。</p>
<p>在决定分离超平面时只有支持向量起作用，其他实例点不起作用。支持向量的个数一般很少，所以支持向量机由很少的“重要的”训练样本确定。</p>
<h3 id="7-2-线性支持向量机与软间隔最大化"><a href="#7-2-线性支持向量机与软间隔最大化" class="headerlink" title="7.2 线性支持向量机与软间隔最大化"></a>7.2 线性支持向量机与软间隔最大化</h3><h4 id="线性支持向量机"><a href="#线性支持向量机" class="headerlink" title="线性支持向量机"></a>线性支持向量机</h4><p>线性可分支持向量机对线性不可分的训练数据是不适用的，因为约束条件并不能都成立。为了扩展到线性不可分问题，需要将硬间隔最大化修改为软间隔最大化。</p>
<p>线性不可分的数据集通常有一些特异点，去掉这些特异点后，剩下的大部分样本点组成的集合是线性可分的。线性不可分意味着某些样本点 $(x_i,y_i)$ 不能满足函数间隔大于等于 1 的约束条件。为了解决这个问题，可以对每个样本点引进一个松弛变量 $\xi_i\ge 0$，使函数间隔加上松弛变量大于等于 1。这样，约束条件变为</p>
<p>​        $y_i(w\cdot x_i+b)\ge1-\xi_i$</p>
<p>目标函数变为</p>
<p>​        $\frac{1}{2}||w||^2+C\sum\limits_{i=1}^N\xi_i$</p>
<p>这里，C &gt; 0 为惩罚参数，C 值大时对误分类的惩罚增大。相应的学习问题称为软间隔最大化。</p>
<p><img src="https://s2.loli.net/2022/10/08/TcnE2MRYzpbgkjK.png" alt="image-20221008184955782" style="zoom: 67%;" /></p>
<p>可以证明 w 的解是唯一的，但 b 的解可能不唯一，而是存在一个区间。</p>
<h3 id="7-3-非线性支持向量机与核函数"><a href="#7-3-非线性支持向量机与核函数" class="headerlink" title="7.3 非线性支持向量机与核函数"></a>7.3 非线性支持向量机与核函数</h3><h4 id="核技巧"><a href="#核技巧" class="headerlink" title="核技巧"></a>核技巧</h4><p>非线性分类问题是指通过利用非线性模型才能很好地进行分类的问题。非线性问题往往不好求解，采取的方法是进行一个非线性变换，将非线性问题变换为线性问题，通过解变换后的线性问题的方法求解原来的非线性问题。</p>
<p>核技巧应用到支持向量机，其基本想法就是通过一个非线性变换将输入空间对应于一个特征空间，使得在输入空间中的超曲面模型对应于特征空间中的超平面模型（支持向量机）。这样通过在特征空间中求解线性支持向量机就可以完成。</p>
<p><strong>核函数</strong></p>
<p>设 $\mathcal{X}$ 是输入空间（欧氏空间 $R^n$ 的子集或离散集合），$\mathcal{H}$ 为特征空间（希尔伯特空间），如果存在一个从 $\mathcal{X}$ 到 $\mathcal{H}$ 的映射</p>
<p>​        $\phi(x):\mathcal{X}\rightarrow\mathcal{H}$</p>
<p>使得对所有 $x,z\in\mathcal{X}$，函数 $K(x,z)$ 满足条件</p>
<p>​        $K(x,z)=\phi(x)\cdot\phi(z)$</p>
<p>则称 K(x, z) 为核函数，$\phi(x)$ 为映射函数。</p>
<p>核技巧在学习与预测中之定义核函数 K(x, z)，而不显式地定义映射函数 $\phi$。通常，直接计算 K(x, z) 比较容易，而通过 $\phi(x)$ 和 $\phi(z)$ 计算 K(x, z) 并不容易。映射函数 $\phi$ 的取法并不唯一。学习是隐式地在特种空间进行的，不需要显式地定义特征空间和映射函数。在实际应用中，往往依赖领域知识直接选择核函数，核函数的有效性需要通过实验验证。</p>
<h4 id="常用核函数"><a href="#常用核函数" class="headerlink" title="常用核函数"></a>常用核函数</h4><ul>
<li>多项式核函数（polynomial kernel function）</li>
</ul>
<p>​        $K(x,z)=(x\cdot z+1)^p$</p>
<ul>
<li>高斯核函数（Gaussian kernel function）</li>
</ul>
<p>​        $K(x,z)=exp(-\frac{||x-z||^2}{2\sigma^2})$</p>
<h2 id="八、提升方法"><a href="#八、提升方法" class="headerlink" title="八、提升方法"></a>八、提升方法</h2><p>提升（<strong>boosting</strong>）方法在分类问题中，通过改变训练样本的权重，学习多个分类器，并将这些分类器进行线性组合，提高分类的性能。</p>
<h3 id="8-1-AdaBoost-算法"><a href="#8-1-AdaBoost-算法" class="headerlink" title="8.1 AdaBoost 算法"></a>8.1 AdaBoost 算法</h3><p>提升方法的思想是：对于一个复杂任务来说，将多个专家的判断进行适当的综合得出的判断，要比其中任何一个专家单独的判断好。</p>
<p>对于分类问题而言，给定一个训练样本集，求比较粗糙的分类规则（弱分类器）要比求精确的分类规则（强分类器）容易得多。提升方法通过反复学习得到一系列弱分类器（基本分类器），然后组合这些弱分类器，构成一个强分类器。大多数的提升方法都是改变训练数据的概率分布（权值分布），针对不同的训练数据分布学习一系列弱分类器。</p>
<p>如何改变训练数据的权值或概率分布？AdaBoost 的做法是，<strong>提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值。</strong></p>
<p>如何将弱分类器组合成一个强分类器？AdaBoost 采取加权多数表决的方法，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用；减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。</p>
<p>在训练过程中，它不改变所给的训练数据，而是<strong>不断改变训练数据权值的分布</strong>，使得被误分类的数据再后一轮的分类中受到更大的关注。</p>
<h3 id="8-2-GBDT"><a href="#8-2-GBDT" class="headerlink" title="8.2 GBDT"></a>8.2 GBDT</h3><h4 id="提升树"><a href="#提升树" class="headerlink" title="提升树"></a>提升树</h4><p>提升树是以分类树或回归树为基本分类器的提升方法，被认为是统计学习中性能最好的方法之一。提升树实际采用<strong>加法模型</strong>（基函数的线性组合）与前向分步算法。以决策树为基函数的提升方法称为提升树（boosting tree）。</p>
<h4 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h4><p>GBDT（Gradient Boosting Decision Tree） 是基于 boosting 的思想，串行地构造多棵决策树来进行数据的预测，它是在损失函数所在的函数空间中做梯度下降，即把待求的决策树模型当作参数，每轮迭代都去拟合损失函数在当前模型下的负梯度，从而使得参数朝着最小化损失函数的方向更新。</p>
<p>GBDT 可以看作是 AdaBoost 的一个推广，AdaBoost 是通过<strong>错分数据点</strong>来识别问题，通过调整错分数据点的权重来改进模型，GBDT 是通过<strong>负梯度</strong>来识别问题，通过计算负梯度来改进模型，实际上，负梯度绝对值大的样例同样会在之后的训练中受到更大的关注。相比 AdaBoost, Gradient Boosting 可以使用更多类型的损失函数，因此可以解决更多的问题。</p>
<h3 id="8-3-随机森林（Random-Forest）"><a href="#8-3-随机森林（Random-Forest）" class="headerlink" title="8.3 随机森林（Random Forest）"></a>8.3 随机森林（Random Forest）</h3><p>随机森林算法背后的思想是群体智慧的体现，它通过<strong>随机的行采样</strong>（bagging）和<strong>列采样</strong>（feature bagging）构造不同的训练集，建立一个决策树森林，利用加权平均方式或多数表决的方式得到最后的预测结果。随机森林能够并行学习，对噪声和异常数据具有很好的过滤作用，因此有很广泛的应用。</p>
<p>随机森林的行采样（bagging）和列采样（feature bagging）都是为了<strong>减小模型之间的相关性</strong>使基学习器变得不同从而<strong>减小集成模型的方差</strong>，但这种随机性会导致随机森林的偏差有所增加（相比于单棵不随机树），因此随机森林的单棵树都会采用很深的决策树，<strong>并不进行剪枝操作</strong>，以减小每棵树的偏差，这使得每一棵决策树就是一个精通于某一个窄领域的专家（因为我们从全部特征中选择部分特征来让每一棵决策树学习），这样在随机森林中就有了很多个精通不同领域的专家，对一个新的问题（新的输入数据），可以用不同的角度去看待它，最终再通过投票或平均得到结果。这也正是群体智慧的体现。</p>
<h3 id="8-4-XGboost"><a href="#8-4-XGboost" class="headerlink" title="8.4 XGboost"></a>8.4 XGboost</h3><p>XGboost 是梯度提升树（GBDT）的一种高效系统实现，是对 GBDT 进一步的改进，包括对代价函数进行了二阶泰勒展开，在代价函数里加入了正则项，借鉴了随机森林的列采样方法，支持并行计算等。具体为：</p>
<ul>
<li>传统 GBDT 在优化时只用到一阶导数信息，xgboost 则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。另外，xgboost 工具支持自定义代价函数，只要函数可一阶和二阶求导。</li>
<li>xgboost 在代价函数里加入了正则项，用于控制模型的复杂度。正则项降低了模型的方差，使学习出来的模型更加简单，防止过拟合。</li>
<li>xgboost 借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算。</li>
<li>xgboost 工具支持并行。xgboost 也是一次迭代完才能进行下一次迭代，它的并行是在特征粒度上的。决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），xgboost 在训练之前，预先对数据进行了排序，然后保存为 block 结构，后面的迭代中重复地使用这个结构，大大减小计算量。</li>
</ul>
<h3 id="8-5-LightGBM"><a href="#8-5-LightGBM" class="headerlink" title="8.5 LightGBM"></a>8.5 LightGBM</h3><p>LightGBM 是一个实现 GBDT 算法的<strong>分布式</strong>高效框架。它通过 <strong>leaf-wise 分裂方法</strong>进行决策树的生成，通过基于<strong>直方图</strong>的算法寻找特征分割点，并支持并行学习，能够更高效的处理大数据，也得到了越来越广泛的应用。</p>
<p>要减少训练的复杂度，可以通过减少特征量和数据量来实现，即从行和列两个角度来减少数据，同时要尽可能少的影响最后的精度。在 LightGBM 中，就是这样做的，对应着 GOSS 和 EFB：</p>
<ul>
<li>Gradient-based One-Side Sampling (GOSS)：GBDT 虽然没有数据权重，但每个数据实例有不同的梯度，根据计算信息增益的定义，梯度大的实例对信息增益有更大的影响，因此在下采样时，我们应该尽量保留梯度大的样本（预先设定阈值，或者最高百分位间），随机去掉梯度小的样本。此措施在相同的采样率下比随机采样获得更准确的结果，尤其是在信息增益范围较大时。从而减少训练的样本数量。</li>
<li>Exclusive Feature Bundling (EFB)：通常在真实应用中，虽然特征量比较多，但是由于特征空间十分稀疏，许多特征几乎是互斥的（例如许多特征不会同时为非零值，像 one-hot），EFB 通过<strong>捆绑互斥</strong>的特征，并将捆绑问题<strong>归约到图着色问题</strong>，通过<strong>贪心算法</strong>求得近似解，以减少特征数量。</li>
</ul>
<p>另外，它支持并行学习，包括<strong>特征并行</strong>和<strong>数据并行</strong>：</p>
<ul>
<li>特征并行的主要思想是不同机器在不同的特征集合上分别寻找最优的分割点，然后在机器间同步最优的分割点。（mapreduce （分治）思想）</li>
<li>数据并行则是让不同的机器先在不同的记录集合上构造直方图，然后进行全局的合并，最后在合并的直方图上面寻找最优分割点。</li>
</ul>
<h3 id="8-6-bagging-与-boosting-的区别？"><a href="#8-6-bagging-与-boosting-的区别？" class="headerlink" title="8.6 bagging 与 boosting 的区别？"></a>8.6 bagging 与 boosting 的区别？</h3><p>Bagging 和 Boosting 都是将已有的分类或回归算法通过一定方式组合起来，形成一个性能更加强大的分类器，即<strong>将弱分类器组装成强分类器的方法</strong>。</p>
<p>首先介绍 <strong>Bootstraping</strong>（自助法），是一种有放回的抽样方法。</p>
<p><strong>Bagging</strong>（套袋法），算法过程如下：</p>
<ul>
<li>从原始样本集 D 中抽取训练集。每轮从原始样本集 D 中使用 Bootstraping 自助的方法抽取 n 个训练样本（有些样本可能被多次抽取到，而有些样本可能一次都没有被抽中）。共进行 k 轮抽取，得到 k 个训练集。（k个训练集之间是相互独立的）</li>
<li>每次使用一个训练集得到一个模型，k 个训练集共得到 k 个模型。</li>
<li>对于分类问题，将上步得到的 k 个模型采用投票的方式得到分类结果；对回归问题，计算上述模型的均值作为最后的结果。</li>
</ul>
<p><strong>Boosting</strong>（提升法）的主要思想是将弱分类器组装成一个强分类器。关于 Boosting 的两个核心问题：</p>
<ul>
<li>每一轮如何改变训练数据的权值或概率分布？</li>
</ul>
<p>​    通过提高那些在前一轮被弱分类器分错样例的权值，减小前一轮分对样例的权值，来使得分类器对误分的数据更多的关注。</p>
<ul>
<li>通过什么方式来组合弱分类器？</li>
</ul>
<p>​    通过加法模型将弱分类器进行线性组合，比如 AdaBoost 通过加权多数表决的方式，即增大错误率小的分类器的权值，同时减小错误率较大的分类器的权值。</p>
<p><strong>两者区别：</strong></p>
<ul>
<li>样本选择：<ul>
<li>Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。</li>
<li>Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。</li>
</ul>
</li>
<li>样本的权重：<ul>
<li>Bagging：使用均匀取样，每个样例的权重相等。</li>
<li>Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。</li>
</ul>
</li>
<li>预测函数：<ul>
<li>Bagging：所有预测函数的权重相等。</li>
<li>Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。</li>
</ul>
</li>
<li>并行计算：<ul>
<li>Bagging：各个预测函数可以并行生成。</li>
<li>Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。</li>
</ul>
</li>
</ul>
<p>Bagging + 决策树 = 随机森林（Random Forest）</p>
<p>AdaBoost + 决策树 = 提升树（Boosting Tree）</p>
<p>Gradient Boosting + 决策树 = GBDT</p>
<p><strong>两者之间如何选择？</strong></p>
<p>Bagging 通过平均方法（averaging）减小方差，如果模型具有很高的偏差，Bagging 并不会对模型有很大的影响。</p>
<p>对于稳定的模型来说，Bagging 并不会工作地很好，而 Boosting 可得会有帮助。如果在训练集上有 noisy 数据，Boosting 会很快地过拟合，降低模型的性能，而Bagging 不存在这样地问题。</p>
<h3 id="8-7-模型融合-stacking-与-blending-的区别？"><a href="#8-7-模型融合-stacking-与-blending-的区别？" class="headerlink" title="8.7 模型融合 stacking 与 blending 的区别？"></a>8.7 模型融合 stacking 与 blending 的区别？</h3><h4 id="voting"><a href="#voting" class="headerlink" title="voting"></a>voting</h4><p>voting 为投票方法，是模型融合策略中最简单的一种方法，其融合过程不需要建立新的模型，只需要在单一模型的输出结果上完成融合。可以分为硬投票和软投票：</p>
<ul>
<li>硬投票（Hard Voting）是指对每个模型给出的样本分类结果以少数服从多数的方式产生最终结果。</li>
<li>软投票（Soft Voting）是指将各个模型预测样本为某一类别的概率的平均值大小来决定所属类别。</li>
</ul>
<h4 id="averaging"><a href="#averaging" class="headerlink" title="averaging"></a>averaging</h4><p>averaging 为平均方法，也比较简单，思路是对多个模型的结果取平均（或加权平均）。bagging 和 boosting 方法都基于此。</p>
<h4 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h4><p>Stacking 是一种<strong>嵌套组合</strong>型的模型融合方法，其基本思路就是在第一层训练多个不同的基学习器，然后把第一层训练的各个基学习器的输出作为输入来训练第二层的学习器，从而得到一个最终的输出。</p>
<h4 id="Blending"><a href="#Blending" class="headerlink" title="Blending"></a>Blending</h4><p>Blending 模型与 Stacking 模型预测过程大致相似，通常情况下模型训练也是要经过两轮，不同之处在于，Blending 划分的训练集<strong>不需要交叉验证</strong>，而是通过独立划分出来的验证集输入到基模型中，得到第二层模型的训练数据。</p>
<h2 id="十、隐马尔可夫模型"><a href="#十、隐马尔可夫模型" class="headerlink" title="十、隐马尔可夫模型"></a>十、隐马尔可夫模型</h2><p>隐马尔可夫模型（hidden Markov model，HMM）是可用于标注问题的统计学习模型，描述由隐藏的马尔科夫链随机生成观测序列的过程，属于<strong>生成模型</strong>。</p>
<h3 id="10-1-基本概念"><a href="#10-1-基本概念" class="headerlink" title="10.1 基本概念"></a>10.1 基本概念</h3><p>隐马尔可夫模型是关于时序的概率模型，描述一个隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测，从而产生观测随机序列的过程。</p>
<p>隐藏的马尔可夫链随机生成的状态的序列，称为<strong>状态序列</strong>；每个状态生成一个观测，由此产生的观测的随机序列，称为<strong>观测序列</strong>。</p>
<p>隐马尔可夫模型由<strong>初始概率分布</strong>、<strong>状态转移概率分布</strong>以及<strong>观测概率分布</strong>确定。</p>
<p>设 Q 是所有可能的状态的集合，V 是所有可能的观测的集合：</p>
<p>​        $Q=\{q_1,q_2,…,q_N\}, V=\{v_1,v_2,…,v_M\}$</p>
<p>I 是状态序列，O 是对应的观测序列：</p>
<p>​        $I=(i_1,i_2,…,i_T), O=(o_1,o_2,…,o_T)$</p>
<p>A 是<strong>状态转移概率矩阵</strong>：</p>
<p>​        $A=[a_{ij}]_{N\times N}$</p>
<p>其中，$a_{ij}=P(i_{t+1}=q_j|i_t=q_i)$ 是在时刻 t 处于状态 $q_i$ 的条件下在时刻 t + 1 转移到状态 $q_j$ 的概率。</p>
<p>B 是<strong>观测概率矩阵</strong>：</p>
<p>​        $B=[b_j(k)]_{N\times M}$</p>
<p>其中，$b_j(k)=P(o_t=v_k|i_t=q_j)$ 是在时刻 t 处于状态 $q_j$ 的条件下生成观测 $v_k$ 的概率。</p>
<p>$\pi$ 是<strong>初始状态概率向量</strong>：</p>
<p>​        $\pi=(\pi_i)$</p>
<p>其中，$\pi_i=P(i_1=q_i)$ 是时刻 t = 1 处于状态 $q_i$ 的概率。</p>
<p>因此，隐马尔可夫模型 λ 可以表示为：</p>
<p>​        $\lambda=(A,B,\pi)$</p>
<p>$A,B,\pi$ 称为隐马尔可夫模型的三要素。</p>
<p>隐马尔可夫模型的两个<strong>基本假设</strong>：</p>
<ul>
<li>假设隐藏的马尔可夫链在任意时刻 t 的状态只依赖于其前一时刻的状态，与其他时刻的状态及观测无关</li>
<li>假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关</li>
</ul>
<h4 id="隐马尔可夫模型的-3-个基本问题"><a href="#隐马尔可夫模型的-3-个基本问题" class="headerlink" title="隐马尔可夫模型的 3 个基本问题"></a>隐马尔可夫模型的 3 个基本问题</h4><ul>
<li>概率计算问题：给定模型 $\lambda=(A,B,\pi)$ 和观测序列 $O=(o_1,o_2,…,o_T)$，计算观测序列 O 出现的概率 P(O|λ)。</li>
<li>学习问题：已知观测序列 O，估计模型 λ 的参数，使得在该模型下观测序列概率 P(O|λ) 最大。</li>
<li>预测问题（解码问题）：已知模型 λ 和观测序列 O，求对给定观测序列条件概率 P(I|O) 最大的状态序列 I。</li>
</ul>
<h3 id="10-2-概率计算算法"><a href="#10-2-概率计算算法" class="headerlink" title="10.2 概率计算算法"></a>10.2 概率计算算法</h3><h4 id="直接计算法"><a href="#直接计算法" class="headerlink" title="直接计算法"></a>直接计算法</h4><p>给定模型 λ 和观测序列 O，计算观测序列 O 出现的概率 P。最直接的方法是按概率公式直接计算。通过列举所有可能的长度为 T 的状态序列 I，求各个状态序列 I 与观测序列 O 的联合概率 P(O, I|λ)，然后对所有可能的状态序列求和，得到 P(O|λ)。</p>
<p>但是，这样计算的时间复杂度为 $O(TN^T)$，算法不可行。</p>
<h4 id="前向算法"><a href="#前向算法" class="headerlink" title="前向算法"></a>前向算法</h4><p><strong>前向概率</strong></p>
<p>给定隐马尔可夫模型 λ，定义到时刻 t 部分观测序列为 $o_1,o_2,…,o_t$ 且状态为 $q_i$ 的概率为前向概率，记作</p>
<p>​        $\alpha_t(i)=P(o_1,o_2,…,o_t,i_t=q_i|\lambda)$</p>
<p>可以递推地求得前向概率 $\alpha_t(i)$ 及观测序列概率 $P(O|\lambda)$。</p>
<p>（1）初值</p>
<p>​        $\alpha_1(i)=\pi_ib_i(o_1), i=1,2,…,N$</p>
<p>（2）递推    对 t = 1, 2, …, T - 1，</p>
<p>​        $\alpha_{t+1}(i)=[\sum\limits_{j=1}^N\alpha_t(j)a_{ji}]b_i(o_{t+1})， i=1,2,…,N$</p>
<p>（3）终止</p>
<p>​        $P(O|\lambda)=\sum\limits_{i=1}^N\alpha_T(i)$</p>
<p><img src="https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009122440303.png" alt="image-20221009122440303" style="zoom:67%;" /></p>
<p>例子：</p>
<p><img src="https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009194041235.png" alt="image-20221009194041235" style="zoom:67%;" /></p>
<p><img src="https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009194113943.png" alt="image-20221009194113943" style="zoom:67%;" /></p>
<h4 id="后向算法"><a href="#后向算法" class="headerlink" title="后向算法"></a>后向算法</h4><p><strong>后向概率</strong></p>
<p>给定隐马尔可夫模型 λ，定义在时刻 t 状态为 $q_i$ 的条件下，从 t + 1 到 T 的部分观测序列为 $o_{t+1}, o_{t+2},…,o_T$ 的概率为后向概率，记作</p>
<p>​        $\beta_t(i)=P(o_{t+1},o_{t+2},…,o_T|i_t=q_i,\lambda)$</p>
<p>可以用递推地方法求得后向概率 $\beta_t(i)$ 及观测序列概率 $P(O|\lambda)$。</p>
<p><img src="https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009194449118.png" alt="image-20221009194449118" style="zoom:67%;" /></p>
<h3 id="10-3-学习问题"><a href="#10-3-学习问题" class="headerlink" title="10.3 学习问题"></a>10.3 学习问题</h3><p>已知观测序列 $O=(o_1,o_2,…,o_T)$，估计模型 $\lambda=(A,B,\pi)$ 参数，使得在该模型下观测序列概率 $P(O|\lambda)$ 最大。用极大似然估计的方法估计参数。Baum-Welch 算法，也就是 EM 算法可以高效地对隐马尔可夫模型进行训练，它是一种无监督学习算法。</p>
<h3 id="10-4-预测问题"><a href="#10-4-预测问题" class="headerlink" title="10.4 预测问题"></a>10.4 预测问题</h3><p>已知模型 $\lambda=(A,B,\pi)$ 和观测序列 $O=(o_1,o_2,…,o_T)$，求对给定观测序列条件概率 $P(O|\lambda)$ 最大的状态序列 $I=(i_1,i_2,…,i_T)$。维特比算法应用动态规划高效地求解最优路径，即概率最大的状态序列。</p>
<h2 id="十一、条件随机场"><a href="#十一、条件随机场" class="headerlink" title="十一、条件随机场"></a>十一、条件随机场</h2><p>条件随机场（conditional random field，CRF）是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型，其特点是假设输出随机变量构成马尔可夫随机场。线性链条件随机场应用于标注问题，由输入序列对输出序列预测的<strong>判别模型</strong>，形式为对数线性模型，其学习方法通常是极大似然估计或正则化的极大似然估计。</p>
<h3 id="11-1-概率无向图模型"><a href="#11-1-概率无向图模型" class="headerlink" title="11.1 概率无向图模型"></a>11.1 概率无向图模型</h3><p>概率无向图模型，又称为马尔可夫随机场（Markov random field），是一个可以由无向图表示的联合概率分布。</p>
<p>设有联合概率分布 P(Y)，由无向图 G = (V, E) 表示，在图 G 中，结点表示随机变量，边表示随机变量之间的依赖关系。如果联合概率分布 P(Y) 满足成对、局部或全局马尔可夫性，就称此联合概率分布为概率无向图模型，或马尔可夫随机场。</p>
<h4 id="因子分解"><a href="#因子分解" class="headerlink" title="因子分解"></a>因子分解</h4><p>将概率无向图模型的联合概率分布表示为其最大团上的随机变量的函数的乘积形式的操作，称为概率无向图模型的因子分解。</p>
<h3 id="11-2-条件随机场"><a href="#11-2-条件随机场" class="headerlink" title="11.2 条件随机场"></a>11.2 条件随机场</h3><p>条件随机场是给定随机变量 X 的条件下，随机变量 Y 的马尔科夫随机场。</p>
<p>设 X 与 Y 是随机变量，P(Y|X) 是在给定 X 的条件下 Y 的条件概率分布。若随机变量 Y 构成一个由无向图 G=(V, E) 表示的马尔可夫随机场，则称条件概率分布 P(Y|X) 为<strong>条件随机场</strong>。</p>
<p>若 X，Y 均为线性链表示的随机变量序列，则称 P(Y|X) 为线性链条件随机场。</p>
<h3 id="监督学习方法总结"><a href="#监督学习方法总结" class="headerlink" title="监督学习方法总结"></a>监督学习方法总结</h3><p><img src="https://s2.loli.net/2022/10/08/IoyYP36vxpnijGc.png" alt="image-20221008215535022" style="zoom:67%;" /></p>
<h2 id="十四、聚类"><a href="#十四、聚类" class="headerlink" title="十四、聚类"></a>十四、聚类</h2><p>无监督学习是从无标注的数据中学习数据的统计规律或内在结构的机器学习，主要包括<strong>聚类</strong>、<strong>降维</strong>、<strong>概率估计</strong>。</p>
<p>无监督学习可用于数据分析或者监督学习的前处理。</p>
<p><strong>聚类</strong>（clustering）是将样本集合中相似的样本分配到相同的类，不相似的样本分配到不同的类。</p>
<h4 id="相似度或距离"><a href="#相似度或距离" class="headerlink" title="相似度或距离"></a>相似度或距离</h4><p>聚类的核心概念是相似度或距离。在进行聚类时，选择合适的距离或相似度非常重要。</p>
<ul>
<li>闵可夫斯基距离</li>
</ul>
<p>对于样本 $x_i=(x_{1i},x_{2i},…,x_{mi})^T,x_j=(x_{1j},x_{2j},…,x_{mj})^T$，样本 $x_i$ 与样本 $x_j$ 的闵可夫斯基距离定义为</p>
<p>​        $d_{ij}=(\sum\limits_{k=1}^m|x_{ki}-x_{kj}|^p)^{\frac{1}{p}}, p\ge1$</p>
<p>当 p = 2 时，称为欧氏距离，即</p>
<p>​        $d_{ij}=(\sum\limits_{k=1}^m|x_{ki}-x_{kj}|^2)^{\frac{1}{2}}$</p>
<p>当 p = 1 时，称为曼哈顿距离，即</p>
<p>​        $d_{ij}=\sum\limits_{k=1}^m|x_{ki}-x_{kj}|$</p>
<p>当 p = ∞ 时，称为切比雪夫距离，取各个坐标数值差的绝对值的最大值，即</p>
<p>​        $d_{ij}=\max\limits_k|x_{ki}-x_{kj}|$</p>
<ul>
<li>马哈拉诺比斯距离</li>
</ul>
<p>简称马氏距离，考虑各个分量（特征）之间的相关性并于各个分量的尺度无关。</p>
<p>给定一个样本集合 X，$X=[x_{ij}]_{m\times n}$，其协方差矩阵记作 S。样本 $x_i$ 与样本 $x_j$ 的马哈拉诺比斯距离定义为</p>
<p>​        $d_{ij}=[(x_i-x_j)^TS^{-1}(x_i-x_j)]^{\frac{1}{2}}$</p>
<p>当 S 为单位矩阵矩阵时，即样本数据的各个分量相互独立且各分量的方差为 1 时，马氏距离就是欧氏距离，所以马氏距离是欧氏距离的推广。</p>
<ul>
<li>相关系数</li>
</ul>
<p>样本 $x_i$ 与样本 $x_j$ 的相关系数定义为</p>
<p><img src="https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009203908759.png" alt="image-20221009203908759" style="zoom:67%;" /></p>
<p>其中</p>
<p><img src="https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009203934547.png" alt="image-20221009203934547" style="zoom:67%;" /></p>
<ul>
<li>夹角余弦</li>
</ul>
<p>样本 $x_i$ 与样本 $x_j$ 的夹角余弦定义为</p>
<p><img src="https://img-1307246870.cos.ap-beijing.myqcloud.com/image-20221009204035263.png" alt="image-20221009204035263" style="zoom:67%;" /></p>
<h3 id="14-1-K-means"><a href="#14-1-K-means" class="headerlink" title="14.1 K-means"></a>14.1 K-means</h3><h3 id="14-2-DBSCAN"><a href="#14-2-DBSCAN" class="headerlink" title="14.2 DBSCAN"></a>14.2 DBSCAN</h3><p>DBSCAN（Density-Based Spatial Clustering of Applications with Noise）是一<strong>基于密度</strong>的聚类算法，DBSCAN 将簇定义为<strong>密度相连的点的最大集合</strong>，能够把具有足够高密度的区域划分为簇，并可在噪声的空间数据库中发现<strong>任意形状</strong>的聚类。</p>
<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>DBSCAN 是基于一组邻域来描述样本集的紧密程度的。对于样本集 $D=\{x_1, x_2, …, x_m\}$，相关定义如下：</p>
<ul>
<li><p>$(\epsilon,MinPts)$ 用来描述邻域的样本分布的紧密程度。其中，$\epsilon$ 表示某一数据点的邻域距离阈值（半径），$MinPts$ 表示数据点半径为 $\epsilon$ 的邻域中数据点个数的最小值。</p>
</li>
<li><p>$\epsilon-邻域$：样本集 D 中与 $x_j$ 的距离不大于 $\epsilon$ 的子样本集。</p>
</li>
<li>核心对象：如果 $x_j$ 的 $\epsilon -邻域$ 至少包含 MinPts 个样本，则 $x_j$ 是核心对象。</li>
<li>密度直达：如果 $x_i$ 位于 $x_j$ 的 $\epsilon-邻域$ 中，且 $x_j$ 是核心对象，则称 $x_i$ 由 $x_j$ 密度直达，反之不一定成立，除非 $x_i$ 也是核心对象。</li>
<li>密度可达：对于 $x_i$ 和 $x_j$ ,如果存在样本样本序列 $p_1,p2,…,p_T$ ,满足 $p_1=x_i,p_T=x_j$ , 且 $p_{t+1}$ 由 $p_t$ 密度直达，则称 $x_j$ 由 $x_i$ 密度可达。也就是说，密度可达满足传递性。此时序列中的传递样本 $p_1,p2,…,p_{T-1}$ <strong>均为核心对象</strong>。</li>
<li>密度相连：对于 xi 和 xj ,如果存在核心对象样本 xk ，使<strong>xi 和 xj 均由 xk 密度可达</strong>，则称 xi 和 xj 密度相连。<strong>密度相连关系满足对称性</strong>。</li>
</ul>
<p>由<strong>密度可达关系</strong>导出的<strong>最大密度相连</strong>的样本集合，即为我们最终聚类的一个类别，或者说一个簇。如果只有一个核心对象，则簇里其他的非核心对象样本都在这个核心对象的 ϵ -邻域里；如果有多个核心对象，则簇里的任意一个核心对象的 ϵ -邻域中一定有一个其他的核心对象，否则这两个核心对象无法密度可达。这些核心对象的 ϵ -邻域里所有的样本的集合组成的一个 <strong>DBSCAN 聚类簇</strong>。</p>
<p>另外，由三个问题需要考虑：</p>
<ul>
<li><strong>异常点问题：</strong>一些异常样本点或者说少量游离于簇外的样本点，这些点不在任何一个核心对象在周围，在DBSCAN中，我们一般将这些样本点标记为噪音点。</li>
<li><strong>距离度量问题</strong>：即如何计算某样本和核心对象样本的距离。在DBSCAN中，一般采用某一种距离度量来衡量样本距离，比如欧式距离、曼哈顿距离等。</li>
<li><strong>数据点优先级分配问题</strong>：例如某些样本可能到两个核心对象的距离都小于 ϵ ，但是这两个核心对象由于不是密度直达，又不属于同一个聚类簇，那么如果界定这个样本的类别呢？一般来说，此时 DBSCAN 采用<strong>先来后到</strong>，先进行聚类的类别簇会标记这个样本为它的类别。也就是说 DBSCAN 的算法<strong>不是完全稳定</strong>的算法。</li>
</ul>
<h4 id="算法-2"><a href="#算法-2" class="headerlink" title="算法"></a>算法</h4><ol>
<li>初始化核心对象集合 Ω=∅，初始化类别 k=0</li>
<li>遍历 D 的元素，如果是核心对象，则将其加入到核心对象集合 Ω 中</li>
<li>如果核心对象集合 Ω 中元素都已经<strong>被访问</strong>，则算法结束，否则转入步骤 4</li>
<li>在核心对象集合 Ω 中，随机选择一个<strong>未访问</strong>的核心对象 o ，首先将 o 标记为<strong>已访问</strong>，然后将 o 标记类别 k ，最后将 o 的 ϵ -邻域中<strong>未访问</strong>的数据，存放到种子集合 Seeds 中。</li>
<li>如果种子集合 Seeds=∅ ，则当前聚类簇 $C_k$ 生成完毕, 且 k=k+1 ，跳转到3。否则，从种子集合 Seeds 中挑选一个种子点 seed ，首先将其标记为已访问、标记类别 k ，然后判断 seed 是否为核心对象，如果是将 seed 中<strong>未访问</strong>的种子点加入到种子集合中，跳转到5。</li>
</ol>
<p><strong>算法优点：</strong></p>
<ul>
<li>可以对任意形状的稠密数据集进行聚类，相对的，K-Means之类的聚类算法一般只适用于凸数据集。</li>
<li>可以在聚类的同时发现异常点，对数据集中的异常点不敏感。</li>
<li>聚类结果没有偏倚，相对的，K-Means之类的聚类算法初始值对聚类结果有很大影响。</li>
</ul>
<p><strong>算法缺点：</strong></p>
<ul>
<li>如果样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差，这时用DBSCAN聚类一般不适合。</li>
<li>如果样本集较大时，聚类收敛时间较长。</li>
<li>调参相对于传统的 K-Means 之类的聚类算法稍复杂，主要需要对距离阈值 ϵ，邻域样本数阈值 MinPts 联合调参，不同的参数组合对最后的聚类效果有较大影响。</li>
</ul>
<h3 id="14-3-分层聚类方法"><a href="#14-3-分层聚类方法" class="headerlink" title="14.3 分层聚类方法"></a>14.3 分层聚类方法</h3><p>分层聚类法是聚类分析中的一种算法，就是对给定数据对象的集合进行层次分解，根据分层分解采用的分解策略，分层聚类法又可以分为<strong>凝聚的</strong>（agglomerative，即自底向上）和<strong>分裂</strong>的（divisive，即自顶向下）分层聚类。</p>
<h4 id="凝聚的分层聚类"><a href="#凝聚的分层聚类" class="headerlink" title="凝聚的分层聚类"></a>凝聚的分层聚类</h4><p>采用自底向上的策略，首先将每一个对象作为一个类，然后根据某种度量(如2个当前类中心点的距离)将这些类合并为较大的类，直到所有的对象都在一个类中，或者是满足某个终止条件时为止，绝大多数分层聚类算法属于这一类，它们只是在类间相似度的定义上有所不同。</p>
<h4 id="分裂的分层聚类"><a href="#分裂的分层聚类" class="headerlink" title="分裂的分层聚类"></a>分裂的分层聚类</h4><p>采用与凝聚的分层聚类相反的策略——自顶向下，它首先将所有的对象置于一个类中，然后根据某种度量逐渐细分为较小的类，直到每一个对象自成一个类，或者达到某个终止条件(如达到希望的类个数，或者2个最近的类之间的距离超过了某个阈值)。</p>
<h2 id="十五、奇异值分解（SVD）"><a href="#十五、奇异值分解（SVD）" class="headerlink" title="十五、奇异值分解（SVD）"></a>十五、奇异值分解（SVD）</h2><p>任意一个 m × n 矩阵，都可以表示为三个矩阵的乘积形式，分别是 m 阶正交矩阵、降序排列的非负的 m × n 对角矩阵和 n 阶正交矩阵。矩阵的奇异值分解一定存在，但不唯一。奇异值分解可以看作是矩阵数据压缩的一种方法。</p>
<p>首先回顾下特征值和特征向量的定义：</p>
<p>$Ax=\lambda x$</p>
<p>其中，A 是 n×n 矩阵，x 是 n 维向量，则 λ 是 矩阵 A 的一个特征值，x 是矩阵 A 的特征值 λ 对应的特征向量。</p>
<p>求出特征值就可以将矩阵 A 特征分解：</p>
<p>$A=W\sum W^{-1}$</p>
<p>其中，W 是 n 个特征向量组成的 n×n 的矩阵， 是由 n 个特征值为主对角线的 n×n 的对角矩阵。</p>
<p>将 n 个向量标准化（$||w_i||_2=1$）后，此时的 n 个特征向量为标准正交基，满足 $W^TW=I$，即 $W^T=W^{-1}$。于是，特征分解表达式可以写为：</p>
<p>$A=W\sum W^T$</p>
<p>如果 A 不是方阵，还可以对矩阵进行分解吗？奇异值分解（SVD）就实现了这一点。</p>
<h4 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h4><p>SVD 也是对矩阵进行分解，但是和特征分解不同，SVD 并不要求要分解的矩阵为方阵。假设我们的矩阵 A 是一个 m×n 的矩阵，那么我们定义矩阵 A 的SVD为：</p>
<p>$A=U\sum V^T$</p>
<p>其中，U 是一个 m×m 的矩阵；Σ 是一个 m×n 的矩阵，主对角线上的元素为奇异值，其他元素都为 0；V 是一个 n×n 的矩阵。U 和 V 都是酉矩阵，即满足 $U^TU=I, V^TV=I$。</p>
<p><img src="https://pic4.zhimg.com/80/v2-5ee98f8f3426b845bc1c5038ecd29593_1440w.webp" alt="img" style="zoom:67%;" /></p>
<h4 id="SVD-计算"><a href="#SVD-计算" class="headerlink" title="SVD 计算"></a>SVD 计算</h4><p>对于一个 m×n 的矩阵：</p>
<ol>
<li>对 n×n 的方阵 $A^TA$ 进行特征分解，得到 n 个特征值和对应的特征向量，特征向量组成 n×n 的矩阵 V。V 中的每个特征向量叫作 A 的右奇异向量。</li>
<li>对 m×m 的方阵 $AA^T$ 以同样的方法计算得到 m×m 的矩阵 U，U 中的每个特征向量叫作 A 的左奇异向量。</li>
<li>求每个奇异值。</li>
</ol>
<p><img src="https://pic3.zhimg.com/80/v2-eab35f0f8896ebe2dbf64d3c0b2bb1da_1440w.webp" alt="img"></p>
<p>证明：</p>
<p><img src="https://pic1.zhimg.com/80/v2-51a61b4e3b977ade92b970f486a4aef4_1440w.webp" alt="img"></p>
<p>奇异值跟特征分解中的特征值类似，在奇异值矩阵中也是按照从大到小排列，而且奇异值的减少特别的快，在很多情况下，前 10% 甚至 1% 的奇异值的和就占了全部的奇异值之和的 99% 以上的比例。也就是说，我们也可以用最大的 k 个的奇异值和对应的左右奇异向量来近似描述矩阵。</p>
<p><img src="https://pic3.zhimg.com/80/v2-6a5a4da69ea5c7450d016fd2a8c7c436_1440w.webp" alt="img"></p>
<p>其中，对于大矩阵，k 比 n 小得多。由于这个重要的性质，SVD 可以用于 PCA 降维，来做数据压缩和去噪。也可以用于推荐算法，将用户和喜好对应的矩阵做特征分解，进而得到隐含的用户需求来做推荐。</p>
<p><strong>左奇异矩阵可以用于行数的压缩。</strong></p>
<p><strong>右奇异矩阵可以用于列数即特征维度的压缩，也就是 PCA 降维。</strong></p>
<h2 id="十六、主成分分析（PCA）"><a href="#十六、主成分分析（PCA）" class="headerlink" title="十六、主成分分析（PCA）"></a>十六、主成分分析（PCA）</h2><p>主成分分析（Principal components analysis，PCA）是最重要的<strong>降维方法</strong>之一。在数据压缩消除冗余和数据噪音消除等领域都有广泛的应用。<strong>降维</strong>是将高维度的数据保留下最重要的一些特征，去除噪声和不重要的特征，从而实现提升数据处理速度的目的。在实际的生产和应用中，降维在一定的信息损失范围内，可以为我们节省大量的时间和成本。</p>
<p>PCA 将 n 维特征映射到 k 维上，这 k 维特征是全新的<strong>正交特征</strong>，也被称为<strong>主成分</strong>。PCA 的工作就是从原始的空间中顺序地找一组相互正交的坐标轴，其中，第一个新坐标轴选择是原始数据中<strong>方差最大</strong>的方向，第二个新坐标轴选取是与第一个坐标轴<strong>正交</strong>的平面中使得方差最大的，第三个轴是与第 1, 2 个轴正交的平面中方差最大的。依次类推，可以得到 n 个这样的坐标轴。我们发现，大部分方差都包含在前面 k 个坐标轴中，后面的坐标轴所含的方差几乎为 0。于是，我们可以忽略余下的坐标轴，只保留前 k 个含有绝大部分方差的坐标轴，从而实现对数据特征的降维处理。</p>
<h4 id="方差最大的主成分的计算"><a href="#方差最大的主成分的计算" class="headerlink" title="方差最大的主成分的计算"></a>方差最大的主成分的计算</h4><p>通过计算数据矩阵的<strong>协方差矩阵</strong>，然后计算协方差矩阵的特征值与特征向量，选择特征值最大（即方差最大）的 k 个特征所对应的特征向量组成的矩阵。可以使用特征分解或奇异值分解的方法。</p>
<h4 id="算法的优缺点"><a href="#算法的优缺点" class="headerlink" title="算法的优缺点"></a>算法的优缺点</h4><p><strong>优点：</strong></p>
<ul>
<li>仅仅需要以方差衡量信息量，不受数据集以外的因素影响</li>
<li>各主成分之间正交，可消除原始数据成分间的相互影响的因素</li>
<li>计算方法简单，主要运算是特征值分解，易于实现</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>主成分各个特征维度的含义具有一定的模糊性，不如原始样本特征的解释性强</li>
<li>方差小的非主成分也可能含有对样本差异的重要信息，因此降维丢弃可能对后续数据处理有影响</li>
</ul>
<h2 id="十七、线性判别分析（LDA）"><a href="#十七、线性判别分析（LDA）" class="headerlink" title="十七、线性判别分析（LDA）"></a>十七、线性判别分析（LDA）</h2><p>PCA 降维是无监督的，没有利用数据的标签信息。有时候我们需要直到降维后的一些<strong>与标签 y 关系最密切的最佳特征</strong>。</p>
<p>LDA 是一种<strong>监督学习</strong>的降维技术，也就是说它的数据集的每个样本是有类别输出的。</p>
<p>LDA 的基本思想：给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近、异类样例的投影点中心尽可能远离。更简单的概括为一句话，就是“投影后<strong>类内方差最小</strong>，<strong>类间方差最大</strong>”。</p>
<p><img src="https://images2015.cnblogs.com/blog/1042406/201701/1042406-20170103121629034-435985945.png" alt="img"></p>
<p>LDA 除了可以用于降维以外，还可以用于<strong>分类</strong>。一个常见的 LDA 分类基本思想是假设各个类别的样本数据符合<strong>高斯分布</strong>（正态分布），这样利用 LDA 进行投影后，可以利用<strong>极大似然估计</strong>计算各个类别投影数据的<strong>均值和方差</strong>，进而得到该类别高斯分布的<strong>概率密度函数</strong>。当一个新的样本到来后，我们可以将它投影，然后将投影后的样本特征分别带入各个类别的高斯分布概率密度函数，计算它属于这个类别的概率，最大的概率对应的类别即为预测类别。</p>
<h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><p><strong>优点：</strong></p>
<ul>
<li>在降维过程中可以使用类别的先验知识经验，而 PCA 这样的无监督学习则无法使用类别先验知识</li>
<li>LDA 在样本分类信息依赖均值而不是方差的时候，比 PCA 之类的算法较优</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>LDA 不适合对非高斯分布样本进行降维，PCA 也有这个问题</li>
<li>LDA 降维最多降到类别数 k-1 的维数，如果我们降维的维度大于 k-1，则不能使用 LDA。当然目前有一些LDA的进化版算法可以绕过这个问题</li>
<li>LDA 在样本分类信息依赖方差而不是均值的时候，降维效果不好</li>
<li>LDA 可能过度拟合数据</li>
</ul>
<h2 id="十八、潜在语义分析（LSA）"><a href="#十八、潜在语义分析（LSA）" class="headerlink" title="十八、潜在语义分析（LSA）"></a>十八、潜在语义分析（LSA）</h2><p>潜在语义分析（LSA）是一种用于知识获取和展示的计算理论和方法，出发点就是<strong>文本中的词与词之间存在某种联系</strong>，即存在某种<strong>潜在的语义结构</strong>。这种潜在的语义结构<strong>隐含在文本中词语的上下文使用模式中</strong>。因此采用统计计算的方法，对大量的文本中进行分析来寻找这种潜在的语义结构，它不需要确定的语义编码，仅依赖于上下文中事物的联系，并用语义结构来表示词和文本，<strong>达到消除词之间的相关性</strong>，<strong>简化文本向量</strong>的目的。</p>
<p>LSA 通过对原文本库的项／文本矩阵的奇异值分解，并取前 K 个最大的奇异值及对应的奇异向量构成一个新矩阵来近似表示原文本库的项／文本矩阵，由于新矩阵削减了项和文本之间语义关系的模糊度，从而有利于信息检索。</p>
<h4 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h4><p><strong>优点：</strong></p>
<ul>
<li>LSA 利用潜在的语义结构表示词条和文本，将词条和文本映射到同一个 k 维的语义空间内，均表示为 k 个因子的形式，它反映的不再是简单的词条出现频率和分布关系，而是强化的语义关系。</li>
<li><p>由于词条和文本被映射到同一 k 维的语义空间，所以在 LSA 模型中不仅能够进行传统的词条与词条、文本与文本之间的相似关系分析，而且能够分析词条与文本之间的相似关系，与传统的向量空间模型相比，具有更好的灵活性。</p>
</li>
<li><p>对于原始的词条一文本矩阵，通过 LSA 提取出 k 维语义空间。这样用低维词条、文本向量代替原始的空间向量，可以有效地处理大规模的文本库。</p>
</li>
<li><p>LSA 不需要人工干预，不需要先验知识。</p>
</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><p>LSA 在进行信息提取时，忽略词语的语法信息（甚至是忽略词语在句子中出现顺序），认为语法结构在文本的语义表达中处于次要的地位。</p>
</li>
<li><p>LSA 处理的对象是可见变量（文本集中出现的词语、文本），它不能通过计算得到词语的暗喻含义，以及类比推论含义。</p>
</li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>统计学习方法</p><p><a href="https://brucehan98@github.io/2022/10/20/统计学习方法-学习笔记/">https://brucehan98@github.io/2022/10/20/统计学习方法-学习笔记/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Bruce Han</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2022-10-20</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2022-10-25</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="../../../../https:/creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="../../../../https:/creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="../../../../https:/creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:0.8rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="../../../../tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习 </a></div></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="../../../../img/alipay.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="../../../../img/wechat.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="../%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">概率与统计</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="../%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="level-item">计算机网络基础</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "138307fb6e216c5a51ecf4675acf8dda",
            repo: "brucehan98.github.io",
            owner: "BruceHan98",
            clientID: "84666a45ad34d2937a18",
            clientSecret: "f2432742d8824e7bd1006ae69b85f0488f928759",
            admin: ["BruceHan98"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 20,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            language: "zh-CN",
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#一、统计学习与监督学习概论"><span class="level-left"><span class="level-item">1</span><span class="level-item">一、统计学习与监督学习概论</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#1-1-统计学习"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">1.1 统计学习</span></span></a></li><li><a class="level is-mobile" href="#1-2-统计学习的分类"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">1.2 统计学习的分类</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#基本分类"><span class="level-left"><span class="level-item">1.2.1</span><span class="level-item">基本分类</span></span></a></li><li><a class="level is-mobile" href="#按模型分类"><span class="level-left"><span class="level-item">1.2.2</span><span class="level-item">按模型分类</span></span></a></li></ul></li><li><a class="level is-mobile" href="#1-3-统计学习方法的三要素"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">1.3 统计学习方法的三要素</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#模型"><span class="level-left"><span class="level-item">1.3.1</span><span class="level-item">模型</span></span></a></li><li><a class="level is-mobile" href="#策略"><span class="level-left"><span class="level-item">1.3.2</span><span class="level-item">策略</span></span></a></li><li><a class="level is-mobile" href="#算法"><span class="level-left"><span class="level-item">1.3.3</span><span class="level-item">算法</span></span></a></li></ul></li><li><a class="level is-mobile" href="#1-5-正则化与交叉验证"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">1.5 正则化与交叉验证</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#正则化"><span class="level-left"><span class="level-item">1.4.1</span><span class="level-item">正则化</span></span></a></li><li><a class="level is-mobile" href="#交叉验证"><span class="level-left"><span class="level-item">1.4.2</span><span class="level-item">交叉验证</span></span></a></li></ul></li><li><a class="level is-mobile" href="#1-7-生成模型与判别模型"><span class="level-left"><span class="level-item">1.5</span><span class="level-item">1.7 生成模型与判别模型</span></span></a></li><li><a class="level is-mobile" href="#1-8-监督学习的应用"><span class="level-left"><span class="level-item">1.6</span><span class="level-item">1.8 监督学习的应用</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#分类问题"><span class="level-left"><span class="level-item">1.6.1</span><span class="level-item">分类问题</span></span></a></li><li><a class="level is-mobile" href="#标注问题"><span class="level-left"><span class="level-item">1.6.2</span><span class="level-item">标注问题</span></span></a></li><li><a class="level is-mobile" href="#回归问题"><span class="level-left"><span class="level-item">1.6.3</span><span class="level-item">回归问题</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#二、感知机"><span class="level-left"><span class="level-item">2</span><span class="level-item">二、感知机</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#2-1-感知机模型"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">2.1 感知机模型</span></span></a></li><li><a class="level is-mobile" href="#2-2-学习策略"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">2.2 学习策略</span></span></a></li><li><a class="level is-mobile" href="#2-3-算法"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">2.3 算法</span></span></a></li></ul></li><li><a class="level is-mobile" href="#三、k-近邻法"><span class="level-left"><span class="level-item">3</span><span class="level-item">三、k 近邻法</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#3-2-模型"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">3.2 模型</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#距离度量"><span class="level-left"><span class="level-item">3.1.1</span><span class="level-item">距离度量</span></span></a></li><li><a class="level is-mobile" href="#k-值的选择"><span class="level-left"><span class="level-item">3.1.2</span><span class="level-item">k 值的选择</span></span></a></li><li><a class="level is-mobile" href="#分类决策规则"><span class="level-left"><span class="level-item">3.1.3</span><span class="level-item">分类决策规则</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#四、朴素贝叶斯法"><span class="level-left"><span class="level-item">4</span><span class="level-item">四、朴素贝叶斯法</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#4-1-朴素贝叶斯法的学习与分类"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">4.1 朴素贝叶斯法的学习与分类</span></span></a></li><li><a class="level is-mobile" href="#4-2-朴素贝叶斯法的参数估计"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">4.2 朴素贝叶斯法的参数估计</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#极大似然估计"><span class="level-left"><span class="level-item">4.2.1</span><span class="level-item">极大似然估计</span></span></a></li><li><a class="level is-mobile" href="#算法-1"><span class="level-left"><span class="level-item">4.2.2</span><span class="level-item">算法</span></span></a></li><li><a class="level is-mobile" href="#贝叶斯估计"><span class="level-left"><span class="level-item">4.2.3</span><span class="level-item">贝叶斯估计</span></span></a></li><li><a class="level is-mobile" href="#频率学派与贝叶斯学派"><span class="level-left"><span class="level-item">4.2.4</span><span class="level-item">频率学派与贝叶斯学派</span></span></a></li><li><a class="level is-mobile" href="#极大似然估计与最大后验概率估计"><span class="level-left"><span class="level-item">4.2.5</span><span class="level-item">极大似然估计与最大后验概率估计</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#五、决策树"><span class="level-left"><span class="level-item">5</span><span class="level-item">五、决策树</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#5-1-决策树模型与学习"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">5.1 决策树模型与学习</span></span></a></li><li><a class="level is-mobile" href="#5-2-特征选择"><span class="level-left"><span class="level-item">5.2</span><span class="level-item">5.2 特征选择</span></span></a></li><li><a class="level is-mobile" href="#5-3-决策树的生成"><span class="level-left"><span class="level-item">5.3</span><span class="level-item">5.3 决策树的生成</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#ID3-算法"><span class="level-left"><span class="level-item">5.3.1</span><span class="level-item">ID3 算法</span></span></a></li><li><a class="level is-mobile" href="#C4-5-算法"><span class="level-left"><span class="level-item">5.3.2</span><span class="level-item">C4.5 算法</span></span></a></li></ul></li><li><a class="level is-mobile" href="#5-4-决策树的剪枝"><span class="level-left"><span class="level-item">5.4</span><span class="level-item">5.4 决策树的剪枝</span></span></a></li><li><a class="level is-mobile" href="#5-5-CART-算法"><span class="level-left"><span class="level-item">5.5</span><span class="level-item">5.5 CART 算法</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#CART-生成"><span class="level-left"><span class="level-item">5.5.1</span><span class="level-item">CART 生成</span></span></a></li><li><a class="level is-mobile" href="#CART-剪枝算法"><span class="level-left"><span class="level-item">5.5.2</span><span class="level-item">CART 剪枝算法</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#六、逻辑回归与最大熵模型"><span class="level-left"><span class="level-item">6</span><span class="level-item">六、逻辑回归与最大熵模型</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#6-1-逻辑回归模型"><span class="level-left"><span class="level-item">6.1</span><span class="level-item">6.1 逻辑回归模型</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#逻辑分布"><span class="level-left"><span class="level-item">6.1.1</span><span class="level-item">逻辑分布</span></span></a></li><li><a class="level is-mobile" href="#二项逻辑回归模型"><span class="level-left"><span class="level-item">6.1.2</span><span class="level-item">二项逻辑回归模型</span></span></a></li><li><a class="level is-mobile" href="#模型参数估计"><span class="level-left"><span class="level-item">6.1.3</span><span class="level-item">模型参数估计</span></span></a></li></ul></li><li><a class="level is-mobile" href="#6-2-最大熵模型"><span class="level-left"><span class="level-item">6.2</span><span class="level-item">6.2 最大熵模型</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#最大熵原理"><span class="level-left"><span class="level-item">6.2.1</span><span class="level-item">最大熵原理</span></span></a></li><li><a class="level is-mobile" href="#最大熵模型"><span class="level-left"><span class="level-item">6.2.2</span><span class="level-item">最大熵模型</span></span></a></li><li><a class="level is-mobile" href="#最大熵模型的学习"><span class="level-left"><span class="level-item">6.2.3</span><span class="level-item">最大熵模型的学习</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#七、支持向量机"><span class="level-left"><span class="level-item">7</span><span class="level-item">七、支持向量机</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#7-1-线性可分支持向量机"><span class="level-left"><span class="level-item">7.1</span><span class="level-item">7.1 线性可分支持向量机</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#间隔最大化"><span class="level-left"><span class="level-item">7.1.1</span><span class="level-item">间隔最大化</span></span></a></li></ul></li><li><a class="level is-mobile" href="#7-2-线性支持向量机与软间隔最大化"><span class="level-left"><span class="level-item">7.2</span><span class="level-item">7.2 线性支持向量机与软间隔最大化</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#线性支持向量机"><span class="level-left"><span class="level-item">7.2.1</span><span class="level-item">线性支持向量机</span></span></a></li></ul></li><li><a class="level is-mobile" href="#7-3-非线性支持向量机与核函数"><span class="level-left"><span class="level-item">7.3</span><span class="level-item">7.3 非线性支持向量机与核函数</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#核技巧"><span class="level-left"><span class="level-item">7.3.1</span><span class="level-item">核技巧</span></span></a></li><li><a class="level is-mobile" href="#常用核函数"><span class="level-left"><span class="level-item">7.3.2</span><span class="level-item">常用核函数</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#八、提升方法"><span class="level-left"><span class="level-item">8</span><span class="level-item">八、提升方法</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#8-1-AdaBoost-算法"><span class="level-left"><span class="level-item">8.1</span><span class="level-item">8.1 AdaBoost 算法</span></span></a></li><li><a class="level is-mobile" href="#8-2-GBDT"><span class="level-left"><span class="level-item">8.2</span><span class="level-item">8.2 GBDT</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#提升树"><span class="level-left"><span class="level-item">8.2.1</span><span class="level-item">提升树</span></span></a></li><li><a class="level is-mobile" href="#GBDT"><span class="level-left"><span class="level-item">8.2.2</span><span class="level-item">GBDT</span></span></a></li></ul></li><li><a class="level is-mobile" href="#8-3-随机森林（Random-Forest）"><span class="level-left"><span class="level-item">8.3</span><span class="level-item">8.3 随机森林（Random Forest）</span></span></a></li><li><a class="level is-mobile" href="#8-4-XGboost"><span class="level-left"><span class="level-item">8.4</span><span class="level-item">8.4 XGboost</span></span></a></li><li><a class="level is-mobile" href="#8-5-LightGBM"><span class="level-left"><span class="level-item">8.5</span><span class="level-item">8.5 LightGBM</span></span></a></li><li><a class="level is-mobile" href="#8-6-bagging-与-boosting-的区别？"><span class="level-left"><span class="level-item">8.6</span><span class="level-item">8.6 bagging 与 boosting 的区别？</span></span></a></li><li><a class="level is-mobile" href="#8-7-模型融合-stacking-与-blending-的区别？"><span class="level-left"><span class="level-item">8.7</span><span class="level-item">8.7 模型融合 stacking 与 blending 的区别？</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#voting"><span class="level-left"><span class="level-item">8.7.1</span><span class="level-item">voting</span></span></a></li><li><a class="level is-mobile" href="#averaging"><span class="level-left"><span class="level-item">8.7.2</span><span class="level-item">averaging</span></span></a></li><li><a class="level is-mobile" href="#Stacking"><span class="level-left"><span class="level-item">8.7.3</span><span class="level-item">Stacking</span></span></a></li><li><a class="level is-mobile" href="#Blending"><span class="level-left"><span class="level-item">8.7.4</span><span class="level-item">Blending</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#十、隐马尔可夫模型"><span class="level-left"><span class="level-item">9</span><span class="level-item">十、隐马尔可夫模型</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#10-1-基本概念"><span class="level-left"><span class="level-item">9.1</span><span class="level-item">10.1 基本概念</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#隐马尔可夫模型的-3-个基本问题"><span class="level-left"><span class="level-item">9.1.1</span><span class="level-item">隐马尔可夫模型的 3 个基本问题</span></span></a></li></ul></li><li><a class="level is-mobile" href="#10-2-概率计算算法"><span class="level-left"><span class="level-item">9.2</span><span class="level-item">10.2 概率计算算法</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#直接计算法"><span class="level-left"><span class="level-item">9.2.1</span><span class="level-item">直接计算法</span></span></a></li><li><a class="level is-mobile" href="#前向算法"><span class="level-left"><span class="level-item">9.2.2</span><span class="level-item">前向算法</span></span></a></li><li><a class="level is-mobile" href="#后向算法"><span class="level-left"><span class="level-item">9.2.3</span><span class="level-item">后向算法</span></span></a></li></ul></li><li><a class="level is-mobile" href="#10-3-学习问题"><span class="level-left"><span class="level-item">9.3</span><span class="level-item">10.3 学习问题</span></span></a></li><li><a class="level is-mobile" href="#10-4-预测问题"><span class="level-left"><span class="level-item">9.4</span><span class="level-item">10.4 预测问题</span></span></a></li></ul></li><li><a class="level is-mobile" href="#十一、条件随机场"><span class="level-left"><span class="level-item">10</span><span class="level-item">十一、条件随机场</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#11-1-概率无向图模型"><span class="level-left"><span class="level-item">10.1</span><span class="level-item">11.1 概率无向图模型</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#因子分解"><span class="level-left"><span class="level-item">10.1.1</span><span class="level-item">因子分解</span></span></a></li></ul></li><li><a class="level is-mobile" href="#11-2-条件随机场"><span class="level-left"><span class="level-item">10.2</span><span class="level-item">11.2 条件随机场</span></span></a></li><li><a class="level is-mobile" href="#监督学习方法总结"><span class="level-left"><span class="level-item">10.3</span><span class="level-item">监督学习方法总结</span></span></a></li></ul></li><li><a class="level is-mobile" href="#十四、聚类"><span class="level-left"><span class="level-item">11</span><span class="level-item">十四、聚类</span></span></a><ul class="menu-list"><ul class="menu-list"><li><a class="level is-mobile" href="#相似度或距离"><span class="level-left"><span class="level-item">11.1.1</span><span class="level-item">相似度或距离</span></span></a></li></ul><li><a class="level is-mobile" href="#14-1-K-means"><span class="level-left"><span class="level-item">11.2</span><span class="level-item">14.1 K-means</span></span></a></li><li><a class="level is-mobile" href="#14-2-DBSCAN"><span class="level-left"><span class="level-item">11.3</span><span class="level-item">14.2 DBSCAN</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#定义"><span class="level-left"><span class="level-item">11.3.1</span><span class="level-item">定义</span></span></a></li><li><a class="level is-mobile" href="#算法-2"><span class="level-left"><span class="level-item">11.3.2</span><span class="level-item">算法</span></span></a></li></ul></li><li><a class="level is-mobile" href="#14-3-分层聚类方法"><span class="level-left"><span class="level-item">11.4</span><span class="level-item">14.3 分层聚类方法</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#凝聚的分层聚类"><span class="level-left"><span class="level-item">11.4.1</span><span class="level-item">凝聚的分层聚类</span></span></a></li><li><a class="level is-mobile" href="#分裂的分层聚类"><span class="level-left"><span class="level-item">11.4.2</span><span class="level-item">分裂的分层聚类</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#十五、奇异值分解（SVD）"><span class="level-left"><span class="level-item">12</span><span class="level-item">十五、奇异值分解（SVD）</span></span></a><ul class="menu-list"><ul class="menu-list"><li><a class="level is-mobile" href="#SVD"><span class="level-left"><span class="level-item">12.1.1</span><span class="level-item">SVD</span></span></a></li><li><a class="level is-mobile" href="#SVD-计算"><span class="level-left"><span class="level-item">12.1.2</span><span class="level-item">SVD 计算</span></span></a></li></ul></ul></li><li><a class="level is-mobile" href="#十六、主成分分析（PCA）"><span class="level-left"><span class="level-item">13</span><span class="level-item">十六、主成分分析（PCA）</span></span></a><ul class="menu-list"><ul class="menu-list"><li><a class="level is-mobile" href="#方差最大的主成分的计算"><span class="level-left"><span class="level-item">13.1.1</span><span class="level-item">方差最大的主成分的计算</span></span></a></li><li><a class="level is-mobile" href="#算法的优缺点"><span class="level-left"><span class="level-item">13.1.2</span><span class="level-item">算法的优缺点</span></span></a></li></ul></ul></li><li><a class="level is-mobile" href="#十七、线性判别分析（LDA）"><span class="level-left"><span class="level-item">14</span><span class="level-item">十七、线性判别分析（LDA）</span></span></a><ul class="menu-list"><ul class="menu-list"><li><a class="level is-mobile" href="#优缺点"><span class="level-left"><span class="level-item">14.1.1</span><span class="level-item">优缺点</span></span></a></li></ul></ul></li><li><a class="level is-mobile" href="#十八、潜在语义分析（LSA）"><span class="level-left"><span class="level-item">15</span><span class="level-item">十八、潜在语义分析（LSA）</span></span></a><ul class="menu-list"><ul class="menu-list"><li><a class="level is-mobile" href="#优缺点-1"><span class="level-left"><span class="level-item">15.1.1</span><span class="level-item">优缺点</span></span></a></li></ul></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="../../../../js/toc.js" defer></script></div></div><!--!--></div></div></section><footer class="footer" style="padding-bottom: 4rem;"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="../../../../index.html"><img src="../../../../img/logo.svg" alt="Bruce Han&#039;s Blog" height="18"></a><p class="is-size-7"><span>&copy; 2022 Bruce Han</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="../../../../js/column.js"></script><script src="../../../../js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="../../../../js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="../../../../js/main.js" defer></script><script src="../../../../js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="../../../../js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"../../../../content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body><script type="text/javascript" src="/js/mathjax-config.js"></script></html>