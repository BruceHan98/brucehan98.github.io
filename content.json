{"pages":[],"posts":[{"title":"PaddleOCR C++ CPU 推理部署","text":"1. 运行准备新建目录 ppocr-cpp-cpu，将最新分支 PaddleOCR/deploy/cpp_infer 下的所有源文件复制到该文件夹下。 123git clone https://github.com.cnpmjs.org/PaddlePaddle/PaddleOCR.gitmkdir ppocr-cpp-cpucp -r PaddleOCR/deploy/cpp_infer/* ppocr-cpp-cpu 将推理模型拷贝到 inference 文件夹下。 12mkdir ppocr-cpp-cpu/inferencecp -r inference ppocr-cpp-cpu/inference 其中，inference 包含推理所需的 det, rec, cls 模型，可以参考模型预测说明，例如文件结构如下： 12345678910inference/|-- det_db| |--inference.pdiparams| |--inference.pdmodel|-- rec_rcnn| |--inference.pdiparams| |--inference.pdmodel|-- cls| |--inference.pdiparams| |--inference.pdmodel 2. 编译 opencv 库首先，下载 opencv 源码到项目路径下。 123cd ppocr-cpp-cpuwget https://paddleocr.bj.bcebos.com/libs/opencv/opencv-3.4.7.tar.gztar -xvf opencv-3.4.7.tar.gz 修改 tools/build_opencv.sh： 12345678910111213141516171819202122232425262728root_path=/root/ppocr-cpp-cpu/opencv-3.4.7 # 下载的 opencv 源码路径，这里假设项目文件夹在 /root 下，需根据实际情况修改install_path=${root_path}/opencv3build_dir=${root_path}/buildrm -rf ${build_dir}mkdir ${build_dir}cd ${build_dir}cmake .. \\ -DCMAKE_INSTALL_PREFIX=${install_path} \\ -DCMAKE_BUILD_TYPE=Release \\ -DBUILD_SHARED_LIBS=OFF \\ -DWITH_IPP=OFF \\ -DBUILD_IPP_IW=OFF \\ -DWITH_LAPACK=OFF \\ -DWITH_EIGEN=OFF \\ -DCMAKE_INSTALL_LIBDIR=lib64 \\ -DWITH_ZLIB=ON \\ -DBUILD_ZLIB=ON \\ -DWITH_JPEG=ON \\ -DBUILD_JPEG=ON \\ -DWITH_PNG=ON \\ -DBUILD_PNG=ON \\ -DWITH_TIFF=ON \\ -DBUILD_TIFF=ONmake -j # 服务器性能差的话，去掉 -j 或者 改为 make -j 2make install 然后，编译 opencv（编译依赖 gcc g++ cmake）： 1sh tools/build_opencv.sh 编译完成后，在 opencv-3.4.7 路径下会生成 opencv3 文件夹，这取决于上面的安装路径 install_path，文件结构如下： 123456opencv3/|-- bin|-- include|-- lib|-- lib64|-- share 3. 编译 Paddle你也可以直接去官网选择和下载编译好的预测库，解压后安装路径为 paddle_inference ，然后跳过这一步。 如果后续编译 PaddleOCR 没有问题，那么 fine！如果出现问题一直不能解决，那么选择亲自编译 Paddle 预测库。 首先，下载 Paddle 最新源码。 123git clone https://github.com.cnpmjs.org/PaddlePaddle/Paddle.gitcd Paddlegit checkout release/2.2 在 Paddle 目录下新建 build.sh： 1vim build.sh 添加以下内容： 12345678910111213141516rm -rf buildmkdir buildcd buildcmake .. \\ -DWITH_CONTRIB=OFF \\ -DWITH_MKL=ON \\ -DWITH_MKLDNN=ON \\ -DWITH_TESTING=OFF \\ -DCMAKE_BUILD_TYPE=Release \\ -DWITH_INFERENCE_API_TEST=OFF \\ -DON_INFER=ON \\ -DWITH_PYTHON=OFF # 如果不需要用 python 的话，设置为 OFFmake -j # 同样，服务器性能不好的话，建议去掉 -j 或者 make -j 2make inference_lib_dist 然后，进行编译： 1sh build.sh 编译完成后，生成了build/paddle_inference_install_dir文件下，文件结构如下： 12345build/paddle_inference_install_dir/|-- CMakeCache.txt|-- paddle|-- third_party|-- version.txt 其中，paddle 就是 C++ 推理所需的 Paddle 库。如果成功到这里，那么已经完成 90% 了~ 4. 编译 PaddleOCR修改 tools/build.sh 中的环境路径。 12cd ../ # 进入到项目路径下vim tools/build.sh 修改内容如下： 这里真正用到的库有两个：opencv 编译安装目录和 paddle 编译安装目录。 12345# 以下路径均填写绝对路径OPENCV_DIR=/root/ppocr-cpp-cpu/opencv-3.4.7/opencv3 # opencv 编译安装路径LIB_DIR=/root/ppocr-cpp-cpu/Paddle/build/paddle_inference_install_dir # Paddle 编译安装路径，或者下载的编译好的 Paddle 预测库路径CUDA_LIB_DIR=/usr/local/cuda/lib64 # 如果仅使用 CPU 推理的话，这个路径不重要；如果使用 GPU 推理，则填写 CUDA lib 实际路径CUDNN_LIB_DIR=/usr/lib/x86_64-linux-gnu # 同上 然后，先修改 ppocr_keys_v1.txt 字典文件路径，假设放在项目目录下，则修改 src/main.cpp 的第 65 行： 1DEFINE_string(char_list_file, &quot;./ppocr_keys_v1.txt&quot;, &quot;Path of dictionary.&quot;); # 每次修改源代码都要重新编译 这里也可以不修改，不过需要在后面运行的时候传入 char_list_file 参数来指定字典文件路径。 接着，编译： 12sudo sh tools/build.sh # 安装位置需要 sudo 权限# 记得将目录的 owner 切换为自己 编译完成后，会在项目目录下生成 build 文件夹，其中包含 ppocr 的可执行文件。 恭喜你，可以运行推理和部署了！ 推理需要用到的文件： 1234build # 编译安装的程序inference # 推理模型ppocr_keys_v1.txt # 字典imgs # 需要预测的图片 5. 运行推理只调用检测： 123./build/ppocr det \\ --det_model_dir=inference/det_db \\ --image_dir=test.jpg 只调用识别： 123./build/ppocr rec \\ --rec_model_dir=inference/rec_crnn \\ --image_dir=test.jpg 整体调用： 12345678910111213# 不使用方向分类器./build/ppocr system \\ --det_model_dir=inference/det_db \\ --rec_model_dir=inference/rec_crnn \\ --image_dir=test.jpg# 使用方向分类器./build/ppocr system \\ --det_model_dir=inference/det_db \\ --use_angle_cls=true \\ --cls_model_dir=inference/cls \\ --rec_model_dir=inference/rec_crnn \\ --image_dir=test.jpg 更多参数： 参数名称 类型 默认参数 意义 use_gpu bool false 是否使用GPU gpu_id int 0 GPU id，使用GPU时有效 gpu_mem int 4000 申请的GPU内存 cpu_math_library_num_threads int 10 CPU预测时的线程数，在机器核数充足的情况下，该值越大，预测速度越快 use_mkldnn bool true 是否使用mkldnn库 det_model_dir string - 检测模型inference model地址 max_side_len int 960 输入图像长宽大于960时，等比例缩放图像，使得图像最长边为960 det_db_thresh float 0.3 用于过滤DB预测的二值化图像，设置为0.-0.3对结果影响不明显 det_db_box_thresh float 0.5 DB后处理过滤box的阈值，如果检测存在漏框情况，可酌情减小 det_db_unclip_ratio float 1.6 表示文本框的紧致程度，越小则文本框更靠近文本 use_polygon_score bool false 是否使用多边形框计算bbox score，false表示使用矩形框计算。矩形框计算速度更快，多边形框对弯曲文本区域计算更准确。 visualize bool true 是否对结果进行可视化，为1时，会在当前文件夹下保存文件名为ocr_vis.png的预测结果。 use_angle_cls bool false 是否使用方向分类器 cls_model_dir string - 方向分类器inference model地址 cls_thresh float 0.9 方向分类器的得分阈值 rec_model_dir string - 识别模型inference model地址 char_list_file string ../../ppocr/utils/ppocr_keys_v1.txt 字典文件 也可以通过软连接将可执行文件连接到用户命令： 1ln -s /root/ppocr-cpp-cpu/build/ppocr /usr/bin/ppocr 然后就可以直接调用命令执行了： 1ppocr system --image_dir test.jpg 6. 部署过程可能出现的问题GCC 版本编译要求支持 c++11，因此 gcc 和 g++ 版本至少为 4.8.5。 cmake 版本编译 Paddle 需要 cmake 版本至少为 3.19.2。 依赖 openssl： 1sudo yum install -y openssl openssl-devel 编译安装 cmake： 12345678910111213wget https://github.com/Kitware/CMake/releases/download/v3.22.1/cmake-3.22.1.tar.gztar -xvf cmake-3.22.1.tar.gzcd cmake-3.22.1.tar.gz./bootstrapmakesudo make install # 安装位置需要 sudo 权限# 此时，还要需要添加到环境变量vim ~/.bashrcexport CMAKE_ROOT=/usr/local/share/cmake-3.22 # 添加 cmake 安装路径source ~/.bashrc # 使配置生效 编译 Paddle 时 github 网络访问编译 Paddle 时需要在线下载编译所需 github 仓库，所以要求能够正常访问 github。 最大的问题是 github 访问慢甚至无法访问的问题，可以使用国内镜像 cnmpjs.org ，具体为，修改 CMakeLists.txt 183 行： 12# github.com --&gt; github.com.cnpmjs.orgset(GIT_URL &quot;https://github.com.cnpmjs.org&quot;) 同样，在 cmake/external 中，部分 cmake 文件需要修改 git 仓库地址为国内镜像地址，包括： 1brpc.cmake eigen.cmake gflags.cmake leveldb.cmake protobuf.cmake rocksdb.cmake spappy.cmake 以上修改了原始 git 仓库地址，但是有些仓库包含子模块，下载地址仍为 github.com，对于这些仓库，需要修改其 .submodule 中的地址为代理地址。 我想到的最笨的方法就是将这些包含子模块的仓库下载下来，修改 .submodule 文件，然后上传到自己创建的仓库，并将对应的 cmake 文件中的仓库地址改为对应的自己创建的仓库的地址（国内镜像的）。 eigen3 编译执行 eigen.cmake 的时候，可能会报 ./../../Eigen/Core: No such file or directory 的错，即找不到 Eigen/Core 路径，不知道是哪里的问题。于是尝试先手动安装 eigen3，然后修改 eigen3.cmake 中的 EIGEN_INCLUDE_DIR 为 eigen3 的安装路径。 12345678910111213# 下载和解压源文件wget https://gitlab.com/libeigen/eigen/-/archive/3.4.0/eigen-3.4.0.tar.gztar -zxvf eigen-3.4.0.tar.gz# 编译安装cd eigen-3.4.0.tar.gzmkdir build &amp;&amp; cd buildmakemake install # 可能需要 sudo 权限# eigen3 默认安装在了 /usr/local/include/eigen3# 修改 eigen3.cmake 第 40 行set(EIGEN_INCLUDE_DIR /usr/local/include/eigen3) # eigen3 安装路径 找不到 OPENCVConfig.cmakeCould not find a package configuration file provided by “OpenCV” with any of the following names: OpenCVConfig.cmake opencv-config.cmake 这是由于 CMakeLists.txt 中的 OpenCV 路径是针对 OpenCV 3.x 版本的，Opencv 4.x 版本的安装路径不同。 对于 OpenCV 4.x 版本，修改 CMakeLists.txt 中的 47 行为： 1find_package(OpenCV REQUIRED PATHS ${OPENCV_DIR}/lib64/cmake/opencv4 NO_DEFAULT_PATH)","link":"2022/01/11/PaddleOCR-C-CPU-%E6%8E%A8%E7%90%86%E9%83%A8%E7%BD%B2/"},{"title":"Centos7 Mysql 使用","text":"1. 清理环境 查看是否已经安装MySQL数据库 1rpm -qa | grep mysql 若存在，依次卸载旧数据库文件 123sudo systemctl status mysqld # 查看mysql运行状态sudo systemctl stop mysqld # 停止mysqlsudo yum remove mysql-xxx-xxx # 卸载已安装的程序 删除MySQL配置文件 123find / -name mysql# /var/lib/mysqlrm -rf [查找到的配置文件] 卸载MariaDB 12rpm -qa | grep mariadb # 检查mariadbsudo yum remove [已安装的mariadb程序] 2. 安装 MySQL 根据系统版本下载yum源 12cat /etc/redhat-release # 查看系统版本wget http：//dev.mysql.com/get/Downloads/mysql80-community-release-el7-1.noarch.rpm # 选择对应版本的rpm 安装刚才下载的MySQL源 1sudo rpm -Uvh mysql80-community-release-el7-3.noarch.rpm 选择要安装的MySQL版本 1234yum repolist all | grep mysql # 查看所有版本，默认下载最新版本# 切换版本，例如切换到5.7版本，若下载最新版本，忽略这一步sudo yum-config-manager --disable mysql80-communitysudo yum-config-manager --enable mysql57-community 安装MySQL 1sudo yum install mysql-community-server 启动MySQL 1sudo systemctl start mysqld 查看、停止MySQL 123sudo systemctl status mysqld # 查看运行状态sudo systemctl stop mysqld # 停止运行sudo systemctl restart mysqld # 重启服务 设置开机启动 12systemctl enable mysqldsystemctl daemon-reload 3. 配置MySQL 打开数据库端口 12sudo firewall-cmd --zone=public --add-port=3306/tcp --permanent # 永久打开3306端口sudo firewall-cmd --reload 查看默认密码 1sudo grep 'temporary password' /var/log/mysqld.log 修改密码 123456789101112# 首先进入MySQLmysql -u root -p # 输入初始密码use mysql;# 修改密码# mysql 7.0mysql&gt; UPDATE user SET password=password(&quot;密码&quot;) WHERE user='root';# mysql 8.0mysql&gt; alter user 'root'@'localhost' identified with mysql_native_password by '密码';mysql&gt; flush privileges; # 刷新生效 开启本地、远程服务 12345678910111213# 开启本地访问mysql&gt; grant all privileges on *.* to root@&quot;localhost&quot; identified by &quot;密码&quot;;# 开启远程访问# mysql 7.0mysql&gt; grant all privileges on *.* to root@&quot;%&quot; identified by &quot;密码&quot;;# mysql 8.0mysql&gt; UPDATE user SET host = '%' WHERE user ='root;mysql&gt; flush privileges; # 刷新MySQL的系统权限相关表# 退出mysql&gt; exit; 忘记密码，重新设置密码 密码要求同时包含大小写字母数字标点，所以先确定你输入的密码是否符合要求。 1234567891011121314151617181920212223242526# 首先找到配置文件 my.cnf，一般是在 /etc/my.cnfvim /etc/my.cnf# 在配置文件中添加 skip-grant-tables，设置为免密码登录，保存退出# 重启服务以生效sudo systemctl restart mysqld# 先将密码设置为空mysql -u root -p # 此时没有密码，直接敲回车进入mysql &gt; use mysql;mysql &gt; update user set authentication_string = '' where user = 'root';mysql &gt; quit # 退出# 然后去除免密码登录# 注释掉配置文件中的 skip-grant-tables 一行# 重启服务 sudo systemctl restart mysqld# 重新登录MySQL，此时密码为空mysql -u root -p # 直接敲回车登录# 修改密码mysql &gt; ALTER USER 'root'@'localhost' IDENTIFIED BY '你的新密码'; # 注意密码需要同时包含大小写字母数字和标点flush privileges; # 刷新mysql &gt; quit # 退出# 重启服务 sudo systemctl restart mysqld 4. 数据库操作数据库操作首先要登录数据库（废话） 1mysql -u root -p 用户操作 1234567891011# 创建用户mysql &gt; CREATE USER username IDENTIFIED BY 'password';# 查看所有用户mysql&gt; select host, user from mysql.user;# 查看当前用户mysql&gt; select current_user;# 查看当前用户权限mysql&gt; show grants; 数据库操作 1234567891011121314151617181920# 显示数据库mysql &gt; show databases;# 选择数据库mysql &gt; use mysql;# 创建数据库mysql &gt; CREATE DATABASE `databasename` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;# 显示数据库的所有表mysql&gt; show tables;# 创建表mysql&gt; create table student(id int auto_increment primary key,name varchar(16) not null, age int, sex char(1));# 查看表结构mysql&gt; describe student;# 查看索引mysql&gt; show index from students; 增删改查 ​ ……","link":"2021/12/18/Centos7-Mysql-%E4%BD%BF%E7%94%A8/"},{"title":"hexo-icarus 从零搭建个人博客","text":"hexo-icarus 使用详解0. 安装Requirements Node.js ($\\geq$ 10.13) Git Install hexo 1npm install -g hexo 安装之后便可以使用命令： 1npx hexo &lt;command&gt; Install icarus 在 Hexo 网站目录下，安装 icarus 主题： 1npm install -S hexo-theme-icarus 推荐下载 icarus 仓库到 theme 目录下，方便后续调整 icarus 配置： 1git clone https://github.com/ppoffice/hexo-theme-icarus.git theme/icarus 在 hexo 的默认配置文件 _config.yml 中开启 icarus 主题： 1theme: icarus 1. 初始化初始化 Hexo 目录： 123npx hexo init &lt;folder&gt;cd &lt;folder&gt;npm install 初始化之后的目录： 12345678 .├── _config.yml # 配置文件├── package.json # 应用依赖的版本├── scaffolds # 脚手架模板├── source # 网站内容 | ├── _drafts # Hexo 忽略'_'开头的隐藏文件（夹），除了&quot;_posts&quot; | └── _posts└── themes # 主题 2. 基础配置_config.yml 为全局配置文件，主题下的 _config.yml 具有最低的优先级。 Site title 网站标题 subtitle 副标题 description 网站描述 keywords 关键词，支持多个 author 作者 language 语言，e.g.，en timezone 时区，默认为当前计算机时区 Url url 网址，必须以 ‘http://’ 或 ‘https://’ 开头 root 网站的根目录 permalink 文章的永久链接形式，:year/:month/:day/:title/ pretty_urls.trailing_index 文章链接跟随 ‘index.html’，设为 false 以删除 pretty_urls.trailing_html 文章链接跟随 ‘.html’，设为 false 以删除 如果网站是一个子目录，例如 ‘http://example.com/blog‘，那么把 url 设为 ’http://example.com/blog‘，把 ‘root’ 设为 ’/blog/‘。 Directory source_dir 存放内容的目录 public_dir 生成的静态文件的目录 tag_dir 标签目录 archive_dir 归档目录 category_dir 分类目录 code_dir 包含的代码的目录 i18n_dir 国际化语言目录 skip_render 跳过渲染，直接拷贝到 ‘public_dir’ 的路径 例如，skip_render: “mypage/*/\\”，跳过 ‘source/mypage/’ 下的所有文件。 skip_render: ”_posts/test-post.md”，跳过 ‘source/_posts/test_post.md’ 这篇文章。 Writing new_post_name 新的文章的文件名，:title.md default_layout 默认布局，post titlecase 将标题转为小写 external_link.enable 使用新标签打开外部链接 external_link.field 用于整个网站（site）还是仅该帖子（post） external_link.exclude 排除的主机名 filename_case 文件名大小写，0: 不转些, 1: 转小写, 2: 转大写 render_drafts 渲染草稿 post_asset_folder 启用 Assert 目录 relative_link 使用相对路径 future 显示未来的帖子 highlight 代码语法高亮设置 prismjs 同上 Extensions theme 使用主题 theme_config 主题配置，覆盖默认主题 deploy 部署设置 meta_generator 更多信息：Configuration 3. icarus 主题配置基础配置和常见问题：hexo-theme-icarus 有问题先翻一翻官方说明和 issues，很多都已解决！ 其他优化配置： 设置图片居中：Hexo博客主题之Icarus的设置与美化（进阶） Latex 公式问题：Hexo折腾系列（六）数学公式渲染优化 夜间模式：Hexo主题Icarus的自定义 Mathjax 自动换行：Hexo主题Icarus的自定义 4. 命令初始化网站初始化一个网站 1hexo init [folder] 新建帖子1hexo new [layout] &lt;title&gt; layout 默认为 _config.yml 中的 default_layout。 title 是不可少的，如果 title 中有空格，请将 title 用引号引起来。 选项： -p, —path 自定义帖子路径 -r, —replace 如果帖子存在，则替换 -s, —slug 自定义帖子的 url 默认情况下，hexo 将使用 post 的 title 来定义文件的路径。使用 —path 来覆盖此行为，例如： 1hexo new --path about/me &quot;About me&quot; 该命令会在 source/_posts/about/ 路径下生成 me.md 帖子，帖子标题为 “About me”。 生成静态文件12hexo generatehexo g # 简写 选项： -d, —deploy 生成文件结束后部署 -w, —watch 观察文件变化 -b, —bail 如果生成文件出错，则抛出错误 -f, —force 强制重新生成文件 -c, —concurrency 并行生成文件数，默认最大 发布草稿1hexo publish [layout] &lt;filename&gt; 启动服务12hexo serverhexo s # 简写 启动本地服务，默认网址为 http://localhost:4000/ 。 选项： -p, —port 端口号 -s, —static 只使用静态文件 -l, —log 开启日志记录 部署文件12hexo deployhexo d # 简写 选项： -g, —generate 部署浅先生成静态文件 清理缓存1hexo clean 清理缓存文件（db.json）和生成的文件（public）。 其他命令12345678hexo list &lt;type&gt; # 列出所有路径hexo version # 查看版本号hexo --safe # 禁止加载插件和脚本hexo --debug # 将详细信息记录到终端和 debug.loghexo --silent # 终端忽略输出hexo --drafts # 发布草稿hexo --config config.yml # 设置配置路径hexo --cwd /path/to/cwd # 自定义当前工作目录 5. 开始写作修改初始化头部信息 头部信息块是一个 YAML 或者 json 代码块，包含以下信息： layout Layout，config.default_layout title date updated comments 是否允许评论 tags 标签 categories 分类 toc 是否使用 toc，注意，如果想使用 toc 的话这个一定要设为 true cover 封面图路径 thumbnail 缩略图路径 excerpt 简介 注意：在生成新帖子时，会按照 scaffolds 目录中的模板生成头部信息，因此最好先定义好模板中的头部信息。 创建帖子 1hexo new [layout] &lt;title&gt; 有三种 layout： post source/_posts（默认） page source draft source/drafts","link":"2021/12/13/hexo-icarus%20%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"title":"人工智能领域会议简介","text":"第一梯队IJCAIAI最好的综合性会议, 1969年开始, 每两年开一次, 奇数年开. 每届基本上能录100多篇（现在已经到200多篇了），但分到每个领域就没几篇了。 AAAI美国人工智能学会AAAI的年会.比IJCAI还是要稍弱一点 NIPS神经计算方面最好的会议之一, NIPS主办, 每年举行.NIPS里有相当一部分神经科学的内容, 和机器学习有一定的距离. 但由于会议的主体内容是机器学习, 或者说与机器学习关系紧密, 所以 不少人把NIPS看成是机器学习方面最好的会议之一.对Jordan系以外的人来说, 发NIPS的难度比ICML更大. 换句话说, ICML比较开放, 小圈子的影响不象NIPS那么大, 所以北美和欧洲人都认, 而NIPS则有些人(特别是一些欧洲人, 包括一些大家)坚决不投稿.Michael Jordan是伯克利大学教授，统计机器学习的老大，大牛中的巨牛 ICLRInternational Conference on Learning Representations,深度学习领域最重要的会议之一，尽管才第五届，已经有很多非常重要的文章，比如VGG Net,attention等 CVPR计算机视觉和模式识别方面最好的会议之一, IEEE主办, 每年举行. 虽然题目上有计算机视觉, 但个人认为它的模式识别味道更重一些. 事实上它应该是模式识别最好的会议, 而在计算机视觉方面, 还有ICCV与之相当. ICCV计算机视觉方面最好的会之一. IEEE主办, 每年举行. ICML机器学习方面最好的会议之一. 现在是IMLS主办, 每年举行. ACL计算语言学/自然语言处理方面最好的会议, ACL (Association of Computational Linguistics) 主办, 每年开. KR知识表示和推理方面最好的会议之一, 实际上也是传统AI(即基于逻辑的AI) 最好的会议之一. KR Inc.主办, 现在是偶数年开. SIGIR信息检索方面最好的会议, ACM主办, 每年开. 这个会现在小圈子气越来越重. 信息检索应该不算AI, 不过因为这里面用到机器学习越来越多, 最近几年甚至有点机器学习应用会议的味道了 SIGKDD数据挖掘方面最好的会议, ACM主办, 每年开. COLT计算学习理论最好的会议, ACM主办, 每年举行. 计算学习理论基本上可以看成理论计算机科学和机器学习的交叉。“一小群数学家在开会” 第二梯队AAMAS (2+)agent方面最好的会议. 但是现在agent已经是一个一般性的概念, 几乎所有AI有关的会议上都有这方面的内容, 所以AAMAS下降的趋势非常明显. ECCV (2+)计算机视觉方面仅次于ICCV的会议, 因为这个领域发展很快, 有可能升级到1-去. ECML (2+)机器学习方面仅次于ICML的会议, 欧洲人极力捧场,因为机器学习发展很快, 这个会议的reputation上升非常明显. ICDM (2+)数据挖掘方面仅次于SIGKDD的会议, 目前和SDM相当. 这个会只有5年历史, 上升速度之快非常惊人. 几年前ICDM还比不上PAKDD, 现在已经拉开很大距离了. SDM (2+)数据挖掘方面仅次于SIGKDD的会议, 目前和ICDM相当. SIAM的底子很厚, 但在CS里面的影响比ACM和IEEE还是要小, SDM眼看着要被ICDM超过了, 但至少目前还是相当的. COLLING (2)计算语言学/自然语言处理方面仅次于ACL的会, 但与ACL的差距比ICCV-ECCV和ICML-ECML大得多. ECAI (2)欧洲的人工智能综合型会议, 历史很久, 但因为有IJCAI/AAAI压着,很难往上升. EMNLP (2-)计算语言学/自然语言处理方面一个不错的会. 有些人认为与COLLING相当, 但我觉得它还是要弱一点. 第三梯队ACCV (3+)亚洲的计算机视觉会议, 在亚太级别的会议里算很好的了. ICIP (3)图像处理方面最著名的会议之一, 盛会型. ICPR (3)模式识别方面最著名的会议之一, 盛会型. IJNLP (3)计算语言学/自然语言处理方面比较著名的一个会议. IJCNN (3)神经网络方面最重要的会议, 盛会型, 参见CEC的介绍.","link":"2021/12/14/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A2%86%E5%9F%9F%E4%BC%9A%E8%AE%AE/"},{"title":"ffmpeg 使用记录","text":"精确裁剪视频1ffmpeg -ss 10 -t 15 -accurate_seek -i test.mp4 -codec copy -avoid_negative_ts 1 cut.mp4 -ss: 起始位置，单位：秒 -t: 持续时间，单位：秒 合并音视频1ffmpeg -i video.mp4 -i audio.wav -c:v copy -c:a aac -strict experimental output.mp4 如果视频中已经包含了音频，这个时候还可以替换视频中的音频，使用下面命令行。 12ffmpeg -i video.mp4 -i audio.wav -c:v copy -c:a aac -strict experimental -map 0:v:0 -map 1:a:0 output.mp4 拼接音频1ffmpeg -i input1.mp3 -i input2.mp3 -filter_complex amerge -ac 2 -c:a libmp3lame -q:a 4 output.mp3 提取视频中的音频1ffmpeg -i input.mp4 -vn -y -acodec copy output.m4a 压缩视频123456789ffmpeg -i input.mp4 -r 20 output.mp4ffmpeg -i input.mp4 -fs 20MB output.mp4ffmpeg -i input.mp4 -b:v 1.5M output.mp4ffmpeg -i input.mp4 -s 960x540 output.mp4-r: 改变帧率-fs: 指定大小-b:v 改变码率为1.5M/s-s: 改变分辨率为960x540 视频类型转换12# 快速转换ffmpeg -i input.flv -codec copy output.mp4 视频、音频倍速1234567# 视频滤波器通过改变每一个 pts 时间戳来实现，pts 时间长则播放慢# -r 指定帧数# 0.25 代表四倍速ffmpeg -i input.mkv -r 120 -filter:v &quot;setpts=0.25*PTS&quot; output.mkv# 2.0 代表 0.5 倍速ffmpeg -i input.mkv -filter:v &quot;setpts=2.0*PTS&quot; output.mkv 12# 通过 av filter 中的 atempo 来实现音频的倍速播放ffmpeg -i input.mkv -filter:&quot;atempo=2.0&quot; -vn output.mkv 12# 同时对视频和音频倍速播放ffmpeg -i input.mkv -filter_complex &quot;[0:v]setpts=0.5*PTS[v];[0:a]atempo=2.0[a]&quot; -map &quot;[v]&quot; -map &quot;[a]&quot; output.mkv","link":"2021/12/14/ffmpeg-%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/"},{"title":"对话系统","text":"1. 引言​ ”机器能否思考？”是一个历史悠久的问题，是二元并存论与唯物论思想之间的区别。唯物主义者笛卡尔认为机器不能像人那样作出适当的反应，并借此区分机器和人。狄德罗也曾说过，“如果他们发现一只鹦鹉可以回答一切问题，我会毫不犹豫宣布它存在智能。” 1950年，密码学和人工智能先驱图灵发表了一篇关于计算机器与智能的论文，提出了著名的 “图灵测试”：如果一台机器能够与人类展开对话（通过电传设备）而不被辨别出其机器身份，那么称这台机器具有智能。令人信服地说明“思考的机器”是可能的。 ​ 图灵测试作为当时衡量人工智能 “智能性” 的最常用标准，指导了后世的计算机与人工智能的发展与技术创新。如今，人工智能的快速发展使得机器在某些领域（如图像识别、语音识别等领域）通过了图灵测试甚至超越了人类的水平，图灵测试虽然不能真正回答 “机器能否思考” 这一问题，但它一直是对话系统的重要评测手段和目标。 2. 发展​ 图灵测试最初是人通过文字与机器进行交流的，伴随着人工智能的研究，人们一直在努力开发高度智能化的人机对话系统。对话系统是人工智能最具挑战性、最综合性的技术之一，涵盖了语义理解、知识表示、逻辑与推理、语言生成等各个方面。第一代对话系统主要是基于规则的。具有代表性的是1966年由MIT开发的使用模板匹配的心理医学聊天机器人 ELIZA 系统。这种基于有限状态自动机的流程图对话系统在当时很流行，优点是具有清晰的内部逻辑，易于分析和调试。但由于高度依赖专家干预，其灵活性和可扩展性很差。 ​ 随着大数据技术的兴起，由统计数据驱动的第二代对话系统应运而生。当时，强化学习在对话系统种被广泛研究和应用。在2005年由剑桥大学Steve Young教授提出的基于部分可观测马尔可夫决策过程 (POMDP)的统计对话系统，在鲁棒性上显著超越了基于规则的对话系统。它通过基于语音识别结果的贝叶斯推理来维护每一轮对话的状态，然后根据对话状态选择对话策略以生成自然语言回复。基于强化学习，该系统不断与仿真用户或真实用户交互，以检测错误并相应地优化对话策略。基于统计数据的对话系统不高度依赖专家干预，但是它的可扩展性依旧较差，并且模型很难维护。 ​ 最近几年，随着深度学习在图像、语音、文本等领域取得的突破，出现了基于深度学习的第三代对话系统。这些系统延续了统计对话系统的架构，但在各个模块应用论神经网络。神经网络的优点是具有很强的表示、分类和生成的能力，使用深度学习的对话系统超越了第二代对话系统，但在训练时需要大量的标注数据。因此，在提高模型的迁移性上仍需要大量研究。 3. 分类​ 通常，对话系统按照任务类型可分为三类：闲聊型对话系统、任务型对话系统以及问答型对话系统。 ​ 闲聊型对话系统的任务是跟随人机交互生成有趣且信息丰富的回答。 ​ 问答型对话系统分析提出的问题并在知识库中找出正确的答案。 ​ 任务型对话系统是任务驱动的多轮对话，理解用户的需求并给出正确结果，是一系列的决策过程。例如订餐、订票、查找产品等。在对话过程中，机器更新和保持内部对话状态，然后基于当前状态选择最佳回应，例如确定需求、查询限制并提供结果。 ​ 三种类型的对话系统并非完全割裂，在任务型、问答型对话系统中往往会穿插闲聊。 ​ 同时，对话系统按照领域又可分为开放域对话和限定域对话，按照对话的生成方式可分为检索式和生成式。 4. 开放域闲聊对话系统​ 主流的开放域闲聊对话系统大致上可以分为生成式和检索式两种，前者通过生成式神经网络模型根据用户输入逐词生成直至构成一个完整对话，代表工作有ECM[1]、CCM[2]，ConceptFlow[3]。后者通过在大规模对话语料库中检索得到合适的对话进行回复，代表工作有SMN[4]、DAM[5]等。近年来，随着大规模预训练模型的兴起，基于预训练的对话模型在性能上进一步提升，逐渐成为主流，代表工作有DialoGPT[6] (Microsoft)，Blender[7] (Facebook)，Meena[8] (Google)，PLATO-2[9] (Baidu) 等。 ​ 单轮的生成式闲聊对话系统可以看成是序列-序列（Seq2Seq）的编码-解码问题，不同于机器翻译，对话生成的输出空间非常大，并且用户输入的对话内容十分有限，单纯依赖用户输入来生成对话会产生重复、信息量缺乏、没有意义的回复。因此，单轮的生成式对话往往需要根据用户输入引入主题、知识库、知识图谱等信息，从而使生成的回复更加多样性和包含丰富的信息。多轮的生成式对话比单轮对话更加复杂，因为需要考虑聊天历史的上下文信息。大规模预训练模型在多轮对话闲聊任务上的表现更好。 ​ 生成式的闲聊对话系统很难处理评估和控制这两个问题。在评估上，生成式对话的结果没有标准答案，其评估往往需要依赖人工评定。在控制上，在生成过程中面临的条件非常多，尤其是开放域闲聊系统，需要考虑上下文信息、说话人的属性、场合等等，很难控制生成器的生成过程。这也是行业更多采用检索式对话系统的原因。 ​ 检索式方法是从候选回复中选择一个最佳回复，其关键在于用户输入的消息与候选回复的匹配。单轮的检索式对话相对简单，通常将用户输入的消息和候选回复进行编码，定义匹配算法检索最佳匹配。多轮的检索式对话则将历史对话与当前消息共同编码作为检索请求来匹配最佳回复。 5.问答型对话系统​ 问答型对话系统多为一问一答的形式，检索式的方法计算用户问句与问答库中问句的相似度，选择最相似的问句并给出其对应的回答（FAQ）。另一种方法是基于知识库的问答（KBQA），该方法分析和理解用户问句，识别意图，提取实体、属性等信息，并利用知识图谱中的结构化知识进行查询、推理，最后生成回复。 6. 任务型对话系统​ 任务型系统需要结合知识领域和后端的数据库或应用接口链接以完成具体操作。任务型对话系统主要分为两类：一类是具有模块化结构的流水线系统（pipeline system），另一类是最近流行于学术研究的端到端（end-to-end）系统。 ​ 任务型对话系统中广泛应用的是流水线系统，该系统由四个模块组成： 自然语言理解（Natural Language Understanding，NLU）：识别并解析用户的文本输入，以获得可供计算机使用的语义标记，如槽值（slot-values）和意图（intentions）。这些slot是根据场景预先设定的，槽值填充通常为序列标注（sequence labeling）问题，通过命名实体识别获取输入文本中包含的槽值。意图检测为分类问题，将输入文本分类为预设的意图类型。 对话状态追踪（Dialog State Tracking，DST）：根据对话历史维护当前对话状态，通常表示为槽值对。 对话策略（Dialog Policy，DP）：根据当前对话状态输出系统下一步动作。与对话状态追踪构成对话管理（Dialog Management，DM）模块。 自然语言生成（Natural Language Generation，NLG）：将系统动作转化为自然语言输出。 ​ 这种对话系统具有很好的可解释性，模块之间相互独立，在行业中应用最多。但缺点是结构不够灵活，模块之间独立导致很难一起优化，使得很难适应不同的应用场景，并且需要耗费精力去设计各个模块。 ​ 为了减少人工参与并提高不同领域之间的扩展性，端到端的任务型对话系统直接将用户输入转化为系统输出，高度灵活且扩展性强，去除了模块之间的独立性。然而，这种方法非常依赖高质量和大数量的数据，过程难以控制且可解释性不高，模型仍需要进一步探索 ，目前在行业中应用很少。 7. 数据集单轮对话​ 生成式 Reddit dataset (Zhou et al., 2018) Weibo dataset (Wu et al., 2020) Persona-chat dataset (Zhang et al., 2018) Each dialogue was constructed from a pair of crowd-workers, who chat to know each other. Each worker was assigned a persona profile, describing their characteristics, and this profile serves as knowledge in the conversation. There are 151,157 turns (each turn corresponds to an utterance and a response pair) of conversations in Persona-chat, which we divide into 122,499 for train, 14,602 for validation and 14,056 for test. The average size of a knowledge collection (the average number of sentences in a persona profile) in this dataset is 4.49. Wizard-of-Wikipedia (Dinan et al., 2018) 多轮对话​ Chatbot MovieTriples (Serban et al., 2016) Developed by expanding and preprocessing the Movie-DiC dataset by Banchs et al. (2012) Span a wide range of topics, contain long interactions with few participants and relatively few spelling mistakes and acronyms. ​ Task-oriented bAbI dialog (Bordes and Weston, 2017) The bAbI dialog includes five end-to-end dialog learning tasks in the restaurant domain, which are simulated dialog data. Task 1 to 4 are about API calls, refining API calls, recommending options, and providing additional information, respectively. Task 5 is the union of tasks 1-4. DSTC2 (Henderson et al., 2014) Extracted from real human-bot dialogs, which is noisier and harder since the bots made mistakes due to speech recognition errors or misinterpretations. In-Car Assistant / SMD (Eric et al., 2017) It has three distinct domains: calendar scheduling, weather information retrieval, and point-of-interest navigation. This dataset has shorter conversation turns, but the user and system behaviors are more diverse. In addition, the system responses are variant and the KB information is much more complicated. Hence, this dataset requires stronger ability to interact with KBs, rather than dialog state tracking. Penn Tree Bank (Marcus et al., 1993) Text8 (Mikolov et al., 2014) MultiWOZ 2.1 (Kim et al., 2020) Each newly inserted turn is grounded on unstructured knowledge in one of the four domains: restaurant, hotel, taxi and train, with the label of its relevant document in the document base. CMUDoG (Zhou, Prabhumoye, and Black, 2018) The dataset addresses the concern of the grounding in conversation responses, context, and coherence in responses. Each movie document consists of four sections corresponding to basic information and three key scenes of the movies. The 4 sections are shown to one or both workers one by one every 3 turns. The dataset consists of total 4112 conversations with an average of 21.43 turns and has been divided into a training set, validation set and test set by publishers. CamRest Contains 676 multi-turn dialogs be\u0002longing to restaurant reservation domain. There are 5 turns on average per dialog. Selected Douban Ubuntu E-commerce 8. Baselines单轮对话​ 生成式 (Generation) Seq2Seq (Sutskever et al., 2014) /+Attention (Luong et al., 2015) CopyNet (Gu et al., 2016) GenDS (Zhu et al., 2017) MemNet (hard/soft) (Ghazvininejad et al., 2018) PostKS (concat/fusion) (Lian et al., 2019) CCM (Zhou et al., 2018) GPT-2 (Radford et al., 2019) ​ 检索式 (Retrieval) 多轮对话​ Chatbot HRED (Serban et al., 2016) ​ Task-oriented Seq2Seq / + Attention MemNN (Sukhbaatar et al., 2015) Ptr-Unk (Gulcehre et al., 2016) GMemNN (Liu and Perez (2017) Mem2Seq (Madotto et al., 2018) GLMP (Wu et al., 2019) 9. 评价指标生成式 PPL BLEU ROUGE Nist Meteor Dist-1/2 Ent-4 P/R/F1 检索式 R10@1/2/5 参考文献[1] Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory, AAAI 2018. [2] CCM: Commonsense Knowledge Aware Conversation Generation with Graph Attention, IJCAI 2018. [3] Grounded Conversation Generation as Guided Traverses in Commonsense Knowledge Graphs, ACL 2020. [4] Sequential Matching Network: A New Architecture for Multi-turn Response Selection in Retrieval-Based Chatbots, ACL 2017. [5] Multi-Turn Response Selection for Chatbots with Deep Attention Matching, ACL 2018. [6] DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation, ACL 2020. [7] Recipes for building an open-domain chatbot, facebook 2020. [8] Towards a Human-like Open-Domain Chatbot, google 2020. [9] PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning, ACL 2021.","link":"2021/12/14/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"title":"图神经网络——综述","text":"本文对 “A comprehensive survey on graph neural networks, IEEE 2021”这篇综述论文进行了翻译，旨在加深对文章内容的理解，并供日后参考。综述原文：A comprehensive survey on graph neural networks, IEEE 2021。 &emsp;&emsp;近年来，深度学习在许多机器学习任务上（如图像分类、视频处理、语音识别、自然语言处理）取得了开创性的成果。通常，这些任务的数据（如图像、序列信息）都是表示在欧氏空间的（Euclidean space）。然而越来越多的应用数据是非欧氏空间的，例如图数据用图结构来表示，不同对象之间有复杂的关系和内在依赖，使得现有的机器学习算法变得不再有效。 &emsp;&emsp;最近，出现了许多针对图数据的深度学习方法。本文对数据挖掘（data mining）和机器学习（machine learning）领域的图神经网络（Graph Neural Networks, GNNs）进行全面梳理，并将其分为四类：循环图神经网络（recurrent GNNs，RecGNNs），卷积神经网络（convolutional GNNs，ConvGNNs），图自编码器（graph autoencoders，GAEs）和时空神经网络（spatial-temporal GNNs，STGNNs）。 1. 引言&emsp;&emsp;神经网络近年来的成果促进了模式识别和数据挖掘的研究。许多机器学习任务，例如目标检测、机器翻译和语音识别等，曾严重依赖特征工程人工地提取特征信息，最近被各种端到端的深度学习方法所取代。深度学习方法的成功得益于快速发展的计算资源（如 GPU）和大量训练数据，以及从欧式空间数据（如图像、文本和视频）提取隐含表示的有效性。以图像数据为例，图像可以表示为欧氏空间的规则网格数据。CNN 能够利用图像数据的移位不变性、局部连通性和组合性提取可全局共享的有意义的局部特征。 &emsp;&emsp;深度学习能够有效捕获欧氏空间数据的隐藏模式，然而越来越多的应用数据表示为图的形式。例如，在电子商务中，一个基于图的学习系统可以利用用户和产品之间的交互做出高度准确的推荐；在化学领域，分子被表示为图模型，鉴定分子的生物活性可用于药物发现；在引文网络中，文章通过引文系统相互连接，需要将文章分为不同的组。图数据的复杂性给现有的机器学习算法带来了巨大的挑战。由于图是不规则的，节点无序且多变，并且节点的邻居数量也可能不同，导致一些重要操作（如卷积）在图像中容易计算但在图领域中却很难计算。另外，现有的机器学习算法的一个重要假设是数据实例之间的相互独立性，这个假设在图数据中不再成立，因为图的每个实例（节点）通过多变的连接相互关联，并非独立。 2. 背景介绍图神经网络简史&emsp;&emsp;Sperduti 和 Starita （1997）首次将神经网络应用到有向无环图（directed acyclic graphs）中 [1]，激发了早期的对 GNNs 的研究。大多数早期的 GNNs 是 RecGNNs，它们通过迭代的方式传播邻居信息直到达到一个稳定值，以此来学习目标节点的表示，然而这个过程的计算成本很高。 &emsp;&emsp;鉴于 CNNs 在计算机视觉领域的成功，ConvGNNs 得到了大量研究，主要分为两类：基于谱（spectral-based）的方法和基于空间（spatial-based）的方法。基于谱的 ConvGNNs 的第一个重要研究是由 Bruna 等人（2014）提出的基于谱图论（spectral graph theory）的图卷积 [2]。从此，基于谱的 ConvGNNs 得到了越来越多的改进、扩展和研究。实际上，基于空间的 ConvGNNs 的研究要早于基于谱的 ConvGNNs。2009年，Micheli 继承了 RecGNNs 中消息传递的思想，通过复合非递归层（composite nonrecursive layers）首次解决了图的相互依赖性 [3]。然而这篇重要的工作的在当时被忽略了，直到最近才出现了许多基于空间的 ConvGNNs。 &emsp;&emsp;除了 RecGNNs 和 ConvGNNs，最近几年出现了一些其他的 GNNs，包括 GAEs 和 STGNNs 等。 图神经网络 vs 网络嵌入&emsp;&emsp;GNNs 的研究与图嵌入或网络嵌入是十分相关的。网络嵌入（Network Embedding）目的是在保留网络拓扑结构和节点内容信息的同时将网络节点表示为低维向量表示，从而方便将现有的机器学习算法应用到下游的图分析任务中，例如分类、聚类和推荐等。另一方面，GNNs 是以端到端的方式解决图相关任务的深度学习模型，目的是提取图、节点等的高层表示。GNNs 和网络嵌入之间的主要区别是，GNNs 是针对不同任务设计的一组神经网络模型，而网络嵌入涵盖网络节点嵌入的不同方法，包括非深度学习方法，例如矩阵分解、随机游走等。 图神经网络 vs 图核方法&emsp;&emsp;图核（Graph kernels）是早期解决图分类问题主流方法，这种方法使用核函数来度量图之间的相似性。与 GNNs 类似，图核方法可以通过映射函数将图或节点嵌入向量空间。不同的是，图核的映射函数是确定的，而 GNNs 是可学习的。 3. 分类和框架A. 图神经网络分类 循环图神经网络（Recurrent Graph Neural Networks, RecGNNs）：大多数早期的 GNNs 是循环图神经网络（下称 RecGNNs），它通过循环神经结构学习节点表示。RecGNNs 认为图中的一个节点不断地与其邻居节点交换信息直到达到稳定平衡。其消息传递（message passing）的思想在基于空间的卷积图神经网络（spatial-based ConvGNNs）中也得到了应用。 卷积图神经网络（Convolutional Graph Neural Networks, ConvGNNs）：这是将卷积操作从网格数据到图数据的拓展。主要思想是通过整合节点本身及其邻居节点的特征来表示该节点。 图自编码器（Graph Autoencoders, GAEs）：GAEs 是无监督的学习框架，编码器将节点、图编码到隐含向量空间，然后通过解码器从编码的信息重构图数据。 B. 框架​&emsp;&emsp;图神经网络的输入是图结构（graph structure）和节点的内容信息（node content information），输出可用于不同的图分析任务。 节点级别（Node level）：用于节点回归（node regression）和节点分类（node classification）任务。RecGNNs 和 ConvGNNs 分别通过信息传播和图卷积捕获高层节点表示，然后接多层感知机或 softmax 层作为输出层，从而可以端到端地处理节点级别的任务。 边级别（Edge level）：用于边分类（edge classification）和链接预测（link prediction）任务。通过 GNNs 得到两个节点的隐藏表示，使用相似度函数或者神经网络可以预测节点之间的边的标签（label）或连接强度（connection strength）。 图级别（Graph level）：用于图分类（graph classification）任务。为了得到图级别的紧凑表示（compact representation），GNNs 通常与池化（pooling）和读出（readout）操作相结合。 训练框架 ​&emsp;&emsp;许多 GNNs 能够通过端到端的学习框架以（半）监督或完全无监督的方式训练，这取决于学习任务和可获得的标签信息。 节点分类的半监督学习：对于只有部分节点标签的图网络，ConvGNNs 能够学习一个鲁棒的模型用于高效地判断（identify）无标签节点的标签。 图分类的监督学习：图分类的目的是预测整个图的类别。该任务可以结合图卷积层、图池化层和读出层进行端到端学习。其中，图卷积层提取高层节点表示；图池化层进行下采样，将图粗化（coarsen）为子结构；读出层将每个图的节点表示细化为图表示；最后使用多层感知机或 softmax 层对图表示进行分类。 图嵌入的无监督学习：当图中没有类别标签时，可以通过端到端的框架以完全无监督的方式学习图嵌入。这些利用边信息的算法分为两种：第一种简单的方法是采用自编码器框架，其中编码器使用图卷积层将图嵌入到隐藏表示，解码器用隐藏表示重构图结构；另一种流行的方法是利用负采样将一部分节点作为负样本对（negative pairs），而图中存在连接的节点对作为正样本对。然后使用逻辑回归层来区分正负样本对，以此来学习图嵌入。 4. 循环图神经网络&emsp;&emsp;RecGNNs 是最早得到研究的 GNNs，考虑到计算能力，早期的研究主要集中在有向无环图（directed acyclic graphs）。Scarselli 等人（2009）[4] 将之前的递归模型扩展到处理一般类型的图的模型 GNN*（为区分于广泛意义上的 GNN，用 GNN*来表示该模型），如无环图、有环图、有向图、无向图。基于信息扩散机制（information diffusion mechanism），GNN* 通过循环交换邻居信息来更新节点状态直到达到一个稳定平衡。节点的隐藏状态通过下面的公式更新： h^{(t)}_v = \\sum_{u \\in N(v)} f(x_v, x^e_{(v, u)}, x_u, h^{(t-1)}_u)&emsp;&emsp;其中，$f(·)$ 是参数函数，$h^{(0)}_v$ 是随机初始化的。该求和函数使得 GNN* 适用于任何节点，即使节点的邻居数量不同且不知道邻居的顺序。为了保证收敛，递归函数 $f(·)$ 必须是收缩映射，将两个点映射到潜在空间后收缩两点之间的距离。如果 $f(·)$ 是神经网络，那么参数的雅可比矩阵必须要施加一个惩罚项。当满足收敛准则时，再将最后一层节点的隐藏状态前向传播到读出层。GNN* 通过计算交替节点状态传播核参数梯度来最小化训练目标，这种策略使 GNN* 能够解决有环图。在后续工作中，GraphESN（graph echo state network）（2010）[5] 扩展了 echo state 网络以提高 GNN* 的训练效率。 &emsp;&emsp;GGNN （Gated GNN）（2015）[6] 使用了门控循环单元（GRU）作为循环函数，将循环次数降低到一个固定的步骤数，其优点是不再需要约束参数来确保收敛。节点隐藏状态通过其先前的隐藏状态和相邻的隐藏状态更新： h^{(t)}_v = GRU(h^{(t-1)}_v, \\sum_{u \\in N(v)} Wh^{(t-1)}_u)&emsp;&emsp;其中，$h^{(0)}_v = x_v$ 。与 GNN* 和 GraphESN 不同，GGNN 使用时间反向传播（backpropagation through time, BPTT）算法来学习模型参数。GGNN 需要对所有节点多次迭代计算，并需要将所有结点的中间状态存储在内存中，这对于大型图来说是有问题的。 &emsp;&emsp;SSE（Stochastic steady-state embedding）（2018）[7] 是一种对大型图更具扩展性的学习算法，以随机和异步的方式重复更新节点隐藏状态。它对一批节点进行采样以进行状态更新，并对一批节点进行梯度计算。为了保持稳定性，SSE 的循环函数为历史状态和新状态的加权平均： h^{(t)}_v = (1 - \\alpha )h^{(t-1)}_v + \\alpha W_1 \\sigma (W_2[x_v, \\sum _{u \\in N(v)}[h^{(t-1)}_u, x_u]])&emsp;&emsp;其中，$\\alpha$ 是超参数，$h^{(0)}_v$ 是随机初始化的。虽然 SSE 在概念上很重要，但是它没有从理论上证明通过重复利用该函数，节点状态能够收敛到稳定值。 5. 卷积图神经网络&emsp;&emsp;由于卷积操作效率更高并且更易于与其他网络组合，近年来对 ConvGNNs 的研究迅速增长。ConvGNNs 分为两类：基于谱的（spectral-based）与基于空间的（spatial-based）。基于谱的方法从图信号处理（graph signal processing）的角度引入了滤波器，将图卷积运算解释为从图信号中去除噪声；基于空间的方法继承了 RecGNNs 的信息传播的思想，将图卷积定义为信息传播。由于 GCN（2017）[8] 弥合了基于谱的方法和基于空间的方法之间的鸿沟，基于空间的方法由于其高效、灵活和通用，最近得到了迅速发展。 A. 基于谱的 ConvGNNs&emsp;&emsp;基于谱的方法基于很强的图信号处理的数学基础。无向图的数学表示为归一化的图拉普拉斯矩阵（normalized graph Laplacian matrix）是，定义为 $ \\mathrm{L = I_n - D ^{(1/2)}AD^{-(1/2)}}$，其中 $\\mathrm D$ 是节点度的对角矩阵，$\\mathrm{D_ij = \\sum_j(A_{i,j})}$。归一化的图拉普拉斯矩阵具有实对称半正定的性质，基于此，可以分解为 $\\mathrm{L = U\\Lambda U^T}$，其中 $\\mathrm U = [u_0, u1, …, u_{n-1}] \\in R^{n \\times n}$ 是按特征值排序的特征向量矩阵，$ \\Lambda $ 是特征值的对角矩阵（谱），$\\Lambda_{ij} = \\lambda_i$。在数学上，归一化拉普拉斯矩阵的特征向量形成一个正交空间 $\\mathrm {U^TU = I}$。在图信号处理中，一个图信号 $x \\in R^n $ 是图的所有节点的一个特征向量，其中 $x_i$ 是第 i 个节点的特征值。一个信号 $\\mathrm x$ 的图傅里叶变换定义为 $\\mathscr F(x) = \\mathbf {U^T} \\mathbf x$，逆变换为 $\\mathscr F^{-1}(\\hat x) = \\mathbf {U \\hat x}$，其中 $\\mathbf {\\hat {x}}$ 表示图傅里叶变换后的信号。图傅里叶变换将输入的图信号映射到正交空间，基由归一化的图拉普拉斯算子的特征向量构成。变换后的信号 $\\hat x$ 的元素是新空间中图信号的坐标，因此输入的信号可以表示为 $x = \\sum_i \\hat x_iu_i$，这正是图傅里叶逆变换。于是，输入信号 $\\mathbf x$ 与滤波器 $\\mathbf {g \\in R^n}$ 定义为: \\mathbf {x *_G g = \\mathscr F^{-1}(\\mathscr F(x) \\odot \\mathscr F(g)) = U(U^T x \\odot U^T g)}&emsp;&emsp;其中，$\\odot$ 表示元素乘积（elementwise product）。如果我们将滤波器表示为 $\\mathbf g_\\theta = diag(\\mathbf {U^T g})$，那么谱图卷积（spectral graph convolution）就被简化为： \\mathbf {x *_G g_\\theta = U g_\\theta U^T x}&emsp;&emsp;基于谱的 ConvGNNs 遵循以上定义，主要区别在于滤波器 $\\mathbf g_\\theta$ 的选择。Spectral CNN（2014）[9] 将滤波器 $\\mathbf g_\\theta = \\Theta^{(k)}_{i,j}$ 当作可学习的参数并且可以处理多通道的图信号。其图卷积层定义为： &emsp;&emsp;其中，$k$ 是层索引，$\\mathbf {H^{(k-1)} \\in R^{n \\times f_{k-1}} }$ 是输入的图信号，$\\mathbf {H{(0)} = X}$，$f_{k-1}$ 是输入的通道数，$f_k$ 是输出的通道数，$\\Theta^{(k)}_{i,j}$ 是可学习参数的对角矩阵。由于使用拉普拉斯矩阵特征分解（eigendecomposition），Spetral CNN 有三个限制：第一，图的任何扰动都会导致特征基的变化；第二，学习的滤波器依赖域，这意味着不能应用到具有不同结构的图中；第三，特征分解的计算复杂度为 $O(n^3)$。后续的工作中，ChebNet 和 GCN 通过一些近似和简化将复杂度降低到 $O(m)$。 &emsp;&emsp;ChebNet（CHebyshev spectral CNN）（2016）[10] 用对角矩阵中特征值的 Chebyshev 多项式来近似滤波器：$\\mathbf {g_\\theta = \\sum ^K_{i=0} \\theta_i T_i (\\hat {\\Lambda})}$ ，其中 $\\mathbf {\\hat {\\Lambda} = 2 \\Lambda / \\lambda_{max} - I_n}$，$\\hat {\\Lambda} \\in [-1, 1]$。 Chebyshev 多项式是递归定义的：$T_i(x) = 2xT_{i-1}(x) - T_{i-2}(x)$， $T_0(x) = 1$，$T_1(x) = x$。于是，图信号 $\\mathbf x$ 的卷积与滤波器 $\\mathbf g_\\theta$ 的定义为： &emsp;&emsp;其中，$\\mathbf {\\hat L = 2L/\\lambda _{max} - I_n}$。由于可以通过归纳证明 $T_i(\\hat {\\mathbf L}) = \\mathbf {U} T_i (\\hat {\\mathbf \\Lambda}) \\mathbf {U}^T$，ChebNet 可以表示为： &emsp;&emsp;作为对 Spectral CNN 的改进，ChebNet 定义的滤波器在空间中局部化，使滤波器可以不考虑图的大小来提取局部特征。ChebNet 的光谱被线性映射到 [-1, 1]。CayleyNet（2019）[11] 进一步应用参数有理复函数（parametric rational complex functions）的 Cayley 多项式来捕获窄频带（narrow frequency bands）。Cayley 的谱图卷积定义为： &emsp;&emsp;其中，$\\mathrm {Re(·)}$ 返回复数的实部，$c_0$ 是实数系数，$c_j$ 是复数系数，$i$ 是虚数，$h$ 是控制 Cayley 滤波器频谱的参数。在保持空间局部性的同时，CayleyNet 证明 ChebNet 可以看作是 CayleyNet 的特例。 &emsp;&emsp;GCN（Graph convolutional network）对 ChebNet 进行了一阶近似。假设 $K = 1, \\lambda_{max} = 2$，于是 ChebNet 简化为： &emsp;&emsp;为了限制参数量且避免过拟合，GCN 进一步假设 $\\theta = \\theta_0 = -\\theta_1$，从而图卷积的定义如下： &emsp;&emsp;为了能满足多通道输入和输出，GCN 将上式修改为： &emsp;&emsp;其中，$\\mathbf {\\bar A = I_n + D^{-(1/2)}AD^{-(1/2)}}$，$f(·)$ 是激活函数。$\\bar {\\mathbf A}$ 会导致 GCN 的数值不稳定，为了解决这个问题，GCN 应用了一个规范化的技巧，用 $\\mathbf {\\bar A = \\tilde D^{-(1/2)} \\tilde A \\tilde D^{-(1/2)}}$ 代替$\\mathbf {\\bar A = I_n + D^{-(1/2)}AD^{-(1/2)}}$。其中，$\\mathbf {\\tilde A = A + I_n, \\tilde D_{ii} = \\sum_j \\tilde A_{ij}}$。作为一种基于谱的方法，GCN 也可以解释为基于空间的方法。从基于空间的角度来看，GCN 可以看作是从节点的邻居聚合特征信息： &emsp;&emsp;最近的一些工作通过探索其他对称矩阵对 GCN 进行了改进。AGCN（Adaptive GCN）（2018）[12] 通过图邻接矩阵学习隐藏结构关系，它将两个节点的特征作为输入学习距离函数来构造残差图邻接矩阵。DGCN（Dual GCN）（2018）[13] 引入了一种双图（dual-graph）卷积结构，具有两个并行的共享参数的图卷积层，使用标准化的邻接矩阵 $\\mathbf {\\bar A}$ 和正点互信息（positive pointwise mutual information, PPMI）矩阵，对图随机游走采样捕获节点共现信息。PPMI 矩阵定义为： &emsp;&emsp;其中，$v_1, v_2 \\in V, |D| = \\sum _{v_1, v_2} count(v_1, v_2)$ 和 $count(·)$ 函数返回节点 $v$ 和/或节点 $u$ 在随机游走采样中共现/出现的频率。通过对双图卷积层的输出进行聚合，DGCN 可以对局部和全局结构信息进行编码，而不需要堆叠多个图卷积层。 B. 基于空间的 ConvGNNs&emsp;&emsp;与传统的图像卷积的 CNN 类似，基于空间的方法通过节点的空间关系来定义图卷积。如果将像素表示为节点，图像的卷积可以看作是图卷积的特例。在图像的卷积上，滤波器对每个通道上的中心节点及其邻居节点的像素值进行加权平均。类似地，基于空间的图卷积对中心节点表示及其邻居节点表示进行卷积，以此来更新中心节点的表示，如下图所示。从另一角度看，基于空间的 ConvGNNs 与 RecGNNs 具有相同的信息传播/消息传播思想。空间图卷积运算本质上是沿着边传播节点信息。 &emsp;&emsp;与 GNN* 同时提出的 NN4G（Neural network for graphs）（2009）[14] 是第一个基于空间的 ConvGNNs。与 RecGNNs 明显不同的是，NN4G 通过一个每层具有独立参数的组合神经结构学习图的相互依赖性，并通过增加架构结构来扩展节点的邻居数。NN4G 通过直接汇总节点的邻居信息进行图卷积，并且应用残差连接来记忆每一层的信息。NN4G 通过下面的公式更新下一层节点： &emsp;&emsp;其中，$f(·)$ 是激活函数，$h^{(0)}_v = 0$。上式的矩阵形式为： &emsp;&emsp;与 GCN 不同的是，NN4G 使用非规范化的邻接矩阵，这可能会导致隐藏节点状态大小差别非常大。CGMM（Contextual graph Markov model）（2018）[15] 提出了一个受 NN4G 启发的概率模型，在保持空间局部性的同时，CGMM 具有概率解释能力。DCNN（Diffusion CNN）(2016）[16] 将图卷积看作一个扩散过程，它假设信息以一定的转移概率从一个节点转移到其邻居节点上，从而信息分布在几轮之后达到平衡。DCNN 将扩散图卷积（diffusion graph convolutin, DGC）定义为： &emsp;&emsp;其中，$f(·)$ 是激活函数，概率变换矩阵 $\\mathbf {P \\in R^{n \\times n}}$ 通过 $\\mathbf {P = D^{-1}A}$ 计算。注意，在 DCNN 中，隐藏表示矩阵 $\\mathbf H^{(k)}$ 与输入特征矩阵 $\\mathbf X$ 维度相同，并且不是其先前隐藏表示矩阵 $\\mathbf H^{(k-1)}$ 的函数。DCNN 将 $\\mathbf {H^{(1)}, H^{(2)}, …, H^{(K)}}$ 连接（concatenation）在一起作为模型的最终输出。由于扩散过程的平稳分布是概率变换矩阵幂级数的总和，DGC（2018）[17] 将每次扩散的输出相加而不是连接： &emsp;&emsp;其中，$\\mathbf {W^{(k)} \\in R^{D \\times F}}$ ，$f(·)$ 是激活函数。使用转移概率矩阵的幂意味着较远的邻居对中心节点贡献的信息很少，PGC-DGCNN（2018）[18] 基于最短路径提高较远邻居的贡献，定义了最短路径邻接矩阵 $\\mathbf S^{(j)}$ 。如果从节点 $v$ 到节点 $u$ 的最短路径长度是 $j$ ，那么 $\\mathbf S^{(j)}_{v, u} = 1$，否则为0。PGC-DGCNN 通过超参数 $r$ 控制感受野大小，引入了一种图卷积运算： &emsp;&emsp;其中，$\\mathbf {H^{(0)} = X, \\bar{A}^{(j)} = (\\tilde{D}^{(j)})^{-(1/2)} \\tilde{A}^{(j)} (\\tilde {D}^{(j)})^{-(1/2)}, \\tilde{A}^{(j)} = A^{(j)} + I}$。 &emsp;&emsp;MPNN（message-passing neural net work）（2017）[19] 提出了基于空间的 ConvGNNs 的一般框架。它将图卷积视为消息传递（message-passing）过程，在这个过程中，信息可以沿着边直接从一个节点传递到另一个节点。MPNN 进行 K 步迭代进行消息传递，消息传递函数定义为： &emsp;&emsp;其中，$\\mathbf h^{(0)}_v = \\mathbf x_v$，$U_k(·), M_k(·)$ 是可学习参数的函数。在计算出每个结点的隐藏表示之后，可以将 $\\mathbf h^{(K)}_v$ 传递到输出层用于节点预测任务，或者传递到读出（readout）函数用于图预测任务。读出函数基于节点隐藏表示生成整个图的表示，通常被定义为： &emsp;&emsp;其中，$R(·)$ 表示可学习参数的读出函数。然而，GIN（Graph isomorphism network）（2019）[20] 发现以前基于 MPNN 的方法无法通过生成的图嵌入区分不同的图结构。为了解决这一点，GIN 通过一个可学习的参数 $\\epsilon^{(k)}$ 调整中心节点的权重。其图卷积定义为： &emsp;&emsp;其中，$\\mathbf MLP(·)$ 代表多层感知机。由于节点的邻居数量可能从一个到一千个甚至更多，因此获取节点所有的邻居是低效的。GraphSage（2017）[21] 为每个节点采样固定数量的邻居。其图卷积定义为： &emsp;&emsp;其中，$\\mathbf h^{(0)}_v = \\mathbf x_v$，$f_k(·)$ 是聚合函数，$S_{N(v)}$ 是节点 $v$ 的邻居的一个随机采样。聚合函数应该与节点的顺序无关，例如求平均值、求和或最大值等。 ​&emsp;&emsp;GAT（Graph attention network）（2017）[22] 中邻居节点对中心节点的贡献既不同于 GraphSage，也不同于 GCN。GAT 采用注意力机制学习两个相连节点之间的相对权重，其图卷积运算定义为： &emsp;&emsp;其中，$\\mathbf h^{(0)}_v = \\mathbf x_v$。注意力权重 $\\alpha^{(k)}_{vu}$ 代表节点 $v$ 与其邻居节点 $u$ 之间的连接强度： &emsp;&emsp;其中，$g(·)$ 是 $\\mathrm {LeakyReLU}$ 激活函数，$a$ 是可学习的向量。softmax 函数能保证节点 $v$ 的所有邻居节点的注意力权重总和为1。使用多头注意力（multihead attention）的 GAT 进一步增加了模型的表达能力。 与 GraphSage 相比，GAT 在节点分类任务上有明显的性能提升。GAT 的注意力头的贡献是相等的，而 GAAN （Gated attention network）（2018）[23] 引入了自注意力（self-attention）机制，为每个注意力头计算额外的注意力分数。除了在空间上应用图注意力外，GeniePath（2019）[24] 进一步提出了类似 LSTM 的门控机制来控制图卷积层之间的信息流。 &emsp;&emsp;MoNet（Mixture model network）（2017）[25] 引入节点的伪坐标来确定节点与其邻居节点之间的相对位置，以此为结点的邻居分配不同的权重。一旦两个节点之间的相对位置确定，权重函数就会将相对位置映射为这两个节点之间的相对权重。通过这种方式，图滤波器的参数可以在不同的位置共享。在 MoNet 框架下，一些现有的流形（manifolds）的方法，例如 GCNN（geodesic CNN）（2015）[26] 、ACNN（anisotropic CNN）（2016）[27] 和 spline CNN（2018）[28]，图方法，例如 GCN、DCNN 等，可以通过构造非参数权重函数将其归纳为 MoNet 的特例。MoNet 还提出了一种具有可学习参数的高斯核来自适应学习权重函数。 &emsp;&emsp;另一个不同的工作路线基于特定标准对结点的邻居进行排序，并将每个排序与可学习的权重相关联，从而实现不同位置的权重共享。PATCHY_SAN（2016）[29] 根据每个结点的图标签对其邻居进行排序，并选择前 $q$ 个邻居。图标签本质上是节点分数，可以通过节点度（degree）、中心度（centrality）和 Weisfeiler-Lehman（WL）颜色计算。由于每个节点有了固定数量的有序邻居，因此可以将图结构数据转换为网格数据。PATCHY-SAN 应用标准的一维卷积滤波器来聚合邻居特征信息，其中滤波器权重的顺序对应于节点邻居的顺序。PATCHY-SAN 的排序标准只考虑图结构，数据处理需要大量的计算。LGCN（Large-scale GCN）（2018）[30] 基于节点特征信息对节点的邻居进行排序。对于每个节点，LGCN 组合由其邻居组成的特征矩阵，并按列对该特征矩阵排序。排序后的特征矩阵的前 $q$ 行作为中心节点的输入数据。 训练效率的提升 &emsp;&emsp;训练 ConvGNNs，例如 GCN，通常需要把整个图数据和所有节点的中间状态存到内存中。当图包含的节点过多时，一起训练全部图数据会出现严重的内存溢出问题。为了节省内存，GraphSage 提出了批训练算法，以固定的样本大小通过 K 步递循环扩展每个节点的邻居节点。对于每个采样的树，GraphSage 通过从下到上分层聚合隐藏节点表示来计算根节点的隐藏表示。FastGCN（Fast learning with GCN）（2018）[31] 对每个图卷积层采样固定的节点数，而不是对每个节点采样固定数量的邻居。它将图卷积解释为概率度量下的节点嵌入函数的积分变换。蒙特卡洛近似（Monte Carlo approximation）和方差缩减（variance reduction）技术也被用于加速训练过程。由于 FastGCN 为每层独立采样节点，层之间的连接可能是稀疏的。Huang 等人（2018）[32] 提出了一种自适应分层采样方法，其中上层的节点采样作为下层的节点采样的前置条件。与 FastGCN 相比，该方法具有更高的精度，但采样方案更复杂。 &emsp;&emsp;另一个工作中，StoGCN（stochastic training of GCNs）（2018）[33] 使用历史节点表示作为控制变量，将图卷积的感受野大小大大降低。即使每个节点只有两个邻居，StoGCN 也能获得很好的性能。然而，StoGCN 仍然需要保存所有结点的中间状态，这对于大型图来说依然消耗内存。 ​&emsp;&emsp;Cluster-GCN（2019）[34] 使用图聚类算法对子图进行采样，并对采样子图的节点进行图卷积。由于在采样子图内进行邻居搜索，Cluster-GCN 能够用更少的时间和内存使用更深的结构处理更大的图。下表是一些模型的时间和内存的比较。 ​&emsp;&emsp;表中，$n$ 是节点总数，$m$ 是边总数，$K$ 是网络层数，$s$ 是批大小（batch-size）。GCN 是全批量（full-batch）训练的基线方法，GraphSage 牺牲时间效率降低了内存使用，同时，随着 $K$ 和 $r$ 的增加，GraphSage 的时间和内存呈指数增长。Sto-GCN 的时间复杂度最高，并且内存瓶颈也没有解决，然而在 $r$ 很小时能获得较好的性能。Cluster-GCN 的时间复杂度与基线方法相同，在所有方法中空间复杂度最低。 谱模型与空间模型的比较 ​&emsp;&emsp;谱模型有图信号处理的理论基础，通过设计新的图信号滤波器，可以构建新的 ConvGNNs。然而，在效率、通用性和灵活性上，空间模型优于谱模型。首先，谱模型的效率低于空间模型，谱模型要么需要进行特征向量计算，要么同时处理整个图。而空间模型通过信息传播直接图进行卷积，在处理大型图上更具可扩展性。而且空间模型可以对节点分批计算，而不是计算整个图。其次，依赖图傅里叶基的谱模型很难推广到新的图上，因为对图的任何扰动都会导致特征基的变化。另一方面，基于空间的模型在每个节点上计算局部图卷积，其权重在不同的位置和结构上很容易共享。第三，谱模型仅适用于对无向图，而空间模型处理多源图，例如输入边、有向图、符号图和超图等，更灵活，因为这些图可以很容易地合并到聚合函数中。 C. 图池化模块​&emsp;&emsp;GNN 生成节点的特征向量后可用于下游任务。然而，直接使用所有特征是困难的，因此需要采用下采样（downsample）策略。池化（pooling）操作旨在通过对节点进行下采样来生成更小的表示来减小参数量，从而避免过拟合、置换不变性（permutation invariance）和计算复杂性问题。读出操作和池化操作非常类似，主要用于基于节点表示生成图表示。 ​&emsp;&emsp;在早期的工作中，图粗化（graph coarsening）算法根据图的拓扑结构使用特征分解对图进行粗化。然而，这些方法面临时间复杂度问题。Graclus 算法（2007）[35] 是特征分解的一种替代方法，用于计算原始图的聚类。最近的一些工作将其作为池化操作对图粗化。 ​&emsp;&emsp;目前，由于在池化窗口计算平均值、最大值、求和是很快的，因此常用来作为下采样最原始和最有效的方法： ​&emsp;&emsp;其中，$K$ 代表最后一个图卷积层数。Henaff 等人（2015）[36] 表明，在网络开始时执行简单的最大、平均池化对于降低图域中的维数和降低图傅里叶变换操作的成本是尤为重要的。此外，一些工作也使用注意力机制增强平均、求和池化操作。图嵌入将任何大小的图生成固定大小的嵌入，即使使用注意力机制，下采样的操作会使嵌入的效率降低。Vinyals 等人（2016）[37] 提出了 Set2Set 的方法来生成随输入大小增加的内存，然后它用一个 LSTM 在下采样之前整合顺序相关的信息到内存嵌入中，避免破坏信息。 ​&emsp;&emsp;Defferard 等人在 ChebNet 中设计了一个有效的池化策略，按照某种意义重新排序图的节点来解决这个问题。首先通过 Graclus 算法将输入图粗化为多个级别，然后将输入图的节点和粗化后的重新排列为平衡二叉树。将平衡二叉树相似的节点排列在一起，从下到上任意聚合，将排列好的信号池化比原始池化要有效得多。 ​&emsp;&emsp;Zhang 等人（2018）[38] 提出的 DGCNN 中使用了名为 SortPooling 的类似的池化策略。与 ChebNet 不同，DGCNN 根据节点在图中的结构角色对节点排序。来自空间图卷积的图的无序节点特征被视为连续的 WL 颜色，并以此来排序节点。除了对节点特征进行排序外，他还通过截断/扩展节点特征矩阵将图大小统一为 $q$。如果 $n &gt; q$，则删除最后的 $n - q$ 行；否则，添加 $q - n$ 个零行。 ​&emsp;&emsp;上述的池化方法主要考虑到图的特征而忽略了图的结构信息。最近提出了一种可微池化（differentiable pooling，DiffPool）（2018）[39] 生成图的层级表示。与以前所有的粗化方法相比，DiffPool 不止对图中节点聚类，而是在 $k$ 层学习一个聚合分配矩阵 $\\mathbf S$，在第 $k$ 层表示为 $\\mathbf S{(k)} \\in \\mathbf R^{n_k \\times n_{k+1}}$，其中， $n_k$ 是第 $k$ 层的节点数量。矩阵 $\\mathbf S^{(k)}$ 中的概率值是基于节点特征和拓扑结构，利用下面的公式计算的： ​&emsp;&emsp;其核心思想是综合考虑图的拓扑结构和特征信息来学习节点的表示，因此上式可以用任何标准的 ConvGNNs 来实现。但是，DiffPool 的缺点是它在池化后生成稠密图，计算复杂度为 $O(n^2)$。最近提出的 SAGPool（2019）[40]方法考虑了节点的特征和图拓扑结构，并以自注意力的方式学习池化。 ​&emsp;&emsp;总的来说，池化是减小图大小的一个基本操作。如何提高池化的有效性和计算复杂性是一个仍待研究的开放问题。 D. 理论方面的讨论 感受野形状（Shape of Receptive Field）：节点的感受野是决定其最终节点表示的一组节点。当合成多个空间图卷积层时，节点的感受野每次都朝着他的远处邻居节点扩展。Micheli （2009）[41] 证明了存在有限数量的空间图卷积层使得每个节点 $v \\in V$ 的感受野覆盖图中的所有节点。因此，ConvGNNs 能够通过叠加局部图卷积层来提取全局信息。 VC 维（VC Dimension）：VC 维是模型复杂度的一种度，关于 GNNs 的 VC 维分析的工作很少。给定模型的参数量 $p$ 和节点数量 $n$，Scarselli 等人（2018）[42] 推导出，如果使用 sigmoid 或 tangent 双曲线激活函数，GNN* 的 VC 维是 $O(p^4n^2)$；如果使用分段多项式激活函数，则 VC 维是 $O(p^2n)$。这一结果表明，如果使用 sigmoid 或 tangent 双曲线激活函数，GNN* 的模型复杂度随着 $p$ 和 $n$ 的增加而迅速增加。 图同构（Graph Isomorphism）：如果两个图拓扑相同，则称为同构。给定两个非同构图 $G_1$ 和 $G_2$，Xu 等人（2019）[43] 证明，如果 GNN 将 $G_1$ 和 $G_2$ 映射到不同的嵌入，则这两个图可以通过同构的 WL 检验确定为非同构的。他们表明，常见的 GNNs，如 GCN 和 GraphSage，不能区分不同的图结构。Xu 等人进一步证明，如果 GNN 的聚合函数和读出函数是内射的，则 GNN 能够像 WL 检测一样区分不同的图。 等变性与不变性（Equivariance and Invariance）：GNN 在处理节点级任务时必须是等边函数，在处理图级别任务时必须是不变函数。对于节点级任务，令 $f(\\mathbf {A, X}) \\in R^{n \\times d}$ 是一个 GNN，$\\mathbf Q$ 可以是节点顺序不同的任何置换矩阵。如果 GNN 满足 $f(\\mathbf {QAQ^T, QX}) = \\mathbf Q f(\\mathbf {A, X})$ 那么该 GNN 是等变的。对于图级别的任务，令 $f(\\mathbf {A, X}) \\in R^d$。如果满足 $f(\\mathbf {QAQ^T, QX}) = f(\\mathbf {A, X})$，则 GNN 是不变的。为了实现等变性与不变性，GNN 的组成部分必须对节点顺序保持不变。Maron 等人（2019）[44] 从理论上研究了图数据的置换不变和等变线形层的性质。 通用近似（Universal Approximation）：众所周知，具有一个隐藏层的多层感知机前馈神经网络可以逼近任何 Borel 可观测函数（1989）[45]，而 GNNs 的通用近似能力很少被研究。Hammer 等人（2005）[46] 证明了级联关系（cascade correlation）可以近似结构化输出的函数。Scarselli 等人（2009）[4] 证明了 RecGNN 可以近似任何保持展开等价性的任何精度的函数。（如果两个节点的展开树相同，则他们展开等价。其中一个节点的展开树是通过在一定深度上迭代展开节点的邻居节点来构造的。）Xu 等人（2019）[20] 表明，消息传递框架下的 ConvGNNs 不是定义在多级上的连续函数的通用近似。Maron 等人(20190[44] 证明了不变图网络可以近似图的任意不变函数。 6. 图自编码器​&emsp;&emsp;GAEs 是将节点映射到潜在特征空间，并从潜在表示解码图信息的深层神经网络。GAEs 可用于学习网络嵌入或生成新的图。 A. 网络嵌入​&emsp;&emsp;网络嵌入是保留节点拓扑信息的低维向量表示。GAEs 使用编码器提取网络嵌入，使用解码器保留图的拓扑信息（如 PPMI 矩阵和邻接矩阵）来学习网络嵌入。早期的方法主要使用多层感知机构建 GAE 来学习网络嵌入。DNGRs（Deep nerual networks for graph representations）（2016）[47] 使用多层去噪编码器来编码，并通过多层感知机对 PPMI 矩阵解码。同时，SDNE（structural deep network embedding）（2016）[48] 使用多层自编码器联合保持节点的一阶近似度和二阶近似度。SDNE 分别在编码器和解码器的输出端使用两个损失函数。第一个损失函数通过最小化节点与其邻居的网络嵌入之间的距离，使学习到的网络嵌入保持节点的一阶相似性。该损失函数定义为： ​&emsp;&emsp;其中，$\\mathbf x_v = \\mathbf A_{v,:}$，$enc(·)$ 是由多层感知机构成的编码器。第二个损失函数通过最小化节点输入与其重构输入之间的距离，使学习到的网络嵌入保持节点的二阶近似。具体定义为： ​&emsp;&emsp;其中，如果 $A_{v,u} = 0$，则$b_{v, u} = 1$；如果 $A_{v,u} = 1$，则$b_{v, u} = \\beta &gt; 1$，$dec(·)$ 使由多层感知机构成的解码器。 ​&emsp;&emsp;DNGR 和 SDNE 只考虑了节点之间连通性的结构信息，忽略了可能包含描述节点自身属性的特征信息。GAE*（避免歧义）（2016）[49] 利用 GCN 同时对节点的结构信息和特征信息进行编码。其编码器由两个图卷积组成： ​&emsp;&emsp;其中，$\\mathbf Z$ 代表图的网络嵌入矩阵，$f(·)$ 是 ReLU 激活函数，$Gconv(·)$ 是 GCN 的图卷积层。GAE* 的解码器目的是通过重构图的邻接矩阵来解码节点嵌入到关系信息，定义为： ​&emsp;&emsp;其中，$\\mathbf z_v$ 是节点 $v$ 的嵌入。GAE* 通过最小化原邻接矩阵 $\\mathbf A$ 和重构的邻接矩阵 $\\hat {\\mathbf A}$ 之间的负交叉熵来训练。 ​&emsp;&emsp;由于自编码器的容量有限，简单地重建图邻接矩阵可能会导致过拟合。VGAE（Variational GAE）[49] 学习数据的分布优化变分下界 $L$： ​&emsp;&emsp;其中，$KL(·)$ 是 Kullback-Leibler 散度，用于衡量两个分布之间的距离，$p(\\mathbf Z)$ 是高斯先验，$p(\\mathbf Z) = \\prod^n_{i=1}p(\\mathbf z_i) = \\prod^n_{i=1}N(\\mathbf z_i|0,\\mathbf I)$，$p(A_{ij} = 1|\\mathbf z_i, \\mathbf z_j) = \\mathrm {dec}(\\mathbf z_i, \\mathbf z_j) = \\sigma (\\mathbf z^T_i \\mathbf z_j)$，$q(\\mathbf {Z|X,A}) = \\prod^n_{i=1}q(\\mathbf z_i|\\mathbf {X, A})$，其中 $q(\\mathbf z_i|\\mathbf {X,A}) = N(\\mathbf z_i|\\mu_i, diag(\\sigma^2_i))$。$\\mu_i$ 是编码器输出的第 i 行的平均向量，$\\mathrm {log}\\sigma_i$ 是与另一个向量的近似度。根据上式，VGAE 认为经验分布 $q(\\mathbf {Z|X,A})$ 应尽可能接近先验分布 $p(\\mathbf Z)$。为了进一步使经验分布 $q(\\mathbf {Z|X,A})$ 近似于先验分布 $p(\\mathbf Z)$，ARVGA（adversarially regularized VGAE）（2018）[50] 采用 GANs（generative adversarial networks）的方式进行训练。 ​&emsp;&emsp;与 GAE* 类似，GraphSage（2017）[21] 使用两个图卷积层对节点特征进行编码。GraphSage 表示，负采样可以保留两个节点之间俺的关系信息，其损失定义为： ​&emsp;&emsp;其中，节点 $u$ 是节点 $v$ 的邻居，节点 $v_n$ 是从负采样分布 $P_n(v)$ 采样的节点 $v$ 的远节点，$Q$ 是负样本的数量。该损失本质上相近的节点有相似的表示，远处的节点有不相似的表示。DGI（2019）[51] 通过最大化局部互信息使局部网络嵌入获取到全局结构信息，在实验结果上比 GraphSage 有明显的改进。 ​&emsp;&emsp;上述方法本质上是通过解决链路预测问题来学习网络嵌入。然而，图的稀疏性导致正节点对的数量远小于负节点对的数量。为了解决网络嵌入中数据稀疏的问题，有一些工作通过随机排列或随机游走将图转换为序列来处理，于是那些适用于序列的深度学习方法可以直接用于处理图数据。DRNE（Deep recursive network embedding）（2018）[52] 认为节点的网络嵌入应该近似于其邻居的网络嵌入的聚合，它使用 LSTM 来聚合节点的邻居。其重构损失定义为： ​&emsp;&emsp;其中，$\\mathbf z_v$ 是节点 $v$ 通过查字典得到的网络嵌入，LSTM 网络的输入为节点 $v$ 的邻居节点，并使用度来排序。如上式所示，DRNE 通过 LSTM 网络隐式地学习网络嵌入，而不是用来生成网络嵌入，这避免了 LSTM 网络对节点序列的排序不变性的问题。NetRAs（Network representations with adversarially regularized autoencoders）（2018）[53] 提出了一种更具一般性的损失函数： ​&emsp;&emsp;其中，dist(·) 衡量节点及其重构节点嵌入之间的距离。NetRA 的编码器和解码器都是 LSTM，每个节点作为根节点随机游走作为输入。与 ARVGA 类似，NetRA 通过对抗训练将学习到的网络嵌入规则化到先验分布，实验结果证明了其有效性。 B. 图生成​&emsp;&emsp;对于多个图，GAEs 能够通过将图编码为隐藏表示，并将隐藏表示解码为图结构来学习图的一般分布。大多数用于图生成的 GAEs 是为了解决分子图生成问题而设计的，在药物发现中具有很高的实用价值。 ​&emsp;&emsp;序列（Sequential）方法通过逐步生成节点和边来生成图。Gómez-Bombarelli 等人（2018）[54]，Kusner 等人（2017）[55]，Dai 等人（2018）[56] 分别用深度 CNNs 和 RNNs 作为编码器和解码器，构建了字符串表示的分子图生成模型。虽然这些方式是特定领域的，但也可应用于一般图中。DeepGMG（Deep generative model of graphs）（2018）[57] 认为图的概率是所有可能的节点置换的总和： ​&emsp;&emsp;其中，$\\pi$ 代表节点顺序。它提取了图中所有节点和边的复杂联合概率。DeepGMG 通过一系列决策生成图，包括是否添加节点、添加哪个节点、是否添加边、连接到哪个节点。生成节点和边的决策过程取决于由 RecGNN 更新的节点状态和图状态。在另一个工作中，GraphRNN（2018）[58] 提出了一个图级别 RNN 和一个边级别 RNN 来建模节点和边的生成过程。图级别 RNN 每次向节点序列添加一个新的节点，边级别 RNN 则生成一个二进制序列，表示新节点与之前生成的节点之间的连接。 ​&emsp;&emsp;全局（Global）方法一次输出整个图。GraphVAE（Graph variational autoencoder）（2018）[59] 将节点和边建模成独立的随机变量。假设编码器得到的后验分布为 $q(\\mathbf z|G)$ ，解码器生成的分布为 $p_\\theta(G|\\mathbf z)$ ，GraphVAE 优化了变分下界： ​&emsp;&emsp;其中，$p(\\mathbf z)$ 遵循高斯先验，$\\phi, \\theta$ 是可学习的参数。GraphVAE 使用 ConvGNN 作为编码器，使用简单的多层感知机作为解码器，输出生成的图及其邻接矩阵、节点属性和边属性。控制生成图的全局属性，如图的连通性（connectivity）、有效性（validity）和节点兼容性（node compatibility）是一项挑战。RGVAE（Regularized GraphVAE）（2018）[60] 进一步对 GraphVAE 施加有效性约束以调节解码器的输出分布。MolGAN（Molecular GAN）（2018）[61] 结合了 convGNNs（2018）[62]、GANs（2017）[63] 和强化学习目标来生成具有所需属性的图。在 MolGAN 中，生成器生成伪（fake）图，鉴别器鉴定伪样本，同时奖励（reward）网络根据评估器（evaluator）促进生成的图具有某些属性。NetGAN（2018）[64] 结合 LSTMs 与 Wasserstein GANs（2017）[65]，基于随机游走的方法生成图。NetGAN 通过 LSTM 训练生成器以生成合理的随机游走，并使用判别器鉴定随机游走的真伪。经过训练，可以通过生成器随机游走计算的规范化共现矩阵导出生成图。 ​&emsp;&emsp;简言之，序列方法将图线性化为序列，由于环的存在可能会丢失一些结构信息。全局方法一次生成一个图形，这种方法不能扩展到大型图，因为 GAE 的输出空间高达 $O(n^2)$。 7. 时空图神经网络​&emsp;&emsp;在许多实际应用中，图的结构和输入是动态的。STGNNs 是处理动态图很重要的方法。这类方法旨在对动态节点输入进行建模，同时假设相连的节点之间存在相互依赖关系。例如，交通网络由放置在路上的速度传感器组成，边的权重由传感器之间的距离确定，由于道路的交通情况可能取决于其临近道路的情况，因此在预测交通速度时有必要考虑空间相关性。STGNNs 可以同时捕获图的空间和时间依赖关系，用来预测未来节点的值或标签，或预测时空图的标签。STGNNs 包括基于 RNN 的和基于 CNN 的两种方法。 ​&emsp;&emsp;大多数基于 RNN 的方法通过使用图卷积过滤传递给循环单元的输入和隐藏状态来捕获时空依赖性。假设一个简单的 RNN 表示为： ​&emsp;&emsp;其中，$\\mathbf X^{(t)} \\in \\mathbf R^{n \\times d}$ 是在时间步 t 时的节点特征矩阵。在加入图卷积后，上式变为： ​&emsp;&emsp;其中，Gconv(·) 是图卷积层。GCRN（2018）[66] 将 ChebNet 与 LSTM 结合；DCRNN（ Diffusion convolutional RNN）（2018）[67] 将扩散图卷积层合并到 GRU 中，并采用编码器-解码器的框架来预测未来 K 步节点的值。同时，一些工作中节点的时间信息和边的时间信息分别通过节点级别 RNNs 和边级别 RNNs 传递。为了整合空间信息，节点 RNN 将边 RNN 的输出作为输入。由于对不同的节点使用不同的 RNNs 会显著增加模型复杂度，因此它将节点和边拆分为语义组。同一语义组的节点或边共享相同的 RNN 模型，以此来降低计算成本。 ​&emsp;&emsp;基于 RNN 的方法存在梯度爆炸和梯度消失以及计算耗时的问题。基于 GNN 的方法以非递归的方式处理时空图，具有并行计算、梯度稳定、内存占用少的优势。基于 CNN 的方法将一维卷积层和图卷积层交错使用来学习时空依赖关系。CGCN 集成了 一维卷积层与 ChebNet（或 GCN 层），通过门控一维卷积层、图卷积层和另一个门控一维卷积层搭建了时空块（spatial-temporal block）。ST-GCN（2018）[68] 使用一个一维卷积层和一个 PGC 层 [36] 搭建了时空块。 ​&emsp;&emsp;前面的方法都使用预定义的图结构，认为预定义的图结构反映了节点之间的真正的依赖关系。然而，由于图数据在时空设置中有许多快照（snapshot），因此可以从数据中自动学习潜在的静态图结构。为实现这一点，Graph WaveNet（2019）[69] 提出了一种自适应邻接矩阵进行图卷积。自适应邻接矩阵定义为： ​&emsp;&emsp;其中，SoftMax 方法沿行方向计算，$\\mathbf {E1}$ 代表源节点嵌入，$\\mathbf {E2}$ 代表目标节点嵌入。通过将 $\\mathbf {E1}$ 与 $\\mathbf {E2}$ 相乘，可以得到源节点和目标节点之间的依赖性权重。Graph Wavenet 采用复杂的基于 CNN 的时空神经网络，无需给定邻接矩阵就有良好的表现。 ​&emsp;&emsp;学习潜在的静态空间依赖关系有助于发现网络中不同实体之间的可解释且稳定的相关性。然而，在某些情况下，学习潜在的动态空间依赖关系可能进一步提高模型精度。例如，在交通网络中，在两条道路的行驶时间可能取决于它们当前的交通状况。GaAN（2018）[70] 采用注意力机制，通过基于 RNN 的方法学习动态空间依赖性。给定两个相连节点输入，使用注意力函数更新两个节点之间的边权重。ASTGCN（2019）[71] 使用空间注意力函数和时间注意力函数，通过基于 CNN 的方法学习潜在的动态空间依赖和时间依赖，时间复杂度为 $O(n^2)$。 8. 应用​&emsp;&emsp;图结构数据无处不在，GNNs 有着广泛的应用。 A. 数据集​&emsp;&emsp;这里主要列举了四个方面的数据集：引用网络、生化图、社交网络以及其他。 B. 评价方法​&emsp;&emsp;节点分类和图分类是评估 RecGNNs 和 ConvGNNs 性能的常见任务。 节点分类：节点分类的大多数方法遵循 benchmark 数据集（如 Cora、Citeseer、Pubmed、PPI 和 Reddit）的标准的 train/valid/test 的划分方法。通常使用多次测试的平均准确率（accuracy）或 F1 分数。更多信息请参考 [72]。 图分类：通常采用十倍交叉验证进行模型评估。然而，在不同的工作中实验设置不统一。更多信息请参考 [73]。 C. 实际应用 计算机视觉：场景图生成、点云分类、动作识别。 识别对象之间的语义关系有助于理解视觉场景背后的含义。场景图生成模型旨在将图像解析为由对象及其语义关系组成的语义图。相反地，由于自然语言可以被解析为语义图，其中每个单词表是一个对象，因此根据给定文本描述合成图像也是一个很有前途的解决方案。 点云是由激光雷达设备扫描到的三维点集。将点云转换为 k-近邻图或超点图，可使用 ConvGNNs 来探索其拓扑结构。 识别视频中人的行为有助于让机器理解视频内容。一些解决方案检测视频帧中人体相关位置，由骨骼连接的人体关节形成图，然后根据人关节位置的时空序列应用 STGNNs 来学习人类行为模式。 另外，GNNs 在计算机视觉中的应用在不断增加，包括人机交互、少样本图像分类、语义分割、视觉推理和问答等。 自然语言处理：常见的应用是文本分类，GNNs 利用文本或单词的相互关系来推断文本类别。尽管自然语言数据往往是序列形式的，但内部可能包含图结构，如句法依赖树。 交通：准确预测交通网络中的交通速度、交通量或道路密度对于智能交通系统至关重要。 推荐系统：基于图的推荐系统将用户和商品作为节点，利用节点之间、商品之间、节点和商品之间以及节点内容信息，生成高质量的推荐。 化学：在化学领域，GNNs 用于研究分子、化合物的图结构。在分子、化合物图中，原子被视为节点，化学键被视为边。节点分类、图分类和图生成是针对分子、化合物的三个重要任务，目的是学习分子指纹（molecular fingerprints）、预测分子特性、推断蛋白质结构以及合成化合物。 其他：GNNs 不限于以上应用。在程序验证、程序推理、社会影响预测、对抗性攻击预防、电子健康记录建模、大脑网络、事件检测和组合优化上都有人探索。 9. 未来方向A. 模型深度​&emsp;&emsp;深度学习的成功在于深度的神经网络结构。然而，Li 等人（2018）[74] 表明，随着图卷积层数量的增加，ConvGNNs 的性能急剧下降。由于图卷积使相邻节点的表示更接近，在理论上，经过无限多的图卷积层，所有结点的表示都将收敛到一个值。于是，更深的网络结构是否是学习图数据的好的策略呢，这是一个问题。 B. 权衡可扩展性​&emsp;&emsp;GNNs 的可扩展性以破坏图的完整性为代价，如论是使用采样还是聚类，模型都会丢失部分图信息。通过采样，节点可能会丢失部分邻居；通过聚类，图可能缺少了不同的结构模式。如何权衡算法的可扩展性和图的完整性可能是未来的研究方向。 C. 异质性​&emsp;&emsp;当前的大多数 GNNs 都采用同质图，因此很难将这些方法应用于异构图。异构图是指可能包含不同节点类型和边类型，或者不同形式的节点和边作为输入（如图和文本）的图。因此，应该开发新的方法来处理异构图。 D. 动态性​&emsp;&emsp;图的输入可能随时间发生变化，需要新的卷积来适应图的动态性，虽然图的动态性可以部分地由 STGNNs 来解决，但很少有人考虑在动态空间关系的情况下如何执行图卷积。 参考文献[1] A. Sperduti and A. Starita, “Supervised neural networks for the classification of structures,” IEEE Trans. Neural Netw., vol. 8, no. 3, pp. 714–735, May 1997. [2] J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun, “Spectral networks and locally connected networks on graphs,” in Proc. ICLR, 2014, pp. 1–14. [3] T. Luong, H. Pham, and C. D. Manning, “Effective approaches to attention-based neural machine translation,” in Proc. Conf. Empirical Methods Natural Lang. Process., 2015, pp. 1412–1421. [4] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini, “The graph neural network model,” IEEE Trans. Neural Netw., vol. 20, no. 1, pp. 61–80, Jan. 2009. [5] C. Gallicchio and A. Micheli, “Graph echo state networks,” in Proc. Int. Joint Conf. Neural Netw. (IJCNN), Jul. 2010, pp. 1–8. [6] Y. Li, D. Tarlow, M. Brockschmidt, and R. Zemel, “Gated graph sequence neural networks,” in Proc. ICLR, 2015, pp. 1–20. [7] H. Dai, Z. Kozareva, B. Dai, A. Smola, and L. Song, “Learning steady-states of iterative algorithms over graphs,” in Proc. ICML, 2018, pp. 1114–1122. [8] T. N. Kipf and M. Welling, “Semi-supervised classification with graph convolutional networks,” in Proc. ICLR, 2017, pp. 1–14. [9] J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun, “Spectral networks and locally connected networks on graphs,” in Proc. ICLR, 2014, pp. 1–14. [10] M. Defferrard, X. Bresson, and P. Van der Gheynst, “Convolutional neural networks on graphs with fast localized spectral filtering,” in Proc. NIPS, 2016, pp. 3844–3852. [11] R. Levie, F. Monti, X. Bresson, and M. M. Bronstein, “CayleyNets: Graph convolutional neural networks with complex rational spectral filters,” IEEE Trans. Signal Process., vol. 67, no. 1, pp. 97–109, Jan. 2019. [12] R. Li, S. Wang, F. Zhu, and J. Huang, “Adaptive graph convolutional neural networks,” in Proc. AAAI, 2018, pp. 3546–3553. [13] C. Zhuang and Q. Ma, “Dual graph convolutional networks for graph-based semi-supervised classification,” in Proc. World Wide Web Conf. World Wide Web (WWW), 2018, pp. 499–508. [14] A. Micheli, “Neural network for graphs: A contextual constructive approach,” IEEE Trans. Neural Netw., vol. 20, no. 3, pp. 498–511, Mar. 2009. [15] D. Bacciu, F. Errica, and A. Micheli, “Contextual graph Markov model: A deep and generative approach to graph processing,” in Proc. ICML, 2018, pp. 1–10. [16] J. Atwood and D. Towsley, “Diffusion-convolutional neural networks,” in Proc. NIPS, 2016, pp. 1993–2001. [17] Y. Li, R. Yu, C. Shahabi, and Y. Liu, “Diffusion convolutional recurrent neural network: Data-driven traffic forecasting,” in Proc. ICLR, 2018, pp. 1–16. [18] D. V. Tran, N. Navarin, and A. Sperduti, “On filter size in graph convolutional networks,” in Proc. IEEE Symp. Ser. Comput. Intell. (SSCI), Nov. 2018, pp. 1534–1541. [19] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl, “Neural message passing for quantum chemistry,” in Proc. ICML, 2017, pp. 1263–1272. [20] K. Xu, W. Hu, J. Leskovec, and S. Jegelka, “How powerful are graph neural networks,” in Proc. ICLR, 2019, pp. 1–17. [21] W. Hamilton, Z. Ying, and J. Leskovec, “Inductive representation learning on large graphs,” in Proc. NIPS, 2017, pp. 1024–1034. [22] P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio, “Graph attention networks,” in Proc. ICLR, 2017, pp. 1–12. [23] J. Zhang, X. Shi, J. Xie, H. Ma, I. King, and D.-Y. Yeung, “GaAN: Gated attention networks for learning on large and spatiotemporal graphs,” in Proc. UAI, 2018, pp. 1–10. [24] Z. Liu et al., “GeniePath: Graph neural networks with adaptive receptive paths,” in Proc. AAAI Conf. Artif. Intell., Jul. 2019, pp. 4424–4431. [25] F. Monti, D. Boscaini, J. Masci, E. Rodola, J. Svoboda, and M. M. Bronstein, “Geometric deep learning on graphs and manifolds using mixture model CNNs,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jul. 2017, pp. 5115–5124. [26] J. Masci, D. Boscaini, M. M. Bronstein, and P. Vandergheynst, “Geodesic convolutional neural networks on Riemannian manifolds,” in Proc. IEEE Int. Conf. Comput. Vis. Workshop (ICCVW), Dec. 2015, pp. 37–45. [27] D. Boscaini, J. Masci, E. Rodolà, and M. Bronstein, “Learning shape correspondence with anisotropic convolutional neural networks,” in Proc. NIPS, 2016, pp. 3189–3197. [28] M. Fey, J. E. Lenssen, F. Weichert, and H. Müller, “SplineCNN: Fast geometric deep learning with continuous B-spline kernels,” in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., Jun. 2018, pp. 869–877. [29] M. Niepert, M. Ahmed, and K. Kutzkov, “Learning convolutional neural networks for graphs,” in Proc. ICML, 2016, pp. 2014–2023. [30] H. Gao, Z. Wang, and S. Ji, “Large-scale learnable graph convolutional networks,” in Proc. 24th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, Aug. 2018, pp. 1416–1424. [31] J. Chen, T. Ma, and C. Xiao, “FastGCN: Fast learning with graph convolutional networks via importance sampling,” in Proc. ICLR, 2018, pp. 1–15. [32] W. Huang, T. Zhang, Y. Rong, and J. Huang, “Adaptive sampling towards fast graph representation learning,” in Proc. NeurIPS, 2018, pp. 4563–4572. [33] J. Chen, J. Zhu, and L. Song, “Stochastic training of graph convolutional networks with variance reduction,” in Proc. ICML, 2018, pp. 941–949. [34] W.-L. Chiang, X. Liu, S. Si, Y. Li, S. Bengio, and C.-J. Hsieh, “Cluster-GCN: An efficient algorithm for training deep and large graph convolutional networks,” in Proc. 25th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining (KDD), 2019, pp. 257–266. [35] I. S. Dhillon, Y. Guan, and B. Kulis, “Weighted graph cuts without eigenvectors a multilevel approach,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 29, no. 11, pp. 1944–1957, Nov. 2007. [36] M. Henaff, J. Bruna, and Y. LeCun, “Deep convolutional networks on graph-structured data,” 2015, arXiv:1506.05163. [Online]. Available: http://arxiv.org/abs/1506.05163 [37] O. Vinyals, S. Bengio, and M. Kudlur, “Order matters: Sequence to sequence for sets,” in Proc. ICLR, 2016, pp. 1–11. [38] M. Zhang, Z. Cui, M. Neumann, and Y. Chen, “An end-to-end deep learning architecture for graph classification,” in Proc. AAAI, 2018, pp. 1–8. [39] Z. Ying, J. You, C. Morris, X. Ren, W. Hamilton, and J. Leskovec, “Hierarchical graph representation learning with differentiable pooling,” in Proc. NeurIPS, 2018, pp. 4801–4811. [40] J. Lee, I. Lee, and J. Kang, “Self-attention graph pooling,” in Proc. ICML, 2019, pp. 3734–3743. [41] A. Micheli, “Neural network for graphs: A contextual constructive approach,” IEEE Trans. Neural Netw., vol. 20, no. 3, pp. 498–511, Mar. 2009. [42] F. Scarselli, A. C. Tsoi, and M. Hagenbuchner, “The Vapnik– Chervonenkis dimension of graph and recursive neural networks,” Neural Netw., vol. 108, pp. 248–259, Dec. 2018. [43] K. Xu, W. Hu, J. Leskovec, and S. Jegelka, “How powerful are graph neural networks,” in Proc. ICLR, 2019, pp. 1–17. [44] H. Maron, H. Ben-Hamu, N. Shamir, and Y. Lipman, “Invariant and equivariant graph networks,” in ICLR, 2019, pp. 1–14. [45] K. Hornik, M. Stinchcombe, and H. White, “Multilayer feedforward networks are universal approximators,” Neural Netw., vol. 2, no. 5, pp. 359–366, Jan. 1989. [46] B. Hammer, A. Micheli, and A. Sperduti, “Universal approximation capability of cascade correlation for structures,” Neural Comput., vol. 17, no. 5, pp. 1109–1159, May 2005. [47] S. Cao, W. Lu, and Q. Xu, “Deep neural networks for learning graph representations,” in Proc. AAAI, 2016, pp. 1145–1152. [48] D. Wang, P. Cui, and W. Zhu, “Structural deep network embedding,” in Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining (KDD), 2016, pp. 1225–1234. [49] T. N. Kipf and M. Welling, “Variational graph auto-encoders,” in Proc. NIPS Workshop Bayesian Deep Learn., 2016, pp. 1–3. [50] S. Pan, R. Hu, G. Long, J. Jiang, L. Yao, and C. Zhang, “Adversarially regularized graph autoencoder for graph embedding,” in Proc. IJCAI, Jul. 2018, pp. 2609–2615. [51] P. Veliˇckovi´c, W. Fedus, W. L. Hamilton, P. Liò, Y. Bengio, and R. D. Hjelm, “Deep graph infomax,” in Proc. ICLR, 2019, pp. 1–17. [52] K. Tu, P. Cui, X. Wang, P. S. Yu, and W. Zhu, “Deep recursive network embedding with regular equivalence,” in Proc. 24th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, Aug. 2018, pp. 2357–2366. [53] W. Yu et al., “Learning deep network representations with adversarially regularized autoencoders,” in Proc. 24th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, Aug. 2018, pp. 2663–2671. [54] R. Gómez-Bombarelli et al., “Automatic chemical design using a data-driven continuous representation of molecules,” ACS Central Sci., vol. 4, no. 2, pp. 268–276, Jan. 2018. [55] M. J. Kusner, B. Paige, and J. M. Hernández-Lobato, “Grammar variational autoencoder,” in Proc. ICML, 2017, pp. 1945–1954. [56] H. Dai, Y. Tian, B. Dai, S. Skiena, and L. Song, “Syntax-directed variational autoencoder for structured data,” in Proc. ICLR, 2018, pp. 1–17. [57] Y. Li, O. Vinyals, C. Dyer, R. Pascanu, and P. Battaglia, “Learning deep generative models of graphs,” in Proc. ICML, 2018, pp. 1–21. [58] J. You, R. Ying, X. Ren, W. L. Hamilton, and J. Leskovec, “GraphRNN: A deep generative model for graphs,” in Proc. ICML, 2018, pp. 1–12. [59] M. Simonovsky and N. Komodakis, “Graphvae: Towards generation of small graphs using variational autoencoders,” in Proc. ICANN. Cham, Switzerland: Springer, 2018, pp. 412–422. [60] T. Ma, J. Chen, and C. Xiao, “Constrained generation of semantically valid graphs via regularizing variational autoencoders,” in Proc. NeurIPS, 2018, pp. 7110–7121. [61] N. De Cao and T. Kipf, “MolGAN: An implicit generative model for small molecular graphs,” ICML Workshop Theor. Found. Appl. Deep Generative Models, 2018, pp. 1–11. [62] M. Schlichtkrull, T. N. Kipf, P. Bloem, R. van den Berg, I. Titov, and M. Welling, “Modeling relational data with graph convolutional networks,” in ESWC. Cham, Switzerland: Springer, 2018, pp. 593–607. [63] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C. Courville, “Improved training of Wasserstein GANs,” in Proc. NIPS, 2017, pp. 5767–5777. [64] A. Bojchevski, O. Shchur, D. Zügner, and S. Günnemann, “NetGAN: Generating graphs via random walks,” in Proc. ICML, 2018, pp. 1–16. [65] M. Arjovsky, S. Chintala, and L. Bottou, “Wasserstein GAN,” 2017, arXiv:1701.07875. [Online]. Available: http://arxiv.org/abs/1701.07875 [66] Y. Seo, M. Defferrard, P. Vandergheynst, and X. Bresson, “Structured sequence modeling with graph convolutional recurrent networks,” in Proc. NeurIPS. Springer, 2018, pp. 362–373. [67] Y. Li, R. Yu, C. Shahabi, and Y. Liu, “Diffusion convolutional recurrent neural network: Data-driven traffic forecasting,” in Proc. ICLR, 2018, pp. 1–16. [68] S. Yan, Y. Xiong, and D. Lin, “Spatial temporal graph convolutional networks for skeleton-based action recognition,” in Proc. AAAI, 2018, pp. 1–9. [69] Z. Wu, S. Pan, G. Long, J. Jiang, and C. Zhang, “Graph WaveNet for deep spatial-temporal graph modeling,” in Proc. IJCAI, Aug. 2019, pp. 1–7. [70] J. Zhang, X. Shi, J. Xie, H. Ma, I. King, and D.-Y. Yeung, “GaAN: Gated attention networks for learning on large and spatiotemporal graphs,” in Proc. UAI, 2018, pp. 1–10. [71] S. Guo, Y. Lin, N. Feng, C. Song, and H. Wan, “Attention based spatial-temporal graph convolutional networks for traffic flow forecasting,” in Proc. AAAI, 2019, pp. 922–929. [72] O. Shchur, M. Mumme, A. Bojchevski, and S. Günnemann, “Pitfalls of graph neural network evaluation,” in Proc. NeurIPS workshop, 2018, pp. 1–11. [73] F. Errica, M. Podda, D. Bacciu, and A. Micheli, “A fair comparison of graph neural networks for graph classification,” in Proc. ICLR, 2020, pp. 1–15. [Online]. Available: https://openreview. net/forum?id=HygDF6NFPB [74] Q. Li, Z. Han, and X.-M. Wu, “Deeper insights into graph convolutional networks for semi-supervised learning,” in Proc. AAAI, 2018, pp. 1–8.","link":"2021/12/22/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94%E7%BB%BC%E8%BF%B0/"}],"tags":[{"name":"OCR","slug":"OCR","link":"tags/OCR/"},{"name":"Mysql","slug":"Mysql","link":"tags/Mysql/"},{"name":"hexo","slug":"hexo","link":"tags/hexo/"},{"name":"人工智能","slug":"人工智能","link":"tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"ffmpeg","slug":"ffmpeg","link":"tags/ffmpeg/"},{"name":"对话系统","slug":"对话系统","link":"tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"GNN","slug":"GNN","link":"tags/GNN/"}],"categories":[{"name":"人工智能","slug":"人工智能","link":"categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"工具使用","slug":"工具使用","link":"categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"},{"name":"博客","slug":"博客","link":"categories/%E5%8D%9A%E5%AE%A2/"},{"name":"对话系统","slug":"对话系统","link":"categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"深度学习","slug":"深度学习","link":"categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]}