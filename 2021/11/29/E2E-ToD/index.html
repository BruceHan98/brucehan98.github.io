<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>E2E-ToD - Bruce Han&#039;s Blog</title><link rel="manifest" href="../../../../manifest.json"><meta name="application-name" content="Bruce Han&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Bruce Han&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="End-to-end Task-oriented Dialogue Generation"><meta property="og:type" content="blog"><meta property="og:title" content="E2E-ToD"><meta property="og:url" content="https://brucehan98@github.io/2021/11/29/E2E-ToD/"><meta property="og:site_name" content="Bruce Han&#039;s Blog"><meta property="og:description" content="End-to-end Task-oriented Dialogue Generation"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211104181332244.png"><meta property="og:image" content="https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211104152652317-16360108141352.png"><meta property="og:image" content="https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211104183936654.png"><meta property="og:image" content="https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211104195616286-16360269774885.png"><meta property="og:image" content="https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211104214021322-16360332224666.png"><meta property="og:image" content="https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211105134659284-16360912216137.png"><meta property="og:image" content="https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211123101529987.png"><meta property="og:image" content="https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211123114235443.png"><meta property="og:image" content="https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211123114254678.png"><meta property="og:image" content="https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211123115432506-16376396736524.png"><meta property="og:image" content="https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211123165757891.png"><meta property="og:image" content="https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211123162234896-16376557559585.png"><meta property="article:published_time" content="2021-11-29T05:31:50.000Z"><meta property="article:modified_time" content="2022-09-01T15:34:10.597Z"><meta property="article:author" content="Bruce Han"><meta property="article:tag" content="ToD"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211104181332244.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://brucehan98@github.io/2021/11/29/E2E-ToD/"},"headline":"E2E-ToD","image":["https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211104181332244.png","https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211104152652317-16360108141352.png","https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211104183936654.png","https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211104195616286-16360269774885.png","https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211104214021322-16360332224666.png","https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211105134659284-16360912216137.png","https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211123101529987.png","https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211123114235443.png","https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211123114254678.png","https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211123115432506-16376396736524.png","https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211123165757891.png","https://brucehan98@github.io/Program%20Files/Typora/documents/pic/image-20211123162234896-16376557559585.png"],"datePublished":"2021-11-29T05:31:50.000Z","dateModified":"2022-09-01T15:34:10.597Z","author":{"@type":"Person","name":"Bruce Han"},"publisher":{"@type":"Organization","name":"Bruce Han's Blog","logo":{"@type":"ImageObject","url":"https://brucehan98@github.io/img/logo.svg"}},"description":"End-to-end Task-oriented Dialogue Generation"}</script><link rel="canonical" href="https://brucehan98@github.io/2021/11/29/E2E-ToD/"><link rel="icon" href="../../../../img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/xcode.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="../../../../css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="../../../../index.html"><img src="../../../../img/logo.svg" alt="Bruce Han&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="../../../../index.html">首页</a><a class="navbar-item" href="../../../../archives">归档</a><a class="navbar-item" href="../../../../categories">分类</a><a class="navbar-item" href="../../../../tags">标签</a><a class="navbar-item" href="../../../../about">关于</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/BruceHan98"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article" style="padding-left: 2rem; padding-right: 2rem; padding-top: 1rem; padding-bottom: 1rem"><h1 class="title is-size-4 is-size-4-mobile" style="font-weight: bold; margin: 0.5rem 0;">E2E-ToD</h1><div class="article-meta is-size-6 is-uppercase level is-mobile" style="margin-top: 0.5rem;"><div class="level-left"><span class="level-item"><time dateTime="2021-11-29T05:31:50.000Z" title="2021-11-29T05:31:50.000Z">2021-11-29</time>发表</span><span class="level-item"><time dateTime="2022-09-01T15:34:10.597Z" title="2022-09-01T15:34:10.597Z">2022-09-01</time>更新</span><span class="level-item"><a class="link-muted" href="../../../../categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/">对话系统</a></span><span class="level-item">20 分钟读完</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><div class="content" style="margin-top: 1rem; margin-bottom: 1rem;"><h3 id="Approaches"><a href="#Approaches" class="headerlink" title="Approaches"></a>Approaches</h3><h4 id="MemN2N"><a href="#MemN2N" class="headerlink" title="MemN2N"></a>MemN2N</h4><p>[<strong>NIPS 2015</strong>] Sukhbaatar et al., New York University, <strong>End-To-End Memory Networks.</strong></p>
<p>Given an <strong>input set</strong> $x_1, .., x_i$ to be stored in memory, the entire set of ${x_i}$ are converted into memory vectors ${m_i}$ of dimension d computed by embedding each $x_i$ in a continuous space with <strong>embedding matrices</strong> A and C (both of size d × |V |).</p>
<p>The <strong>query q</strong> is also embedded to obtain an internal state $u$ using another embedding matrix B.</p>
<p>In the embedding space, we compute the <strong>match</strong> between $u$ and each memory $m_i$ by taking the <strong>inner product</strong> followed by a softmax: $p_i = Softmax(u^Tm_i)$, $p$ is a probability vector over the inputs.</p>
<p>Each $x_i$ has a corresponding output vector $c_i$, the response vector from the <strong>memory</strong> $o$ is then a sum over the transformed inputs $c_i$ , weighted by the probability vector from the input: $o = \sum\limits_i p_ic_i$ .</p>
<p>The predicted label: $\hat{a} = Softmax(W(o+u))$ .</p>
<p>During training, all three embedding matrices A, B and C, as well as W are jointly learned by minimizing a standard <strong>cross-entropy loss</strong> between $\hat{a}$ and the true label $a$.</p>
<p><img src="../../../../Program Files/Typora/documents/pic/image-20211104181332244.png" alt="image-20211104181332244" style="zoom:50%;" /></p>
<p><img src="../../../../Program Files/Typora/documents/pic/image-20211104152652317-16360108141352.png" alt="image-20211104152652317"></p>
<h4 id="GMemN2N"><a href="#GMemN2N" class="headerlink" title="GMemN2N"></a>GMemN2N</h4><p>[<strong>ACL 2017</strong>] Fei Liu et al., The University of Melbourne Victoria, Australia, <strong>Gated End-to-End Memory Networks</strong>.</p>
<p>Based on MemN2N, introduced a  novel end-to-end <strong>memory access regulation mechanism</strong> inspired by the current progress on the <strong>connection short-cutting principle</strong> in the field of computer vision.</p>
<p><strong>Highway and Residual Networks</strong></p>
<p><strong>Highway Networks</strong> (Srivastava et al., NIPS 2015) include a <strong>transform gate T</strong> and a <strong>carry gate C</strong>, allowing the network to learn how much information it should transform or carry to form the input to the next layer.</p>
<p>$y = H(x) \odot T(x) + x \odot C(x)$    or    $y = H(x) \odot T(x) + x \odot (1-T(x))$</p>
<p>where $H(x), T(x), C(x)$ is a non-linear transformation of its input $x$, $\odot$ is the Hadamard product.</p>
<p><strong>Residual Networks</strong> (He et al., CVPR 2016) can be viewed as a <em>special case</em> of Highway Networks where both the transform and carry gates are substituted by the identity mapping function:    $y = H(x) + x$</p>
<p>However, Highway Networks is the adaptive gating mechanism, capable of learning to dynamically control the information flow based on the current input.</p>
<p>Therefore, we adopt the idea  and integrate it into MemN2N, dynamically conditioning the memory reading operation on the controller state $u^k$ at each hop.</p>
<p>$T^k(u^k) = \sigma(W^k_Tu^k + b^k_T)$</p>
<p>$u^{k+1} = \sigma^k \odot T^k(u^k) + u^k \odot (1-T^k(u^k))$</p>
<p><img src="../../../../Program Files/Typora/documents/pic/image-20211104183936654.png" alt="image-20211104183936654" style="zoom:50%;" /></p>
<h4 id="Mem2Seq"><a href="#Mem2Seq" class="headerlink" title="Mem2Seq"></a>Mem2Seq</h4><p>[<strong>ACL 2018</strong>] Madotto et al., The Hong Kong University of Science and Technology, <strong>Mem2Seq: Effectively Incorporating Knowledge Bases into End-to-End Task-Oriented Dialog Systems</strong>.</p>
<p><strong>Mem2Seq</strong> using global multi-hop attention mechanisms to copy words directly from dialog history or KBs. Main contributions: </p>
<p>(1) combines <strong>multi-hop attention mechanisms</strong> with the idea of <strong>pointer networks</strong>, which allows us to effectively incorporate KB information.</p>
<p>(2) learns how to <strong>generate dynamic queries</strong> to control the memory access.</p>
<p><strong>Memory Encoder:</strong></p>
<p>We define all the words in the dialog history as a sequence of tokens $X = {x_1, . . . , x_n, $}$, the KB tuples as $B = {b_1, . . . , b_l}$, $U = [B; X]$ as the concatenation of the two sets $X$ and $B$.  $Y = {y_1, . . . , y_m}$ as the set of words in the expected system response. $PTR = {ptr_1 , . . . , ptr_m}$ as the pointer index set.</p>
<p>Mem2Seq uses a standard MemN2N with adjacent weighted tying (Sukhbaatar et al., 2015) as an encoder. The input of the encoder is word-level information in $U$. The memories of MemNN are represented by a set of trainable embedding matrices $C = {C<em>1 , . . . , C</em>{K+1}}$, where each $C_k$ maps tokens to vectors, and a query vector $q_k$ is used as a reading head.</p>
<p>The <strong>attention weights</strong> at hop $k$ for each memory i using: $p^k_i = Softmax((q^k)^TC^k_i)$, where $C^k_i = C^k(x_i)$ is the memory content in position $i$.</p>
<p>Then, the model reads out the memory $o^k$ by the weighted sum over $C^{k+1}$: $o^k = \sum\limits_i p^k_iC^{k+1}_i$.</p>
<p>Then, the query vector is updated for the next hop by using $q^{k+1} = q^k + o^k$.</p>
<p><strong>Memory Decoder:</strong></p>
<p>The decoder uses RNN and MemN2N. GRU is used as a <strong>dynamic query generator</strong> for the MemNN.</p>
<p>At each decoding step $t$, the GRU gets the previously generated word and the previous query as input, and it generates the new query vector: $h<em>t = GRU(C^1(\hat{y}</em>{t-1}), h_{t-1})$, where $h_0$ is the encoder vector $o^K$.</p>
<p>At each time step, <strong>two distribution</strong> are generated: one over all the words in the vocabulary ($P<em>{vocab})$, and one over the memory contents ($P</em>{ptr})$. </p>
<p>$P_{vocab}$ is generated by concatenating the first hop attention read out and the current query vector.</p>
<p>$P_{vocab}(\hat{y}_t) = Softmax(W_1[h_t;o_1])$</p>
<p>$P<em>{ptr}$ is generated using the attention weights at the last MemNN hop of the decoder: $P</em>{ptr} = p^K_t$. </p>
<p><img src="../../../../Program Files/Typora/documents/pic/image-20211104195616286-16360269774885.png" alt="image-20211104195616286"></p>
<p>If the expected word is not appearing in the memories, then the $P<em>{ptr}$ is trained to produce the <em>sentinel</em> token , then the model generates the token from $P</em>{vocab}$; otherwise, it using the $P_{ptr}$ distribution. Basically, the <em>sentinel</em> token is used as a <strong>hard gate</strong> to control which distribution to use at each time step.</p>
<h4 id="GLMP"><a href="#GLMP" class="headerlink" title="GLMP"></a>GLMP</h4><p>[<strong>ICLR 2019</strong>] Wu et al., The Hong Kong University of Science and Technology, <strong>Global-to-local Memory Pointer Networks for Task-oriented Dialogue</strong>.</p>
<p>The dialogue history $X = (x_1, . . . , x_n)$ and the KB information $B = (b_1, . . . , b_l)$ are the input, and the system response $Y = (y_1, . . . , y_m)$ is the expected output.</p>
<p>First, the global memory encoder uses a context RNN to encode dialogue history and writes its hidden states into the external knowledge. Then the last hidden state is used to read the external knowledge and generate the global memory pointer at the same time. </p>
<p>During the decoding stage, the local memory decoder first generates sketch responses by a sketch RNN. Then the global memory pointer and the sketch RNN hidden state are passed to the external knowledge as a filter and a query. The local memory pointer returns from the external knowledge can copy text from the external knowledge to replace the sketch tags and obtain the final system response.</p>
<p><strong>Global contextual representation</strong></p>
<p>In the <strong>KB memory module</strong>, each element bi ∈ B is represented in the <strong>triplet format</strong> as (Subject, Relation, Object) structure, for example, (Tom’s house, distance, 3 miles).</p>
<p>The dialogue context $X$ is stored in the <strong>dialogue memory module</strong> like a <strong>triplet format</strong>, ($user, turn1, I).</p>
<p><strong>Knowledge read and write</strong></p>
<p>Our <strong>external knowledge</strong> is composed of a set of <strong>trainable embedding matrices</strong> $C = (C^1 , . . . , C^{K+1})$, where $C^k ∈ R^{|V |×d<em>{emb}}$ , $K$ is the maximum memory hop. We denote <strong>memory</strong> in the external knowledge as $M = [B; X] = (m_1, . . . , m</em>{n+l})$, where $m_i$ is one of the triplet components mentioned.</p>
<p>To read the memory, the external knowledge needs a initial query vector $q$, and computes the attention weights at each hop $k$ using: $p^k<em>i = Softmax((q^k ) ^T c^k_i )$, where $c^k_i = B(C^k (mi)) ∈ R^{d</em>{emb}}$ is the embedding in $i_{th}$ memory position using the embedding matrix $C^k$ , $q^k$ is the query vector for hop $k$, and $B(.)$ is the bag-of-word function.</p>
<p>Then, the model reads out the memory $o^k$ by the weighted sum over $c^{k+1}$ and update the query vector $q^{k+1}$: $o^k = \sum\limits_i p^k_i c^{k+1}_i, q^{k+1} = q^k + o^k$.</p>
<p><img src="../../../../Program Files/Typora/documents/pic/image-20211104214021322-16360332224666.png" alt="image-20211104214021322"></p>
<p><strong>GLOBAL MEMORY ENCODER</strong></p>
<p>A context RNN is used to model the sequential dependency and encode the context X. Then the hidden states are written into the external knowledge. The last encoder hidden state serves as the query to read the external knowledge and get two outputs, the global memory pointer and the memory readout.</p>
<p>A bi-directional gated recurrent unit (GRU) (Chung et al., 2014) is used to encode dialogue history into the hidden states $H = (h^e_1 , . . . , h^e_l )$, and the last hidden state $h^e_n$ is used to query the external knowledge as the encoded dialogue history.</p>
<p><strong>LOCAL MEMORY DECODER</strong></p>
<p>The local memory decoder first initializes its <strong>sketch RNN</strong> using the <strong>concatenation</strong> of $h^e_n$ and $q^{K+1}$, and generates a sketch response that excludes slot values but <strong>includes the sketch tags</strong>. For example, sketch RNN will generate “@poi is @distance away”. </p>
<p>At each decoding time step, if a sketch tag is generated, the global memory pointer is passed to the external knowledge, and the expected output word will be picked up from the local memory pointer. Otherwise, the output word is the word that generated by the sketch RNN. For example, a <em>@poi tag</em> is generated at the first time step, therefore, the word <em>Starbucks</em> is picked up from the local memory pointer as the system output word.</p>
<p><img src="../../../../Program Files/Typora/documents/pic/image-20211105134659284-16360912216137.png" alt="image-20211105134659284"></p>
<h4 id="GraphDialog"><a href="#GraphDialog" class="headerlink" title="GraphDialog"></a>GraphDialog</h4><p>[<strong>EMNLP 2020</strong>] Yang et al., The University of Melbourne, <strong>GraphDialog: Integrating Graph Knowledge into End-to-End Task-Oriented Dialogue Systems</strong></p>
<p>There are two challenges for such systems: one is how to <strong>effectively incorporate external knowledge bases</strong> (KBs) into the learning framework; the other is how to <strong>accurately capture the semantics of dialogue history</strong>. In this paper, we address these two challenges by exploiting the <strong>graph structural information</strong> in the knowledge base and in the <strong>dependency parsing tree</strong> of the dialogue.</p>
<p><strong>Dialogue Graph</strong></p>
<p>We first use the off-the-shelf tool spacy to extract the <strong>dependency relations</strong> among the words in the dialogue history X.  The intuition is that the representation learning of the head words should be allowed being influenced by the dependent words and vice versa.</p>
<p><strong>Multi-hop Reasoning Mechanism over Knowledge Graph</strong></p>
<p>We extend the graph with multi-hop reasoning mechanism, which aimed to strengthen the reasoning ability over graph as well as to capture the graph structural information between entities via self-attention.</p>
<p><strong>Decoder</strong></p>
<p>We use a standard Gated Recurrent Unit (GRU) as the decoder to generate the system response word-by-word.</p>
<h4 id="DF-Net-Multi-Domain-Feature-Fusion"><a href="#DF-Net-Multi-Domain-Feature-Fusion" class="headerlink" title="DF-Net [Multi-Domain Feature Fusion]"></a>DF-Net [Multi-Domain Feature Fusion]</h4><p>[<strong>ACL 2020</strong>] Qin et al., Harbin Institute of Technology, <strong>Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog</strong>.</p>
<p>Most neural models rely on large training data, which are only available for a certain number of task domains, such as navigation and scheduling. This makes it difficult to scalable for a <strong>new domain with limited labeled data</strong>. To this end, we investigate methods that can make <strong>explicit use of domain knowledge</strong> and introduce a shared-private network to <strong>learn shared and specific knowledge</strong>.</p>
<p><img src="../../../../Program Files/Typora/documents/pic/image-20211123101529987.png" alt="image-20211123101529987" style="zoom:80%;" /></p>
<p>Methods for multi-domain dialogue:</p>
<p>(1) mixed multi-domain mixed datasets</p>
<p>(2) each domain separately</p>
<p>(3) basic shared-private fusion mechanism</p>
<p>(4) dynamic fusion mechanism</p>
<p>Based on GLMP, we propose to use a shared-private framework including a <strong>shared encoder-decoder</strong> for capturing domain-shared feature and a <strong>private model</strong> for each domain to consider the domain-specific features explicitly. Each instance X goes through both the shared and its corresponding private encoder-decoder.</p>
<p><img src="../../../../Program Files/Typora/documents/pic/image-20211123114235443.png" alt="image-20211123114235443" style="zoom:50%;" /></p>
<p><img src="../../../../Program Files/Typora/documents/pic/image-20211123114254678.png" alt="image-20211123114254678" style="zoom:50%;" /></p>
<h4 id="MCL-Meta-Learning"><a href="#MCL-Meta-Learning" class="headerlink" title="MCL [Meta Learning]"></a>MCL [Meta Learning]</h4><p>[<strong>AAAI 2021</strong>] Qin et al., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, <strong>Exploring Auxiliary Reasoning Tasks for Task-oriented Dialog Systems with Meta Cooperative Learning</strong>.</p>
<p><strong>Contributions</strong></p>
<p><strong>Solved Problems</strong></p>
<p>This model consists of three networks: </p>
<p>(i) an <strong>auxiliary KB reasoning task</strong> for learning meta KB knowledge; </p>
<p>(ii) an <strong>auxiliary dialogue reasoning task</strong> for learning dialogue patterns; </p>
<p>(iii) a <strong>TDS task (primary task)</strong> for not only retrieving accurate entities from KB but also generating natural responses.</p>
<p>Given the input: (1) dialog history that includes a sequence of historical user utterances ${u<em>1, . . . , u_c}$ and system response utterances ${s_1, . . . , s</em>{c−1}}$, and (2) KB tuples ${b_1, . . . , b_l}$, the goal of the task-oriented dialog generation (primary task) is to generate the next system response $s_c = {y_1, y_2, . . . , y_T }$ word by word, where $c$ and $l$ represent the numbers of utterances and KB tuples, $T$ is the length of the generated response.</p>
<p>Our proposed task-oriented dialog generation model is composed of four primary components: <strong>a dialog encoder</strong>, <strong>a dialog memory</strong>, <strong>a KB memory</strong>, and <strong>a response decoder</strong>.</p>
<p><strong>Dialog Encoder</strong></p>
<p>For the $i$-th ($i$ &gt; 1) turn, the input is ${s<em>{i−1}, u_i}$ consisting of the last system response $s</em>{i−1}$ and current user request $u<em>i$ .We define the input ${s</em>{i−1}, u<em>i}$ at each turn as dialog context, which is denoted as a sequence of tokens $X = (x_1, x_2, . . . , x_m)$. First, each token is converted into a word embedding through an embedding layer. Then, we apply a BiGRU (Chung et al. 2014) to encode the dialog context into hidden states: $h_t = BiGRU(e(x_t), h</em>{t−1})$. where $e(x_t)$ denotes the embedding of word $x_t$.</p>
<p><strong>Dialog Memory </strong></p>
<p>We propose a dialog memory to reason over dialog context, which is implemented with a dynamic key-value memory network (Wang et al. 2020). The dialog memory network contains a dialog key memory and a dialog value memory.  The dialog key memory keeps updated at each turn for tracking the dialog history, while the dialog value memory keeps fixed for storing the representation of dialog context.</p>
<p><strong>KB Memory</strong></p>
<p>We employ a separate KB memory to encode the KB information. We access the KB memory by K-hop reading mechanism. Specifically, we use an initial query vector (decoder hidden state) as the reading head, and it loops over K hops and computes the soft attention weights at each hop. The soft memory attention decides the relevance between each memory vector and the query vector.</p>
<p><strong>Response Decoder</strong></p>
<p>Specifically, the t-th word in the target response is either copied from dialog value memory/KB value memory or generated from the overall vocabulary. Similarly, we use $P<em>d(y_t)$ and $P</em>{kb}(y<em>t)$ to represent the probabilities for copying the $t$-th word from the dialog memory and KB memory, respectively. A soft gate $g_1$ determines whether a word is copied from memories or generated from the vocabulary, and another gate $g_2$ determines which of the two memories is used to copy values. The final output distribution $P</em>θ(y<em>t)$ for the t-th target word is computed as: $P</em>θ(y<em>t) = g_1P_v(y_t) + (1 − g_1) [g_2P_d(y_t) + (1 − g_2) P</em>{kb}(y_t)]$.</p>
<p>We compute the loss function $L<em>{primary}$ as the cross-entropy between the predicted word distribution $P</em>θ(y<em>t)$ and the ground-truth target word distribution $y_t$: $L</em>{primary} (θ) = − \sum\limits^T<em>{t=1} y_t log (P</em>θ(y_t))$, where T indicates the length of the output response. </p>
<p><img src="../../../../Program Files/Typora/documents/pic/image-20211123115432506-16376396736524.png" alt="image-20211123115432506"></p>
<h4 id="TPEM-Continual-Learning"><a href="#TPEM-Continual-Learning" class="headerlink" title="TPEM [Continual Learning]"></a>TPEM [Continual Learning]</h4><p>[<strong>ACL 2021</strong>] Geng et al., University of Science and Technology of China, <strong>Continual Learning for Task-oriented Dialogue System with Iterative Network Pruning, Expanding and Masking</strong>.</p>
<p><strong>Continual learning</strong> is hardly a new idea for machine learning, but remains as a non-trivial step for building empirically successful AI systems. It is essentially the case for creating a high-quality TDS.</p>
<p>On the one hand, a dialogue system <strong>is expected to reuse previously acquired knowledge</strong>, but focusing too much on stability may hinder a TDS from quickly adapting to a new task. On the other hand, when a TDS pays too much attention to plasticity, it <strong>may quickly forget previously-acquired abilities</strong>.</p>
<p>In this paper, we propose a continual learning method for task-oriented dialogue system with iterative network pruning, expanding and masking (TPEM), which preserves performance on previously encountered tasks while accelerating learning progress on the future tasks. TPEM adopts the global-to-local memory pointer networks <strong>(GLMP) as the base model</strong>.</p>
<p><strong>Network Pruning</strong></p>
<p>To avoid “catastrophic forgetting” of GLMP, a feasible way is to add weights for learning new tasks. However, as the number of tasks grows, the complexity of model architecture increases rapidly, making the deep model difficult to train. To avoid constructing a huge network, we compress the model for the current task by releasing a certain fraction of neglectable weights of old tasks by setting them to zero. To avoid changing the network connectivity, we re-train the preserved weights for a small number of epochs. When inferring task k, the released weights are masked in a binary on/off fashion.</p>
<p><strong>Network Expanding</strong></p>
<p>The amount of preserved weights for old tasks becomes larger with the growth of new tasks, and there will be fewer free weights for learning new tasks, resulting in slowing down the learning process and making the found solution non-optimal. An intuitive solution is to expand the model while learning new tasks. To effectively perform network expansion while keeping the compactness of network architecture, we define the following strategy to expand the hidden size $H<em>k$ for the $k$-th task from $H</em>{k−1}$: $H<em>k = H</em>{k−1} + α ∗ (P_{k−1} − F_k) ∗ log(1 + N_k/β)$, where α and β are two hyperparameters. </p>
<p><strong>Network Masking</strong></p>
<p>However, not all preserved weights are beneficial to learn new tasks, especially when there is a large gap between old and new tasks. To resolve this issue, we apply a learnable binary mask $M^k$ for each task k to filter some old weights that may hinder the learning of new tasks. $M^k_ij = \begin{cases} 1, &amp; if \tilde{M}^k_ij &gt; τ \ 0, &amp;ortherwise \end{cases}$</p>
<p>Note that old weights WP k are “picked” only and keep unchanged during training. Thus, old tasks can be recalled without forgetting.</p>
<h4 id="CDNET-KB-Distillation"><a href="#CDNET-KB-Distillation" class="headerlink" title="CDNET [KB Distillation]"></a>CDNET [KB Distillation]</h4><p>[<strong>AAAI 2021</strong>] Raghu et al., IBM Research, <strong>Constraint based Knowledge Base Distillation in End-to-End Task Oriented Dialogs</strong>.</p>
<p>Inferring those KB entities that are most relevant for an utterance is crucial for response generation. However, <strong>distilling the KB by softly filtering</strong> irrelevant KB information based on the dialog history revealed that embeddings learnt for entities of the same type are quite close to each other. Such embeddings hurt the overall performance as they <strong>reduce the gap between relevant and irrelevant KB records</strong>. Moreover, GLMP performs KB distillation but fails to <strong>capture the relationship</strong> across attributes in KB records.</p>
<p>This paper proposed two methods to distill irrelevant KB records: (1) a <strong>pairwise similarity score</strong> and (2) an <strong>embedding constraint loss</strong>.</p>
<p><strong>Content Encoder</strong></p>
<p>The dialog history H is encoded using a hierarchical encoder with two GRU.</p>
<p><strong>KB Encoder</strong></p>
<p>We encode the KB using the multi-level memory. In the first level, each KB record is represented as sum of its attributes. In the second level, each attribute is a key-value pair.</p>
<p><strong>KB Distillation</strong></p>
<p>The KB distillation module softly filters irrelevant KB records based on the dialog history by computing a distillation distribution ($P_d$) over the <strong>KB records</strong>.</p>
<p>$P<em>d = [d_1, d_2, …, d_M]$,    $d_m = Softmax(s_m)$,     $s_m = \sum\limits</em>{w∈H} \sum\limits_{v^n_m∈r_m}CosSim(Φ^e(w), Φ^e(v^n_m))$</p>
<p>where CosSim is the cosine similarity between two vectors.</p>
<p><strong>Sketch RNN</strong></p>
<p>We use a GRU to generate the sketch response. At each time t, a generate distribution $P<em>g$ is computed using the decoder hidden state $h_t$ and an attended summary of the dialog context $g_t = \sum_i\sum_ja</em>{ij}w^j<em>i$, where $a</em>{ij}$ is the Luong attention weights over the context word representations $w^j_i$.</p>
<p><strong>Context Memory Pointer</strong></p>
<p>Same as GLMP. At each time t, generate the copy distribution over the context $P<em>{con}$ by performing a multi-hop Luong attention over the context memory. The initial query $q^0_t$ is set to $h_t$, $q^0_t$ is then attended over the context to generate an attention distribution $a^1$ and a summarized context $g^1_t$. In the next hop the same process is repeated by updating the query $q^1_t = q^0_t + g^1_t$. The attention weights after H hops is used for computing the context pointer $P</em>{con}$ as follows: $P<em>{con}(y_t = w) = \sum</em>{ij:w^j<em>i = w} a^H</em>{ij}$</p>
<p><strong>KB Memory Pointer</strong></p>
<p>At each time t, we generate the copy distribution over the KB $P_{kb}$ using:</p>
<p>(1) Luong attention weight $β^t_m$ over the KB record $r_m$</p>
<p>(2) Luong attention weight $γ^t_n$ over attribute keys in a record $k_n$</p>
<p>(3) the distillation weight $d_m$ over the KB record $r_m$</p>
<p>The KB pointer $P_{kb}$ is computed as follows: </p>
<p><img src="../../../../Program Files/Typora/documents/pic/image-20211123165757891.png" alt="image-20211123165757891" style="zoom: 50%;" /></p>
<p>The two copy pointers are combined using a soft gate α to get the final copy distribution $P_c$ as follows:</p>
<p>$P<em>c(y_t) = αP</em>{kb}(y<em>t) + (1 − α)P</em>{con}(y_t)$</p>
<p><img src="../../../../Program Files/Typora/documents/pic/image-20211123162234896-16376557559585.png" alt="image-20211123162234896"></p>
<h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><h4 id="bAbI"><a href="#bAbI" class="headerlink" title="bAbI"></a>bAbI</h4><p>[<strong>Multi-Task</strong>] The bAbI dialog includes five end-to-end dialog learning tasks in the restaurant domain, which are simulated dialog data. Task 1 to 4 are about API calls, refining API calls, recommending options, and providing additional information, respectively. Task 5 is the union of tasks 1-4. There are two test sets for each task: one follows the same distribution as the training set and the other has out-of-vocabulary (OOV) entity values that does not exist in the training set. Along with the train, dev and test sets, we also include a knowledge base file (dialog-babi-kb-all.txt) that contain all entities appearing in dialogs for tasks 1-5. We also include a file containing the candidates to select the answer from (dialog-babi-candidates.txt) for tasks 1-5, that is simply made of all the bot utterances in train, dev, test for these tasks.</p>
<p>The goal of the tasks is to predict the bot utterances, that can be sentences or API calls. </p>
<h4 id="In-Car-Assistant-SMD-KVRET"><a href="#In-Car-Assistant-SMD-KVRET" class="headerlink" title="In-Car Assistant (SMD, KVRET)"></a>In-Car Assistant (SMD, KVRET)</h4><p>The In-Car Assistant dataset is composed of 3031 multi-turn dialogs from calendar scheduling, weather information retrieval, and point-of-interest navigation domains. The average number of turns per dialog is about 2.6.</p>
<h4 id="CamRest"><a href="#CamRest" class="headerlink" title="CamRest"></a>CamRest</h4><p>This corpus contains 676 multi-turn dialogs belonging to restaurant reservation domain. There are 5 turns on average per dialog.</p>
<h4 id="Multi-WOZ"><a href="#Multi-WOZ" class="headerlink" title="Multi-WOZ"></a>Multi-WOZ</h4><p>[<strong>Multi-domain</strong>] Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics. There are 3,406 single-domain dialogues that include booking if the domain allows for that and 7,032 multi-domain dialogues consisting of at least 2 up to 5 domains. The test and development sets contain 1k examples each. </p>
<h4 id="DSTC-2"><a href="#DSTC-2" class="headerlink" title="DSTC-2"></a>DSTC-2</h4><p>The Dialog State Tracking Challenges 2 &amp; 3 (DSTC2&amp;3) were research challenge focused on improving the state of the art in tracking the state of spoken dialog systems. DSTC-2 released a large number of training dialogs related to restaurant search.</p>
<h3 id="Evaluation-Metrics"><a href="#Evaluation-Metrics" class="headerlink" title="Evaluation Metrics"></a>Evaluation Metrics</h3><h4 id="BLEU"><a href="#BLEU" class="headerlink" title="BLEU"></a>BLEU</h4><p>BLEU measures the n-gram (i.e., 4-gram) overlap between the produced responses and the gold responses. BLEU is a popular metric to measure the TDS ’s ability to accurately generate the dialog from the language model perspective.</p>
<h4 id="Entity-F1"><a href="#Entity-F1" class="headerlink" title="Entity-F1"></a>Entity-F1</h4><p>Entity F1 measures the system’s capability of generating relevant entities to accomplish certain tasks by retrieving accurate entities from the provided KB. There are a set of reference entities for each utterance. The entity F1 score is computed by micro-averaging the precision and recall over KB entities of the generated responses.</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>E2E-ToD</p><p><a href="https://brucehan98@github.io/2021/11/29/E2E-ToD/">https://brucehan98@github.io/2021/11/29/E2E-ToD/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Bruce Han</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-11-29</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2022-09-01</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px; margin:0.5rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="../../../../tags/ToD/">ToD </a></div></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="../../../../img/alipay.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="../../../../img/wechat.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="../../../12/13/hexo-icarus%20%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">hexo-icarus 从零搭建个人博客</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="../../../10/02/git%E4%BD%BF%E7%94%A8/"><span class="level-item">git使用</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "ceaf8d398a4beb8152e805dff6b0fb80",
            repo: "brucehan98.github.io",
            owner: "BruceHan98",
            clientID: "84666a45ad34d2937a18",
            clientSecret: "f2432742d8824e7bd1006ae69b85f0488f928759",
            admin: ["BruceHan98"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 20,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            language: "zh-CN",
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Approaches"><span class="level-left"><span class="level-item">1</span><span class="level-item">Approaches</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#MemN2N"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">MemN2N</span></span></a></li><li><a class="level is-mobile" href="#GMemN2N"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">GMemN2N</span></span></a></li><li><a class="level is-mobile" href="#Mem2Seq"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">Mem2Seq</span></span></a></li><li><a class="level is-mobile" href="#GLMP"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">GLMP</span></span></a></li><li><a class="level is-mobile" href="#GraphDialog"><span class="level-left"><span class="level-item">1.5</span><span class="level-item">GraphDialog</span></span></a></li><li><a class="level is-mobile" href="#DF-Net-Multi-Domain-Feature-Fusion"><span class="level-left"><span class="level-item">1.6</span><span class="level-item">DF-Net [Multi-Domain Feature Fusion]</span></span></a></li><li><a class="level is-mobile" href="#MCL-Meta-Learning"><span class="level-left"><span class="level-item">1.7</span><span class="level-item">MCL [Meta Learning]</span></span></a></li><li><a class="level is-mobile" href="#TPEM-Continual-Learning"><span class="level-left"><span class="level-item">1.8</span><span class="level-item">TPEM [Continual Learning]</span></span></a></li><li><a class="level is-mobile" href="#CDNET-KB-Distillation"><span class="level-left"><span class="level-item">1.9</span><span class="level-item">CDNET [KB Distillation]</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Datasets"><span class="level-left"><span class="level-item">2</span><span class="level-item">Datasets</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#bAbI"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">bAbI</span></span></a></li><li><a class="level is-mobile" href="#In-Car-Assistant-SMD-KVRET"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">In-Car Assistant (SMD, KVRET)</span></span></a></li><li><a class="level is-mobile" href="#CamRest"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">CamRest</span></span></a></li><li><a class="level is-mobile" href="#Multi-WOZ"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">Multi-WOZ</span></span></a></li><li><a class="level is-mobile" href="#DSTC-2"><span class="level-left"><span class="level-item">2.5</span><span class="level-item">DSTC-2</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Evaluation-Metrics"><span class="level-left"><span class="level-item">3</span><span class="level-item">Evaluation Metrics</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#BLEU"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">BLEU</span></span></a></li><li><a class="level is-mobile" href="#Entity-F1"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">Entity-F1</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="../../../../js/toc.js" defer></script></div></div><!--!--></div></div></section><footer class="footer" style="padding-bottom: 4rem;"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="../../../../index.html"><img src="../../../../img/logo.svg" alt="Bruce Han&#039;s Blog" height="18"></a><p class="is-size-7"><span>&copy; 2023 Bruce Han</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="../../../../js/column.js"></script><script src="../../../../js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="../../../../js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="../../../../js/main.js" defer></script><script src="../../../../js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="../../../../js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"../../../../content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body><script type="text/javascript" src="/js/mathjax-config.js"></script></html>